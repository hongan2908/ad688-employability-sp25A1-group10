[
  {
    "objectID": "skill_gap_analysis.html",
    "href": "skill_gap_analysis.html",
    "title": "Skill Gap Analysis",
    "section": "",
    "text": "In this analysis, we evaluate the current skill levels of our team and compare them with industry requirements based on job postings data. This will help identify skill gaps and propose improvement strategies.\n\n\n\n\nCode\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\n\n# Load dataset\ncsv_path = 'region_analysis/lightcast_job_postings.csv'\ndf = pd.read_csv(csv_path)\n\n# Drop unnecessary columns\ncolumns_to_drop = [\n    \"ID\", \"URL\", \"ACTIVE_URLS\", \"DUPLICATES\", \"LAST_UPDATED_TIMESTAMP\",\n    \"NAICS2\", \"NAICS3\", \"NAICS4\", \"NAICS5\", \"NAICS6\",\n    \"SOC_2\", \"SOC_3\", \"SOC_5\"\n]\ndf.drop(columns=columns_to_drop, inplace=True)\n\n# Drop columns with &gt;50% missing\ndf.dropna(thresh=len(df) * 0.5, axis=1, inplace=True)\n\n# Fill missing values\nfor col in df.select_dtypes(include=[np.number]):\n    df[col].fillna(df[col].median(), inplace=True)\n\nfor col in df.select_dtypes(include=['object']):\n    df[col].fillna(\"Unknown\", inplace=True)\n\n# Drop duplicates\ndf.drop_duplicates(subset=[\"TITLE\", \"COMPANY\", \"LOCATION\", \"POSTED\"], keep=\"first\", inplace=True)\n\n\n\n\n\n\n\nCode\n# Get top software skills from job postings\nsoftware_skills = (\n    df['SOFTWARE_SKILLS_NAME']\n    .dropna()\n    .str.replace(r'[\\[\\]\\n]', '', regex=True)  # Remove brackets and newlines\n    .str.split(',')\n    .explode()\n    .str.strip()\n)\n\n# Filter out empty strings\nsoftware_skills = software_skills[software_skills != '']\n\n# Get top 5 most frequent software skills\ntop_5_software_skills = software_skills.value_counts().head(5)\n\n# Extract skill names\ntop_5_skills = top_5_software_skills.index.tolist()\n\nprint(\"Top 5 software skills from job postings:\")\nprint(top_5_software_skills)\n\n# Get top 8 most frequent software skills\ntop_8_software_skills = software_skills.value_counts().head(8)\n\n# Extract skill names\ntop_8_skills = top_8_software_skills.index.tolist()\n\nprint(\"Top 8 software skills from job postings:\")\nprint(top_8_software_skills)\n\n\nTop 5 software skills from job postings:\nSOFTWARE_SKILLS_NAME\n\"SQL (Programming Language)\"       20744\n\"Microsoft Excel\"                  12262\n\"Python (Programming Language)\"    11626\n\"SAP Applications\"                 11554\n\"Dashboard\"                        11373\nName: count, dtype: int64\nTop 8 software skills from job postings:\nSOFTWARE_SKILLS_NAME\n\"SQL (Programming Language)\"                  20744\n\"Microsoft Excel\"                             12262\n\"Python (Programming Language)\"               11626\n\"SAP Applications\"                            11554\n\"Dashboard\"                                   11373\n\"Tableau (Business Intelligence Software)\"    11220\n\"Power BI\"                                    10369\n\"Microsoft Office\"                             7238\nName: count, dtype: int64\n\n\n\n\nCode\nimport pandas as pd\n\n# Define team skill levels (Proficiency scale: 1=Beginner, 5=Expert)\nskills_data = {\n    \"Name\": [\"Shreya\", \"An Ly\", \"Advait\", \"Ritusri\"],\n    \"SQL (Programming Language)\": [3, 2, 2, 3],\n    \"Microsoft Excel\": [4, 3, 3, 4],\n    \"Python (Programming Language)\": [3, 3, 3, 3],\n    \"SAP Applications\": [2, 1, 3, 2],\n    \"Dashboard\": [2, 2, 3, 4]\n}\n\ndf_skills = pd.DataFrame(skills_data)\ndf_skills.set_index(\"Name\", inplace=True)\ndf_skills\n\n\n\n\n\n\n\n\n\nSQL (Programming Language)\nMicrosoft Excel\nPython (Programming Language)\nSAP Applications\nDashboard\n\n\nName\n\n\n\n\n\n\n\n\n\nShreya\n3\n4\n3\n2\n2\n\n\nAn Ly\n2\n3\n3\n1\n2\n\n\nAdvait\n2\n3\n3\n3\n3\n\n\nRitusri\n3\n4\n3\n2\n4\n\n\n\n\n\n\n\n\n\nCode\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Team skills for top 5\nskills_data_top5 = {\n    \"Name\": [\"Shreya\", \"An Ly\", \"Advait\", \"Ritusri\"],\n    \"SQL (Programming Language)\": [3, 2, 2, 3],\n    \"Microsoft Excel\": [4, 3, 3, 4],\n    \"Python (Programming Language)\": [3, 3, 3, 3],\n    \"SAP Applications\": [2, 1, 3, 2],\n    \"Dashboard\": [2, 2, 3, 4]\n}\n\ndf_skills_top5 = pd.DataFrame(skills_data_top5).set_index(\"Name\")\n\n# Plot Heatmap 1\nplt.figure(figsize=(10, 5))\nsns.heatmap(df_skills_top5, annot=True, cmap=\"YlOrBr\", linewidths=0.5)\nplt.title(\"Team Skill Levels – Top 5 Software Skills\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\nimport pandas as pd\n\n# Define team skill levels (Proficiency scale: 1=Beginner, 5=Expert)\nskills_data1 = {\n    \"Name\": [\"Shreya\", \"An Ly\", \"Advait\", \"Ritusri\"],\n    \"SQL (Programming Language)\": [3, 2, 2, 3],\n    \"Microsoft Excel\": [4, 3, 3, 4],\n    \"Python (Programming Language)\": [3, 3, 3, 3],\n    \"SAP Applications\": [2, 1, 3, 2],\n    \"Dashboard\": [2, 2, 3, 4],\n    \"Tableau (Business Intelligence Software)\":[0, 0, 0, 0],\n    \"Power BI\":[0, 0, 0, 0],\n    \"Microsoft Office\":[0, 0, 0, 0],\n    \n}\n\ndf_skills1 = pd.DataFrame(skills_data1)\ndf_skills1.set_index(\"Name\", inplace=True)\ndf_skills1\n\n\n\n\n\n\n\n\n\nSQL (Programming Language)\nMicrosoft Excel\nPython (Programming Language)\nSAP Applications\nDashboard\nTableau (Business Intelligence Software)\nPower BI\nMicrosoft Office\n\n\nName\n\n\n\n\n\n\n\n\n\n\n\n\nShreya\n3\n4\n3\n2\n2\n0\n0\n0\n\n\nAn Ly\n2\n3\n3\n1\n2\n0\n0\n0\n\n\nAdvait\n2\n3\n3\n3\n3\n0\n0\n0\n\n\nRitusri\n3\n4\n3\n2\n4\n0\n0\n0\n\n\n\n\n\n\n\n\n\nCode\nimport pandas as pd\n\n# Define team skill levels (Proficiency scale: 1=Beginner, 5=Expert)\nskills_data1 = {\n    \"Name\": [\"Shreya\", \"An Ly\", \"Advait\", \"Ritusri\"],\n    \"SQL (Programming Language)\": [3, 2, 2, 3],\n    \"Microsoft Excel\": [4, 3, 3, 4],\n    \"Python (Programming Language)\": [3, 3, 3, 3],\n    \"SAP Applications\": [2, 1, 3, 2],\n    \"Dashboard\": [2, 2, 3, 4],\n    \"Tableau (Business Intelligence Software)\":[0, 0, 0, 0],\n    \"Power BI\":[0, 0, 0, 0],\n    \"Microsoft Office\":[0, 0, 0, 0],\n    \n}\ndf_skills_top8 = pd.DataFrame(skills_data1).set_index(\"Name\")\n\n# Plot Heatmap 2\nplt.figure(figsize=(10, 5))\nsns.heatmap(df_skills_top8, annot=True, cmap=\"YlOrBr\", linewidths=0.5)\nplt.title(\"Team Skill Levels – Top 8 Software Skills\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nThe heatmap analysis indicates that while the team has solid grounding in fundamental IT tools, there are significant gaps in certain enterprise and visualization technologies that are highly demanded in job postings. Addressing these gaps will elevate the team’s capabilities and make them more market-ready.\nSQL (Programming Language) Although the team has intermediate proficiency in SQL, moving towards expert-level understanding is essential. SQL remains one of the most requested skills across IT and data-centric roles. Advanced topics like complex joins, window functions, performance tuning, and writing optimized queries should be covered. Recommended resources include Coursera’s SQL for Data Science and DataCamp SQL Career Track.\nPython (Programming Language) Python is the cornerstone of automation, analytics, and machine learning. The team should focus on advancing their skills beyond basic scripting. This includes learning about data manipulation (Pandas), building small projects, and exploring libraries used in data science or automation. Free resources like the Google Python Crash Course and the IBM Python for Data Science (Coursera) can be leveraged.\nSAP Applications SAP is currently one of the weakest areas within the team. Enterprise software skills like SAP are critical in corporate environments. Team members should target introductory SAP courses to gain a basic understanding of navigation, reporting, and common SAP modules. Free options like OpenSAP are recommended to start with.\nDashboarding Tools (Power BI / Tableau) Visual storytelling and data presentation are crucial skills in modern IT roles. As seen in the analysis, there is little to no current exposure to Power BI and Tableau. Training should start with beginner-friendly courses that teach how to create interactive dashboards and perform basic data analysis. Tableau Public and Microsoft Learn for Power BI offer excellent free resources.\nMicrosoft Excel While the team is relatively advanced in Excel, moving towards expert proficiency will unlock greater efficiencies. Topics like VBA macros, Power Query, pivot tables, and advanced formulas should be prioritized. Recommended platforms include LinkedIn Learning and Excel Skills for Business (Coursera).\nTableau, Power BI, and Microsoft Office (Missing Skills) The missing ratings for Tableau, Power BI, and Microsoft Office indicate complete lack of knowledge. These tools are essential for reporting, business communication, and project collaboration in IT environments. Each team member should aim to reach at least intermediate level proficiency through self-paced courses and hands-on practice.\n\n\nTo close these gaps systematically:\nWeekly Learning Sessions: Rotate weekly responsibilities where each member shares what they learned about a specific skill.\nPair Learning: Pair up team members with stronger skills (e.g., SQL, Python) to support others.\nMicro-Certifications: Encourage completion of short certifications within 4–6 weeks (e.g., Tableau Desktop Specialist, Power BI Fundamentals).\nPractical Projects: Apply new skills through internal mock projects like building dashboards or writing Python scripts.\nTracking Progress: Regularly assess skill levels every month and update the heatmap to measure progress.\n\n\n\n\nThe skill gap analysis clearly highlights the team’s current strengths and opportunities for improvement. While foundational skills like SQL, Python, and Excel are relatively well developed, enterprise tools like SAP, Tableau, and Power BI remain significant blind spots.\nBy following the improvement plan and encouraging structured learning, the team will not only close existing gaps but also align with modern IT and data industry expectations. This proactive approach will make the team more versatile, industry-relevant, and ready for advanced career opportunities."
  },
  {
    "objectID": "skill_gap_analysis.html#team-skill-level-data",
    "href": "skill_gap_analysis.html#team-skill-level-data",
    "title": "Skill Gap Analysis",
    "section": "",
    "text": "Code\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\n\n# Load dataset\ncsv_path = 'region_analysis/lightcast_job_postings.csv'\ndf = pd.read_csv(csv_path)\n\n# Drop unnecessary columns\ncolumns_to_drop = [\n    \"ID\", \"URL\", \"ACTIVE_URLS\", \"DUPLICATES\", \"LAST_UPDATED_TIMESTAMP\",\n    \"NAICS2\", \"NAICS3\", \"NAICS4\", \"NAICS5\", \"NAICS6\",\n    \"SOC_2\", \"SOC_3\", \"SOC_5\"\n]\ndf.drop(columns=columns_to_drop, inplace=True)\n\n# Drop columns with &gt;50% missing\ndf.dropna(thresh=len(df) * 0.5, axis=1, inplace=True)\n\n# Fill missing values\nfor col in df.select_dtypes(include=[np.number]):\n    df[col].fillna(df[col].median(), inplace=True)\n\nfor col in df.select_dtypes(include=['object']):\n    df[col].fillna(\"Unknown\", inplace=True)\n\n# Drop duplicates\ndf.drop_duplicates(subset=[\"TITLE\", \"COMPANY\", \"LOCATION\", \"POSTED\"], keep=\"first\", inplace=True)"
  },
  {
    "objectID": "skill_gap_analysis.html#top-5-and-top-8-software-skills-from-job-postings",
    "href": "skill_gap_analysis.html#top-5-and-top-8-software-skills-from-job-postings",
    "title": "Skill Gap Analysis",
    "section": "",
    "text": "Code\n# Get top software skills from job postings\nsoftware_skills = (\n    df['SOFTWARE_SKILLS_NAME']\n    .dropna()\n    .str.replace(r'[\\[\\]\\n]', '', regex=True)  # Remove brackets and newlines\n    .str.split(',')\n    .explode()\n    .str.strip()\n)\n\n# Filter out empty strings\nsoftware_skills = software_skills[software_skills != '']\n\n# Get top 5 most frequent software skills\ntop_5_software_skills = software_skills.value_counts().head(5)\n\n# Extract skill names\ntop_5_skills = top_5_software_skills.index.tolist()\n\nprint(\"Top 5 software skills from job postings:\")\nprint(top_5_software_skills)\n\n# Get top 8 most frequent software skills\ntop_8_software_skills = software_skills.value_counts().head(8)\n\n# Extract skill names\ntop_8_skills = top_8_software_skills.index.tolist()\n\nprint(\"Top 8 software skills from job postings:\")\nprint(top_8_software_skills)\n\n\nTop 5 software skills from job postings:\nSOFTWARE_SKILLS_NAME\n\"SQL (Programming Language)\"       20744\n\"Microsoft Excel\"                  12262\n\"Python (Programming Language)\"    11626\n\"SAP Applications\"                 11554\n\"Dashboard\"                        11373\nName: count, dtype: int64\nTop 8 software skills from job postings:\nSOFTWARE_SKILLS_NAME\n\"SQL (Programming Language)\"                  20744\n\"Microsoft Excel\"                             12262\n\"Python (Programming Language)\"               11626\n\"SAP Applications\"                            11554\n\"Dashboard\"                                   11373\n\"Tableau (Business Intelligence Software)\"    11220\n\"Power BI\"                                    10369\n\"Microsoft Office\"                             7238\nName: count, dtype: int64\n\n\n\n\nCode\nimport pandas as pd\n\n# Define team skill levels (Proficiency scale: 1=Beginner, 5=Expert)\nskills_data = {\n    \"Name\": [\"Shreya\", \"An Ly\", \"Advait\", \"Ritusri\"],\n    \"SQL (Programming Language)\": [3, 2, 2, 3],\n    \"Microsoft Excel\": [4, 3, 3, 4],\n    \"Python (Programming Language)\": [3, 3, 3, 3],\n    \"SAP Applications\": [2, 1, 3, 2],\n    \"Dashboard\": [2, 2, 3, 4]\n}\n\ndf_skills = pd.DataFrame(skills_data)\ndf_skills.set_index(\"Name\", inplace=True)\ndf_skills\n\n\n\n\n\n\n\n\n\nSQL (Programming Language)\nMicrosoft Excel\nPython (Programming Language)\nSAP Applications\nDashboard\n\n\nName\n\n\n\n\n\n\n\n\n\nShreya\n3\n4\n3\n2\n2\n\n\nAn Ly\n2\n3\n3\n1\n2\n\n\nAdvait\n2\n3\n3\n3\n3\n\n\nRitusri\n3\n4\n3\n2\n4\n\n\n\n\n\n\n\n\n\nCode\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Team skills for top 5\nskills_data_top5 = {\n    \"Name\": [\"Shreya\", \"An Ly\", \"Advait\", \"Ritusri\"],\n    \"SQL (Programming Language)\": [3, 2, 2, 3],\n    \"Microsoft Excel\": [4, 3, 3, 4],\n    \"Python (Programming Language)\": [3, 3, 3, 3],\n    \"SAP Applications\": [2, 1, 3, 2],\n    \"Dashboard\": [2, 2, 3, 4]\n}\n\ndf_skills_top5 = pd.DataFrame(skills_data_top5).set_index(\"Name\")\n\n# Plot Heatmap 1\nplt.figure(figsize=(10, 5))\nsns.heatmap(df_skills_top5, annot=True, cmap=\"YlOrBr\", linewidths=0.5)\nplt.title(\"Team Skill Levels – Top 5 Software Skills\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\nimport pandas as pd\n\n# Define team skill levels (Proficiency scale: 1=Beginner, 5=Expert)\nskills_data1 = {\n    \"Name\": [\"Shreya\", \"An Ly\", \"Advait\", \"Ritusri\"],\n    \"SQL (Programming Language)\": [3, 2, 2, 3],\n    \"Microsoft Excel\": [4, 3, 3, 4],\n    \"Python (Programming Language)\": [3, 3, 3, 3],\n    \"SAP Applications\": [2, 1, 3, 2],\n    \"Dashboard\": [2, 2, 3, 4],\n    \"Tableau (Business Intelligence Software)\":[0, 0, 0, 0],\n    \"Power BI\":[0, 0, 0, 0],\n    \"Microsoft Office\":[0, 0, 0, 0],\n    \n}\n\ndf_skills1 = pd.DataFrame(skills_data1)\ndf_skills1.set_index(\"Name\", inplace=True)\ndf_skills1\n\n\n\n\n\n\n\n\n\nSQL (Programming Language)\nMicrosoft Excel\nPython (Programming Language)\nSAP Applications\nDashboard\nTableau (Business Intelligence Software)\nPower BI\nMicrosoft Office\n\n\nName\n\n\n\n\n\n\n\n\n\n\n\n\nShreya\n3\n4\n3\n2\n2\n0\n0\n0\n\n\nAn Ly\n2\n3\n3\n1\n2\n0\n0\n0\n\n\nAdvait\n2\n3\n3\n3\n3\n0\n0\n0\n\n\nRitusri\n3\n4\n3\n2\n4\n0\n0\n0\n\n\n\n\n\n\n\n\n\nCode\nimport pandas as pd\n\n# Define team skill levels (Proficiency scale: 1=Beginner, 5=Expert)\nskills_data1 = {\n    \"Name\": [\"Shreya\", \"An Ly\", \"Advait\", \"Ritusri\"],\n    \"SQL (Programming Language)\": [3, 2, 2, 3],\n    \"Microsoft Excel\": [4, 3, 3, 4],\n    \"Python (Programming Language)\": [3, 3, 3, 3],\n    \"SAP Applications\": [2, 1, 3, 2],\n    \"Dashboard\": [2, 2, 3, 4],\n    \"Tableau (Business Intelligence Software)\":[0, 0, 0, 0],\n    \"Power BI\":[0, 0, 0, 0],\n    \"Microsoft Office\":[0, 0, 0, 0],\n    \n}\ndf_skills_top8 = pd.DataFrame(skills_data1).set_index(\"Name\")\n\n# Plot Heatmap 2\nplt.figure(figsize=(10, 5))\nsns.heatmap(df_skills_top8, annot=True, cmap=\"YlOrBr\", linewidths=0.5)\nplt.title(\"Team Skill Levels – Top 8 Software Skills\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nThe heatmap analysis indicates that while the team has solid grounding in fundamental IT tools, there are significant gaps in certain enterprise and visualization technologies that are highly demanded in job postings. Addressing these gaps will elevate the team’s capabilities and make them more market-ready.\nSQL (Programming Language) Although the team has intermediate proficiency in SQL, moving towards expert-level understanding is essential. SQL remains one of the most requested skills across IT and data-centric roles. Advanced topics like complex joins, window functions, performance tuning, and writing optimized queries should be covered. Recommended resources include Coursera’s SQL for Data Science and DataCamp SQL Career Track.\nPython (Programming Language) Python is the cornerstone of automation, analytics, and machine learning. The team should focus on advancing their skills beyond basic scripting. This includes learning about data manipulation (Pandas), building small projects, and exploring libraries used in data science or automation. Free resources like the Google Python Crash Course and the IBM Python for Data Science (Coursera) can be leveraged.\nSAP Applications SAP is currently one of the weakest areas within the team. Enterprise software skills like SAP are critical in corporate environments. Team members should target introductory SAP courses to gain a basic understanding of navigation, reporting, and common SAP modules. Free options like OpenSAP are recommended to start with.\nDashboarding Tools (Power BI / Tableau) Visual storytelling and data presentation are crucial skills in modern IT roles. As seen in the analysis, there is little to no current exposure to Power BI and Tableau. Training should start with beginner-friendly courses that teach how to create interactive dashboards and perform basic data analysis. Tableau Public and Microsoft Learn for Power BI offer excellent free resources.\nMicrosoft Excel While the team is relatively advanced in Excel, moving towards expert proficiency will unlock greater efficiencies. Topics like VBA macros, Power Query, pivot tables, and advanced formulas should be prioritized. Recommended platforms include LinkedIn Learning and Excel Skills for Business (Coursera).\nTableau, Power BI, and Microsoft Office (Missing Skills) The missing ratings for Tableau, Power BI, and Microsoft Office indicate complete lack of knowledge. These tools are essential for reporting, business communication, and project collaboration in IT environments. Each team member should aim to reach at least intermediate level proficiency through self-paced courses and hands-on practice.\n\n\nTo close these gaps systematically:\nWeekly Learning Sessions: Rotate weekly responsibilities where each member shares what they learned about a specific skill.\nPair Learning: Pair up team members with stronger skills (e.g., SQL, Python) to support others.\nMicro-Certifications: Encourage completion of short certifications within 4–6 weeks (e.g., Tableau Desktop Specialist, Power BI Fundamentals).\nPractical Projects: Apply new skills through internal mock projects like building dashboards or writing Python scripts.\nTracking Progress: Regularly assess skill levels every month and update the heatmap to measure progress.\n\n\n\n\nThe skill gap analysis clearly highlights the team’s current strengths and opportunities for improvement. While foundational skills like SQL, Python, and Excel are relatively well developed, enterprise tools like SAP, Tableau, and Power BI remain significant blind spots.\nBy following the improvement plan and encouraging structured learning, the team will not only close existing gaps but also align with modern IT and data industry expectations. This proactive approach will make the team more versatile, industry-relevant, and ready for advanced career opportunities."
  },
  {
    "objectID": "nlp_method.html",
    "href": "nlp_method.html",
    "title": "Introduction",
    "section": "",
    "text": "Introduction\nIn this project, we used Natural Language Processing (NLP) to extract required skills from job postings based on their description text in the BODY column. The dataset contains job postings with unstructured text descriptions, which often mention skills needed for the role (e.g., “analyze data” or “develop software”). Our goal was to identify and analyze the most common skills mentioned in these postings, providing insights into the skills most in demand. This analysis can help job seekers understand the key skills to develop and assist employers in identifying trends in skill requirements.\n\n\nData Preprocessing\nWe started by loading the dataset and focusing on the BODY column, which contains the job description text. The BODY text is unstructured and requires preprocessing for NLP analysis. We performed the following steps:\nTokenization and Cleaning: Converted the text to lowercase, removed punctuation, and tokenized the text into words.\nStop Word Removal: Removed common stop words (e.g., “the”, “is”) that don’t add meaningful information. We used a predefined list of common stop words to avoid external dependencies.\nSkill Extraction: Defined a list of common skills relevant to job postings (e.g., “data analysis,” “software development”) and searched for these skills in the cleaned text. For simplicity, we used keyword matching to identify skills, but this could be extended with more advanced NLP techniques like named entity recognition (NER) or pre-trained models.\nSince this task is exploratory and doesn’t require a target variable, we didn’t split the data into training and testing sets. Instead, we processed all available job descriptions to extract and analyze skills.\nHere’s the Python code we used for data preprocessing and skill extraction:\n\n\nCode\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport re\nfrom collections import Counter\n\n# Load dataset\ncsv_path = 'region_analysis/lightcast_job_postings.csv'\ndf = pd.read_csv(csv_path)\n\n# Drop rows with missing job descriptions\ndf = df.dropna(subset=['BODY'])\n\n# Define stop words\nstop_words = {\n    'a', 'an', 'and', 'are', 'as', 'at', 'be', 'by', 'for', 'from', 'has', 'he',\n    'in', 'is', 'it', 'its', 'of', 'on', 'that', 'the', 'to', 'was', 'were', 'will',\n    'with', 'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your',\n    'yours', 'yourself', 'yourselves', 'him', 'his', 'her', 'hers', 'herself', 'it',\n    'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which',\n    'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were',\n    'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing',\n    'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of',\n    'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during',\n    'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on',\n    'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when',\n    'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other',\n    'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very',\n    's', 't', 'can', 'will', 'just', 'don', 'should', 'now'\n}\n\n# Clean text\ndef clean_text(text):\n    text = text.lower()\n    text = re.sub(r'[^a-z\\s]', '', text)\n    tokens = text.split()\n    return ' '.join([word for word in tokens if word not in stop_words])\n\ndf['BODY_CLEANED'] = df['BODY'].apply(clean_text)\n\n# Define common skills\nskills_list = [\n    \"data analysis\", \"software development\", \"machine learning\",\n    \"project management\", \"communication\", \"teamwork\",\n    \"sql\", \"python\", \"modeling\", \"analytics\"\n]\n\n# Extract skills\ndef extract_skills(text):\n    found_skills = []\n    for skill in skills_list:\n        if skill in text:\n            found_skills.append(skill)\n    return found_skills\n\ndf['SKILLS'] = df['BODY_CLEANED'].apply(extract_skills)\n\n# Flatten skill list and count\nall_skills = [skill for sublist in df['SKILLS'] for skill in sublist]\nskill_counts = Counter(all_skills)\n\n\n\n# Visualize top skills\nplt.figure(figsize=(10, 6))\nif skill_counts:\n    skills, counts = zip(*sorted(skill_counts.items(), key=lambda x: x[1], reverse=True))\n    plt.bar(skills, counts, color='skyblue')\n    plt.xlabel('Skills')\n    plt.ylabel('Frequency')\n    plt.title('Most Common Skills in Job Postings')\n    plt.xticks(rotation=45, ha='right')\n    plt.tight_layout()\n    plt.savefig('skills_frequency.png')\n    plt.show()\nelse:\n    print(\"No skills were found in the job descriptions.\")\n\n\n\n\n\n\n\n\n\n\n\nSkill Analysis and Visualization\nAfter extracting skills from the job descriptions, we analyzed their frequency to identify the most common skills mentioned. We visualized the results using a bar plot, showing the count of each skill across all job postings. This helps highlight the skills that are most in demand based on the dataset.\nHere’s the code we used for analyzing and visualizing the skills:\n\n\nCode\n# Plot the most common skills\nplt.figure(figsize=(10, 6))\nskills, counts = zip(*skill_counts.items()) if skill_counts else ([], [])\nif counts:  # Ensure there are skills to plot\n    plt.bar(skills, counts, color='skyblue')\n    plt.xlabel('Skills')\n    plt.ylabel('Frequency')\n    plt.title('Most Common Skills in Job Postings')\n    plt.xticks(rotation=45, ha='right')\n    plt.tight_layout()\n    plt.savefig('skills_frequency.png')\nelse:\n    print(\"No skills were found in the job descriptions.\")"
  },
  {
    "objectID": "ML.html",
    "href": "ML.html",
    "title": "ML Methods",
    "section": "",
    "text": "In this machine learning project, I aimed to predict how long job postings remain active (i.e., their DURATION) using a Random Forest Regressor. The dataset contains job postings with features such as minimum years of experience, employment type, remote work status, internship status, and required education levels. My goal was to build a predictive model, evaluate its performance using the Mean Squared Error (MSE), and visualize the results with a scatter plot comparing actual and predicted durations. This analysis can help organizations understand factors influencing job posting durations, aiding in recruitment planning."
  },
  {
    "objectID": "ML.html#sample-of-preprocessed-education_levels",
    "href": "ML.html#sample-of-preprocessed-education_levels",
    "title": "ML Methods",
    "section": "2.1 Sample of preprocessed EDUCATION_LEVELS",
    "text": "2.1 Sample of preprocessed EDUCATION_LEVELS\n\n\nCode\n# Define function to parse MIN_EDULEVELS strings\ndef parse_education_levels(edu):\n    if isinstance(edu, (int, float)) and not np.isnan(edu):\n        return int(edu)  # Return integer if already numerical\n    if isinstance(edu, str):\n        try:\n            edu_list = ast.literal_eval(edu.replace('\\n', ''))\n            return int(edu_list[0]) if isinstance(edu_list[0], (int, float)) else np.nan\n        except (ValueError, SyntaxError, IndexError) as e:\n            print(f\"Parsing failed for: {edu}, Error: {e}\")\n            return np.nan\n    return np.nan\n\n# Select features and target\nfeatures = ['MIN_YEARS_EXPERIENCE', 'EMPLOYMENT_TYPE', 'REMOTE_TYPE', 'IS_INTERNSHIP', 'MIN_EDULEVELS']\ntarget = 'DURATION'\n\n# Check if all features and target exist\nmissing_cols = [col for col in features + [target] if col not in df.columns]\nif missing_cols:\n    print(f\"Missing columns: {missing_cols}\")\n    # If IS_INTERNSHIP is missing, remove it from features\n    if 'IS_INTERNSHIP' in missing_cols:\n        features.remove('IS_INTERNSHIP')\n    else:\n        raise ValueError(\"Required columns not found in dataset\")\n\n# Create a copy of the dataset with selected columns\ndf_subset = df[features + [target]].copy()\n\n# Parse MIN_EDULEVELS\ndf_subset['MIN_EDULEVELS'] = df_subset['MIN_EDULEVELS'].apply(parse_education_levels)\n\n# Handle missing values with imputation for all numerical columns\nnum_cols = [col for col in features if col in df_subset.columns]\nnum_imputer = SimpleImputer(strategy='median')\ndf_subset[num_cols] = num_imputer.fit_transform(df_subset[num_cols])\n\n# Impute DURATION with mean\ndf_subset['DURATION'] = df_subset['DURATION'].fillna(df_subset['DURATION'].mean())\n\n# Ensure IS_INTERNSHIP is integer if present\nif 'IS_INTERNSHIP' in df_subset.columns:\n    df_subset['IS_INTERNSHIP'] = df_subset['IS_INTERNSHIP'].astype(int)\n\n# Verify no missing values\nprint(f\"Missing values after imputation:\\n{df_subset.isnull().sum()}\")\nprint(f\"Preprocessed dataset size: {df_subset.shape}\")\n\n# Features and target\nX = df_subset[num_cols]\ny = df_subset['DURATION']\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nprint(\"Training set size:\", X_train.shape)\nprint(\"Testing set size:\", X_test.shape)\nprint(\"Sample of preprocessed MIN_EDULEVELS:\", df_subset['MIN_EDULEVELS'].head().tolist())\n\n\nMissing values after imputation:\nMIN_YEARS_EXPERIENCE    0\nEMPLOYMENT_TYPE         0\nREMOTE_TYPE             0\nIS_INTERNSHIP           0\nMIN_EDULEVELS           0\nDURATION                0\ndtype: int64\nPreprocessed dataset size: (72498, 6)\nTraining set size: (57998, 5)\nTesting set size: (14500, 5)\nSample of preprocessed MIN_EDULEVELS: [2.0, 99.0, 2.0, 99.0, 99.0]"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Job Market Analysis 2024",
    "section": "",
    "text": "Artificial Intelligence (AI) is no longer a niche field—it is a driving force behind economic transformation in 2024. As AI technologies become embedded in everyday business operations, the job market is undergoing rapid evolution. One of the most visible impacts is on compensation. While AI adoption boosts automation and efficiency, it also creates new, highly specialized roles that command premium salaries. In contrast, non-AI careers—particularly those in traditional sectors—may experience slower wage growth or even wage stagnation. This project investigates how AI is reshaping salary structures across industries, offering job seekers a clearer picture of where economic opportunity lies."
  },
  {
    "objectID": "index.html#why-is-this-topic-important",
    "href": "index.html#why-is-this-topic-important",
    "title": "Job Market Analysis 2024",
    "section": "",
    "text": "Artificial Intelligence (AI) is no longer a niche field—it is a driving force behind economic transformation in 2024. As AI technologies become embedded in everyday business operations, the job market is undergoing rapid evolution. One of the most visible impacts is on compensation. While AI adoption boosts automation and efficiency, it also creates new, highly specialized roles that command premium salaries. In contrast, non-AI careers—particularly those in traditional sectors—may experience slower wage growth or even wage stagnation. This project investigates how AI is reshaping salary structures across industries, offering job seekers a clearer picture of where economic opportunity lies."
  },
  {
    "objectID": "index.html#what-trends-make-this-a-crucial-area-of-study-in-2024",
    "href": "index.html#what-trends-make-this-a-crucial-area-of-study-in-2024",
    "title": "Job Market Analysis 2024",
    "section": "What trends make this a crucial area of study in 2024?",
    "text": "What trends make this a crucial area of study in 2024?\nThis topic is critical for understanding and navigating today’s labor market. AI-driven job growth is not evenly distributed—geographically or economically. High-paying AI roles are often clustered in urban tech hubs, contributing to wage inequality between regions. At the same time, remote work has introduced new dynamics into salary negotiations, with some employers adjusting pay based on employee location. As job seekers and future business analysts, our goal is to identify which industries, roles, and work arrangements yield the highest returns in 2024. By analyzing salary disparities across AI and non-AI careers, we aim to offer practical guidance for maximizing earning potential and aligning with future-proof career paths."
  },
  {
    "objectID": "index.html#what-do-you-expect-to-find-in-your-analysis",
    "href": "index.html#what-do-you-expect-to-find-in-your-analysis",
    "title": "Job Market Analysis 2024",
    "section": "What do you expect to find in your analysis?",
    "text": "What do you expect to find in your analysis?\nHow do salaries differ across AI vs. non-AI careers?\nWhat regions offer the highest-paying jobs in AI-related and traditional careers?\nAre remote jobs better paying than in-office roles?\nWhat industries saw the biggest wage growth in 2024?"
  },
  {
    "objectID": "eda_updation.html",
    "href": "eda_updation.html",
    "title": "Introduction",
    "section": "",
    "text": "Introduction\nThis EDA explores key characteristics of the job postings dataset, including salary distribution, industry representation, geographic trends, and temporal patterns. The analysis provides insights that guide downstream tasks such as skill gap analysis, clustering, and prediction.\n\n\nDataset Overview\n\n\nCode\nimport pandas as pd\n\ndf = pd.read_csv('region_analysis/lightcast_job_postings.csv')\ndf.info()\ndf.head()\n\n\nC:\\Users\\honga\\AppData\\Local\\Temp\\ipykernel_18024\\1554311625.py:3: DtypeWarning:\n\nColumns (19,30) have mixed types. Specify dtype option on import or set low_memory=False.\n\n\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 72498 entries, 0 to 72497\nColumns: 131 entries, ID to NAICS_2022_6_NAME\ndtypes: float64(38), object(93)\nmemory usage: 72.5+ MB\n\n\n\n\n\n\n\n\n\nID\nLAST_UPDATED_DATE\nLAST_UPDATED_TIMESTAMP\nDUPLICATES\nPOSTED\nEXPIRED\nDURATION\nSOURCE_TYPES\nSOURCES\nURL\n...\nNAICS_2022_2\nNAICS_2022_2_NAME\nNAICS_2022_3\nNAICS_2022_3_NAME\nNAICS_2022_4\nNAICS_2022_4_NAME\nNAICS_2022_5\nNAICS_2022_5_NAME\nNAICS_2022_6\nNAICS_2022_6_NAME\n\n\n\n\n0\n1f57d95acf4dc67ed2819eb12f049f6a5c11782c\n9/6/2024\n2024-09-06 20:32:57.352 Z\n0.0\n6/2/2024\n6/8/2024\n6.0\n[\\n \"Company\"\\n]\n[\\n \"brassring.com\"\\n]\n[\\n \"https://sjobs.brassring.com/TGnewUI/Sear...\n...\n44.0\nRetail Trade\n441.0\nMotor Vehicle and Parts Dealers\n4413.0\nAutomotive Parts, Accessories, and Tire Retailers\n44133.0\nAutomotive Parts and Accessories Retailers\n441330.0\nAutomotive Parts and Accessories Retailers\n\n\n1\n0cb072af26757b6c4ea9464472a50a443af681ac\n8/2/2024\n2024-08-02 17:08:58.838 Z\n0.0\n6/2/2024\n8/1/2024\nNaN\n[\\n \"Job Board\"\\n]\n[\\n \"maine.gov\"\\n]\n[\\n \"https://joblink.maine.gov/jobs/1085740\"\\n]\n...\n56.0\nAdministrative and Support and Waste Managemen...\n561.0\nAdministrative and Support Services\n5613.0\nEmployment Services\n56132.0\nTemporary Help Services\n561320.0\nTemporary Help Services\n\n\n2\n85318b12b3331fa490d32ad014379df01855c557\n9/6/2024\n2024-09-06 20:32:57.352 Z\n1.0\n6/2/2024\n7/7/2024\n35.0\n[\\n \"Job Board\"\\n]\n[\\n \"dejobs.org\"\\n]\n[\\n \"https://dejobs.org/dallas-tx/data-analys...\n...\n52.0\nFinance and Insurance\n524.0\nInsurance Carriers and Related Activities\n5242.0\nAgencies, Brokerages, and Other Insurance Rela...\n52429.0\nOther Insurance Related Activities\n524291.0\nClaims Adjusting\n\n\n3\n1b5c3941e54a1889ef4f8ae55b401a550708a310\n9/6/2024\n2024-09-06 20:32:57.352 Z\n1.0\n6/2/2024\n7/20/2024\n48.0\n[\\n \"Job Board\"\\n]\n[\\n \"disabledperson.com\",\\n \"dejobs.org\"\\n]\n[\\n \"https://www.disabledperson.com/jobs/5948...\n...\n52.0\nFinance and Insurance\n522.0\nCredit Intermediation and Related Activities\n5221.0\nDepository Credit Intermediation\n52211.0\nCommercial Banking\n522110.0\nCommercial Banking\n\n\n4\ncb5ca25f02bdf25c13edfede7931508bfd9e858f\n6/19/2024\n2024-06-19 07:00:00.000 Z\n0.0\n6/2/2024\n6/17/2024\n15.0\n[\\n \"FreeJobBoard\"\\n]\n[\\n \"craigslist.org\"\\n]\n[\\n \"https://modesto.craigslist.org/sls/77475...\n...\n99.0\nUnclassified Industry\n999.0\nUnclassified Industry\n9999.0\nUnclassified Industry\n99999.0\nUnclassified Industry\n999999.0\nUnclassified Industry\n\n\n\n\n5 rows × 131 columns\n\n\n\n\n\nHandling Missing Data\n\n\nCode\ndf.isnull().mean().sort_values(ascending=False).head(10)\n\n\nACTIVE_SOURCES_INFO       0.892163\nMAX_YEARS_EXPERIENCE      0.883721\nMAX_EDULEVELS_NAME        0.774959\nMAX_EDULEVELS             0.774959\nLIGHTCAST_SECTORS         0.754655\nLIGHTCAST_SECTORS_NAME    0.754655\nSALARY                    0.575050\nSALARY_FROM               0.553119\nSALARY_TO                 0.553119\nORIGINAL_PAY_PERIOD       0.553119\ndtype: float64\n\n\n\n\nSalary Distribution\n\n\nCode\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndf['SALARY'] = pd.to_numeric(df['SALARY'], errors='coerce')\nplt.figure(figsize=(10,6))\nsns.histplot(df['SALARY'], bins=50, kde=True)\nplt.title(\"Salary Distribution\")\nplt.xlabel(\"Salary ($)\")\nplt.ylabel(\"Frequency\")\nplt.xlim(0, 300000)\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nTop 10 Job Titles\n\n\nCode\ndf['TITLE_NAME'].value_counts().head(10)\n\n\nTITLE_NAME\nData Analysts                     8591\nUnclassified                      3149\nBusiness Intelligence Analysts    2072\nEnterprise Architects             1999\nOracle Cloud HCM Consultants      1042\nData Modelers                      668\nData Governance Analysts           628\nData Analytics Engineers           537\nERP Business Analysts              488\nData Quality Analysts              467\nName: count, dtype: int64\n\n\n\n\nTop 10 Industries\n\n\nCode\ndf['NAICS_2022_2_NAME'].value_counts().head(10)\n\n\nNAICS_2022_2_NAME\nProfessional, Scientific, and Technical Services                            23315\nUnclassified Industry                                                        9488\nAdministrative and Support and Waste Management and Remediation Services     8628\nFinance and Insurance                                                        7342\nManufacturing                                                                4827\nInformation                                                                  3967\nHealth Care and Social Assistance                                            2877\nWholesale Trade                                                              2141\nEducational Services                                                         2004\nRetail Trade                                                                 1953\nName: count, dtype: int64\n\n\n\n\nJob Postings by State\n\n\nCode\nstate_counts = df['STATE_NAME'].value_counts().head(15)\nstate_counts.plot(kind='barh', figsize=(10,6), color='steelblue')\nplt.title(\"Top 15 States by Job Postings\")\nplt.xlabel(\"Number of Postings\")\nplt.gca().invert_yaxis()\nplt.grid(True, linestyle='--', alpha=0.5)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nPosting Trends Over Time\n\n\nCode\ndf['POSTED'] = pd.to_datetime(df['POSTED'], errors='coerce')\ndf['POSTED'].dt.to_period('M').value_counts().sort_index().plot(kind='line', figsize=(12,6))\nplt.title(\"Job Postings Over Time\")\nplt.ylabel(\"Number of Postings\")\nplt.xlabel(\"Month\")\nplt.grid(True, alpha=0.5)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\nprint(df.columns.tolist())\n\n\n['ID', 'LAST_UPDATED_DATE', 'LAST_UPDATED_TIMESTAMP', 'DUPLICATES', 'POSTED', 'EXPIRED', 'DURATION', 'SOURCE_TYPES', 'SOURCES', 'URL', 'ACTIVE_URLS', 'ACTIVE_SOURCES_INFO', 'TITLE_RAW', 'BODY', 'MODELED_EXPIRED', 'MODELED_DURATION', 'COMPANY', 'COMPANY_NAME', 'COMPANY_RAW', 'COMPANY_IS_STAFFING', 'EDUCATION_LEVELS', 'EDUCATION_LEVELS_NAME', 'MIN_EDULEVELS', 'MIN_EDULEVELS_NAME', 'MAX_EDULEVELS', 'MAX_EDULEVELS_NAME', 'EMPLOYMENT_TYPE', 'EMPLOYMENT_TYPE_NAME', 'MIN_YEARS_EXPERIENCE', 'MAX_YEARS_EXPERIENCE', 'IS_INTERNSHIP', 'SALARY', 'REMOTE_TYPE', 'REMOTE_TYPE_NAME', 'ORIGINAL_PAY_PERIOD', 'SALARY_TO', 'SALARY_FROM', 'LOCATION', 'CITY', 'CITY_NAME', 'COUNTY', 'COUNTY_NAME', 'MSA', 'MSA_NAME', 'STATE', 'STATE_NAME', 'COUNTY_OUTGOING', 'COUNTY_NAME_OUTGOING', 'COUNTY_INCOMING', 'COUNTY_NAME_INCOMING', 'MSA_OUTGOING', 'MSA_NAME_OUTGOING', 'MSA_INCOMING', 'MSA_NAME_INCOMING', 'NAICS2', 'NAICS2_NAME', 'NAICS3', 'NAICS3_NAME', 'NAICS4', 'NAICS4_NAME', 'NAICS5', 'NAICS5_NAME', 'NAICS6', 'NAICS6_NAME', 'TITLE', 'TITLE_NAME', 'TITLE_CLEAN', 'SKILLS', 'SKILLS_NAME', 'SPECIALIZED_SKILLS', 'SPECIALIZED_SKILLS_NAME', 'CERTIFICATIONS', 'CERTIFICATIONS_NAME', 'COMMON_SKILLS', 'COMMON_SKILLS_NAME', 'SOFTWARE_SKILLS', 'SOFTWARE_SKILLS_NAME', 'ONET', 'ONET_NAME', 'ONET_2019', 'ONET_2019_NAME', 'CIP6', 'CIP6_NAME', 'CIP4', 'CIP4_NAME', 'CIP2', 'CIP2_NAME', 'SOC_2021_2', 'SOC_2021_2_NAME', 'SOC_2021_3', 'SOC_2021_3_NAME', 'SOC_2021_4', 'SOC_2021_4_NAME', 'SOC_2021_5', 'SOC_2021_5_NAME', 'LOT_CAREER_AREA', 'LOT_CAREER_AREA_NAME', 'LOT_OCCUPATION', 'LOT_OCCUPATION_NAME', 'LOT_SPECIALIZED_OCCUPATION', 'LOT_SPECIALIZED_OCCUPATION_NAME', 'LOT_OCCUPATION_GROUP', 'LOT_OCCUPATION_GROUP_NAME', 'LOT_V6_SPECIALIZED_OCCUPATION', 'LOT_V6_SPECIALIZED_OCCUPATION_NAME', 'LOT_V6_OCCUPATION', 'LOT_V6_OCCUPATION_NAME', 'LOT_V6_OCCUPATION_GROUP', 'LOT_V6_OCCUPATION_GROUP_NAME', 'LOT_V6_CAREER_AREA', 'LOT_V6_CAREER_AREA_NAME', 'SOC_2', 'SOC_2_NAME', 'SOC_3', 'SOC_3_NAME', 'SOC_4', 'SOC_4_NAME', 'SOC_5', 'SOC_5_NAME', 'LIGHTCAST_SECTORS', 'LIGHTCAST_SECTORS_NAME', 'NAICS_2022_2', 'NAICS_2022_2_NAME', 'NAICS_2022_3', 'NAICS_2022_3_NAME', 'NAICS_2022_4', 'NAICS_2022_4_NAME', 'NAICS_2022_5', 'NAICS_2022_5_NAME', 'NAICS_2022_6', 'NAICS_2022_6_NAME']"
  },
  {
    "objectID": "Data/Salaries Differ Across AI vs. Non-AI Careers .html",
    "href": "Data/Salaries Differ Across AI vs. Non-AI Careers .html",
    "title": "Job Market Analysis 2024",
    "section": "",
    "text": "Code\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport statsmodels.api as sm\nimport os\n\n\n\n\nCode\n\ndf = pd.read_csv('lightcast_job_postings.csv', low_memory=False)\n\ndf.head(10)\n\n\n\n\n\n\n\n\n\nID\nLAST_UPDATED_DATE\nLAST_UPDATED_TIMESTAMP\nDUPLICATES\nPOSTED\nEXPIRED\nDURATION\nSOURCE_TYPES\nSOURCES\nURL\n...\nNAICS_2022_2\nNAICS_2022_2_NAME\nNAICS_2022_3\nNAICS_2022_3_NAME\nNAICS_2022_4\nNAICS_2022_4_NAME\nNAICS_2022_5\nNAICS_2022_5_NAME\nNAICS_2022_6\nNAICS_2022_6_NAME\n\n\n\n\n0\n1f57d95acf4dc67ed2819eb12f049f6a5c11782c\n9/6/2024\n2024-09-06 20:32:57.352 Z\n0.0\n6/2/2024\n6/8/2024\n6.0\n[\\n \"Company\"\\n]\n[\\n \"brassring.com\"\\n]\n[\\n \"https://sjobs.brassring.com/TGnewUI/Sear...\n...\n44.0\nRetail Trade\n441.0\nMotor Vehicle and Parts Dealers\n4413.0\nAutomotive Parts, Accessories, and Tire Retailers\n44133.0\nAutomotive Parts and Accessories Retailers\n441330.0\nAutomotive Parts and Accessories Retailers\n\n\n1\n0cb072af26757b6c4ea9464472a50a443af681ac\n8/2/2024\n2024-08-02 17:08:58.838 Z\n0.0\n6/2/2024\n8/1/2024\nNaN\n[\\n \"Job Board\"\\n]\n[\\n \"maine.gov\"\\n]\n[\\n \"https://joblink.maine.gov/jobs/1085740\"\\n]\n...\n56.0\nAdministrative and Support and Waste Managemen...\n561.0\nAdministrative and Support Services\n5613.0\nEmployment Services\n56132.0\nTemporary Help Services\n561320.0\nTemporary Help Services\n\n\n2\n85318b12b3331fa490d32ad014379df01855c557\n9/6/2024\n2024-09-06 20:32:57.352 Z\n1.0\n6/2/2024\n7/7/2024\n35.0\n[\\n \"Job Board\"\\n]\n[\\n \"dejobs.org\"\\n]\n[\\n \"https://dejobs.org/dallas-tx/data-analys...\n...\n52.0\nFinance and Insurance\n524.0\nInsurance Carriers and Related Activities\n5242.0\nAgencies, Brokerages, and Other Insurance Rela...\n52429.0\nOther Insurance Related Activities\n524291.0\nClaims Adjusting\n\n\n3\n1b5c3941e54a1889ef4f8ae55b401a550708a310\n9/6/2024\n2024-09-06 20:32:57.352 Z\n1.0\n6/2/2024\n7/20/2024\n48.0\n[\\n \"Job Board\"\\n]\n[\\n \"disabledperson.com\",\\n \"dejobs.org\"\\n]\n[\\n \"https://www.disabledperson.com/jobs/5948...\n...\n52.0\nFinance and Insurance\n522.0\nCredit Intermediation and Related Activities\n5221.0\nDepository Credit Intermediation\n52211.0\nCommercial Banking\n522110.0\nCommercial Banking\n\n\n4\ncb5ca25f02bdf25c13edfede7931508bfd9e858f\n6/19/2024\n2024-06-19 07:00:00.000 Z\n0.0\n6/2/2024\n6/17/2024\n15.0\n[\\n \"FreeJobBoard\"\\n]\n[\\n \"craigslist.org\"\\n]\n[\\n \"https://modesto.craigslist.org/sls/77475...\n...\n99.0\nUnclassified Industry\n999.0\nUnclassified Industry\n9999.0\nUnclassified Industry\n99999.0\nUnclassified Industry\n999999.0\nUnclassified Industry\n\n\n5\n35a6cd2183d9fb270e3f504b270f36d43cb759a6\n9/6/2024\n2024-09-06 20:32:57.352 Z\n0.0\n6/2/2024\n6/12/2024\n10.0\n[\\n \"Job Board\"\\n]\n[\\n \"dejobs.org\"\\n]\n[\\n \"https://dejobs.org/little-rock-ar/sr-lea...\n...\n51.0\nInformation\n517.0\nTelecommunications\n5178.0\nAll Other Telecommunications\n51781.0\nAll Other Telecommunications\n517810.0\nAll Other Telecommunications\n\n\n6\n06de8d192f30b1d8d3c575d453faf143d332f4d4\n8/2/2024\n2024-08-02 17:08:58.838 Z\n0.0\n6/2/2024\n8/1/2024\nNaN\n[\\n \"Company\"\\n]\n[\\n \"oraclecloud.com\"\\n]\n[\\n \"https://hctz.fa.us2.oraclecloud.com/hcmU...\n...\n31.0\nManufacturing\n334.0\nComputer and Electronic Product Manufacturing\n3344.0\nSemiconductor and Other Electronic Component M...\n33441.0\nSemiconductor and Other Electronic Component M...\n334413.0\nSemiconductor and Related Device Manufacturing\n\n\n7\n3d589c9d84677ca9468a5bc82295456e0ce6b13f\n9/6/2024\n2024-09-06 20:32:57.352 Z\n1.0\n6/2/2024\n7/7/2024\n35.0\n[\\n \"Job Board\"\\n]\n[\\n \"dejobs.org\"\\n]\n[\\n \"https://dejobs.org/dayton-oh/data-analys...\n...\n52.0\nFinance and Insurance\n524.0\nInsurance Carriers and Related Activities\n5242.0\nAgencies, Brokerages, and Other Insurance Rela...\n52429.0\nOther Insurance Related Activities\n524291.0\nClaims Adjusting\n\n\n8\n5a843df632e1ff756fa19d80a0871262d51becc0\n6/21/2024\n2024-06-21 07:00:00.000 Z\n0.0\n6/2/2024\n6/20/2024\n18.0\n[\\n \"Job Board\"\\n]\n[\\n \"computerwork.com\"\\n]\n[\\n \"http://computerwork.com/us/en/search-job...\n...\n99.0\nUnclassified Industry\n999.0\nUnclassified Industry\n9999.0\nUnclassified Industry\n99999.0\nUnclassified Industry\n999999.0\nUnclassified Industry\n\n\n9\n229620073766234e814e8add21db7dfaef69b3bd\n10/9/2024\n2024-10-09 18:07:44.758 Z\n0.0\n6/2/2024\n8/1/2024\nNaN\n[\\n \"Company\"\\n]\n[\\n \"3ds.com\"\\n]\n[\\n \"https://www.3ds.com/careers/jobs/sr-mark...\n...\n54.0\nProfessional, Scientific, and Technical Services\n541.0\nProfessional, Scientific, and Technical Services\n5415.0\nComputer Systems Design and Related Services\n54151.0\nComputer Systems Design and Related Services\n541511.0\nCustom Computer Programming Services\n\n\n\n\n10 rows × 131 columns\n\n\n\n\n\nCode\n# Check all columns in your dataset\nprint(df.columns.tolist())\n\n\n['ID', 'LAST_UPDATED_DATE', 'LAST_UPDATED_TIMESTAMP', 'DUPLICATES', 'POSTED', 'EXPIRED', 'DURATION', 'SOURCE_TYPES', 'SOURCES', 'URL', 'ACTIVE_URLS', 'ACTIVE_SOURCES_INFO', 'TITLE_RAW', 'BODY', 'MODELED_EXPIRED', 'MODELED_DURATION', 'COMPANY', 'COMPANY_NAME', 'COMPANY_RAW', 'COMPANY_IS_STAFFING', 'EDUCATION_LEVELS', 'EDUCATION_LEVELS_NAME', 'MIN_EDULEVELS', 'MIN_EDULEVELS_NAME', 'MAX_EDULEVELS', 'MAX_EDULEVELS_NAME', 'EMPLOYMENT_TYPE', 'EMPLOYMENT_TYPE_NAME', 'MIN_YEARS_EXPERIENCE', 'MAX_YEARS_EXPERIENCE', 'IS_INTERNSHIP', 'SALARY', 'REMOTE_TYPE', 'REMOTE_TYPE_NAME', 'ORIGINAL_PAY_PERIOD', 'SALARY_TO', 'SALARY_FROM', 'LOCATION', 'CITY', 'CITY_NAME', 'COUNTY', 'COUNTY_NAME', 'MSA', 'MSA_NAME', 'STATE', 'STATE_NAME', 'COUNTY_OUTGOING', 'COUNTY_NAME_OUTGOING', 'COUNTY_INCOMING', 'COUNTY_NAME_INCOMING', 'MSA_OUTGOING', 'MSA_NAME_OUTGOING', 'MSA_INCOMING', 'MSA_NAME_INCOMING', 'NAICS2', 'NAICS2_NAME', 'NAICS3', 'NAICS3_NAME', 'NAICS4', 'NAICS4_NAME', 'NAICS5', 'NAICS5_NAME', 'NAICS6', 'NAICS6_NAME', 'TITLE', 'TITLE_NAME', 'TITLE_CLEAN', 'SKILLS', 'SKILLS_NAME', 'SPECIALIZED_SKILLS', 'SPECIALIZED_SKILLS_NAME', 'CERTIFICATIONS', 'CERTIFICATIONS_NAME', 'COMMON_SKILLS', 'COMMON_SKILLS_NAME', 'SOFTWARE_SKILLS', 'SOFTWARE_SKILLS_NAME', 'ONET', 'ONET_NAME', 'ONET_2019', 'ONET_2019_NAME', 'CIP6', 'CIP6_NAME', 'CIP4', 'CIP4_NAME', 'CIP2', 'CIP2_NAME', 'SOC_2021_2', 'SOC_2021_2_NAME', 'SOC_2021_3', 'SOC_2021_3_NAME', 'SOC_2021_4', 'SOC_2021_4_NAME', 'SOC_2021_5', 'SOC_2021_5_NAME', 'LOT_CAREER_AREA', 'LOT_CAREER_AREA_NAME', 'LOT_OCCUPATION', 'LOT_OCCUPATION_NAME', 'LOT_SPECIALIZED_OCCUPATION', 'LOT_SPECIALIZED_OCCUPATION_NAME', 'LOT_OCCUPATION_GROUP', 'LOT_OCCUPATION_GROUP_NAME', 'LOT_V6_SPECIALIZED_OCCUPATION', 'LOT_V6_SPECIALIZED_OCCUPATION_NAME', 'LOT_V6_OCCUPATION', 'LOT_V6_OCCUPATION_NAME', 'LOT_V6_OCCUPATION_GROUP', 'LOT_V6_OCCUPATION_GROUP_NAME', 'LOT_V6_CAREER_AREA', 'LOT_V6_CAREER_AREA_NAME', 'SOC_2', 'SOC_2_NAME', 'SOC_3', 'SOC_3_NAME', 'SOC_4', 'SOC_4_NAME', 'SOC_5', 'SOC_5_NAME', 'LIGHTCAST_SECTORS', 'LIGHTCAST_SECTORS_NAME', 'NAICS_2022_2', 'NAICS_2022_2_NAME', 'NAICS_2022_3', 'NAICS_2022_3_NAME', 'NAICS_2022_4', 'NAICS_2022_4_NAME', 'NAICS_2022_5', 'NAICS_2022_5_NAME', 'NAICS_2022_6', 'NAICS_2022_6_NAME']\n\n\n\n\nCode\ndf = df.copy()\ndf['SALARY'] = pd.to_numeric(df['SALARY'], errors='coerce')\n\ndef tag_ai(row):\n    title = str(row['TITLE_NAME']).lower()\n    industry = str(row['NAICS_2022_2_NAME']).lower()\n    \n    if ('ai' in title or \n        'artificial intelligence' in title or \n        'machine learning' in title or \n        'data scientist' in title or \n        'deep learning' in title or\n        'nlp' in title or\n        'computer vision' in title or\n        'robotics' in title or\n        'ml' in title or\n        'data engineer' in title or\n        'ml engineer' in title or\n        'scientist' in title or\n        ('professional, scientific, and technical services' in industry) or\n        ('information' in industry)):  \n        return 'AI Career'\n    else:\n        return 'Non-AI Career'\n\ndf['Career_Type'] = df.apply(tag_ai, axis=1)\n\nprint(df['Career_Type'].value_counts())\n\n\nCareer_Type\nNon-AI Career    44188\nAI Career        28310\nName: count, dtype: int64\n\n\n\n\nCode\noutput_dir = 'DATA'\nif not os.path.exists(output_dir):\n    os.makedirs(output_dir)\n\n\n\n\nCode\ndf_salary = df.dropna(subset=['SALARY'])\n\nplt.figure(figsize=(10,6))\ndf_salary.boxplot(column='SALARY', by='Career_Type')\nplt.title('Salary Comparison: AI vs Non-AI Careers')\nplt.suptitle('')  # remove default matplotlib subtitle\nplt.xlabel('Career Type')\nplt.ylabel('Salary ($)')\nplt.grid(True)\n\nplot_path = os.path.join(output_dir, 'ai_vs_nonai_salary_comparison.png')\nplt.savefig(plot_path, dpi=300, bbox_inches='tight')\n\n\nplt.show()\n\n\n&lt;Figure size 1000x600 with 0 Axes&gt;\n\n\n\n\n\n\n\n\n\n\n\nCode\ndf['SALARY'] = pd.to_numeric(df['SALARY'], errors='coerce')\n\ndef tag_ai(row):\n    title = str(row['TITLE_NAME']).lower()\n    industry = str(row['NAICS_2022_2_NAME']).lower()\n    \n    if ('ai' in title or \n        'artificial intelligence' in title or \n        'machine learning' in title or \n        'data scientist' in title or \n        'deep learning' in title or\n        'nlp' in title or\n        'computer vision' in title or\n        'robotics' in title or\n        'ml' in title or\n        'data engineer' in title or\n        'ml engineer' in title or\n        'scientist' in title or\n        ('professional, scientific, and technical services' in industry) or\n        ('information' in industry)):\n        return 'AI Career'\n    else:\n        return 'Non-AI Career'\n\ndf['Career_Type'] = df.apply(tag_ai, axis=1)\n\ndf_salary = df.dropna(subset=['SALARY'])\n\nmean_salary_df = df_salary.groupby('Career_Type')['SALARY'].mean().round(2).reset_index()\nmean_salary_df.columns = ['Career_Type', 'Mean_Salary ($)']\nmean_salary_df\n\n\n\n\n\n\n\n\n\nCareer_Type\nMean_Salary ($)\n\n\n\n\n0\nAI Career\n133344.66\n\n\n1\nNon-AI Career\n108512.87\n\n\n\n\n\n\n\n\n\nCode\ndf['SALARY'] = pd.to_numeric(df['SALARY'], errors='coerce')\n\n# Drop rows with missing salary\ndf_salary = df.dropna(subset=['SALARY'])\n\n# Group by career type and compute all key stats\nsummary_stats = df_salary.groupby('Career_Type')['SALARY'].agg(\n    count='count',\n    mean='mean',\n    median='median',\n    min='min',\n    max='max',\n    std='std'\n).round(2)\n\n# Rename columns for display\nsummary_stats = summary_stats.rename(columns={\n    'count': 'Valid Salary Entries',\n    'mean': 'Mean Salary ($)',\n    'median': 'Median Salary ($)',\n    'min': 'Minimum Salary ($)',\n    'max': 'Maximum Salary ($)',\n    'std': 'Standard Deviation ($)'\n})\n\n# Add total job counts manually (from earlier classification)\nsummary_stats['Job Postings Count'] = [28310 if i == 'AI Career' else 44188 for i in summary_stats.index]\n\n# Reorder columns\nsummary_stats = summary_stats[['Job Postings Count', 'Valid Salary Entries', 'Mean Salary ($)',\n                               'Median Salary ($)', 'Minimum Salary ($)', 'Maximum Salary ($)',\n                               'Standard Deviation ($)']]\n\nsummary_stats_path = os.path.join(output_dir, 'ai_vs_nonai_salary_summary.csv')\nsummary_stats.to_csv(summary_stats_path)\n\n# Display the final table\nsummary_stats \n\n\n\n\n\n\n\n\n\n\nJob Postings Count\nValid Salary Entries\nMean Salary ($)\nMedian Salary ($)\nMinimum Salary ($)\nMaximum Salary ($)\nStandard Deviation ($)\n\n\nCareer_Type\n\n\n\n\n\n\n\n\n\n\n\nAI Career\n28310\n11713\n133344.66\n130500.0\n23585.0\n500000.0\n43401.01\n\n\nNon-AI Career\n44188\n19095\n108512.87\n102500.0\n15860.0\n500000.0\n43552.64\n\n\n\n\n\n\n\n\n\nCode\nimport matplotlib.pyplot as plt\n\n# Job count\njob_counts = {'AI Careers': 28310, 'Non-AI Careers': 44188}\n\n# Plot\nplt.figure(figsize=(8, 4))\nplt.barh(list(job_counts.keys()), list(job_counts.values()), color=['steelblue', 'gray'])\nplt.xlabel(\"Number of Job Postings\")\nplt.title(\"Distribution of AI vs. Non-AI Job Postings\")\nplt.grid(axis='x', linestyle='--', alpha=0.6)\nplt.tight_layout()\n\n# Save (optional)\nplt.savefig(\"DATA/job_distribution_bar_chart.png\", dpi=300, bbox_inches='tight')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\ndf['POSTED'] = pd.to_datetime(df['POSTED'], errors='coerce')\ndf['SALARY'] = pd.to_numeric(df['SALARY'], errors='coerce')\n\n# Define AI career tagging function\ndef tag_ai(row):\n    title = str(row['TITLE_NAME']).lower()\n    industry = str(row['NAICS_2022_2_NAME']).lower()\n    if ('ai' in title or 'artificial intelligence' in title or 'machine learning' in title or\n        'data scientist' in title or 'deep learning' in title or 'nlp' in title or\n        'computer vision' in title or 'robotics' in title or 'ml' in title or\n        'data engineer' in title or 'ml engineer' in title or 'scientist' in title or\n        'professional, scientific, and technical services' in industry or 'information' in industry):\n        return 'AI Career'\n    else:\n        return 'Non-AI Career'\n\ndf['Career_Type'] = df.apply(tag_ai, axis=1)\n\n# Forecast 1: Monthly job postings count (AI vs Non-AI)\ndf_valid = df.dropna(subset=['POSTED'])\nmonthly_counts = df_valid.groupby([df_valid['POSTED'].dt.to_period('M'), 'Career_Type']) \\\n                         .size().unstack().fillna(0)\nmonthly_counts.index = monthly_counts.index.to_timestamp()\n\n# Plot job posting trends\nplt.figure(figsize=(10, 5))\nmonthly_counts.plot(kind='line', marker='o', ax=plt.gca())\nplt.title(\"Monthly Job Postings: AI vs. Non-AI Careers\")\nplt.ylabel(\"Number of Postings\")\nplt.xlabel(\"Month\")\nplt.grid(True)\nplt.tight_layout()\njob_postings_path = \"DATA/monthly_job_postings_forecast.png\"\nplt.savefig(job_postings_path, dpi=300)\nplt.show()\n\n# Forecast 2: Average salary for AI jobs over time\ndf_ai = df[(df['Career_Type'] == 'AI Career') & (~df['SALARY'].isna())]\nmonthly_salary = df_ai.groupby(df_ai['POSTED'].dt.to_period('M'))['SALARY'].mean().dropna()\nmonthly_salary.index = monthly_salary.index.to_timestamp()\n\n# Build simple linear regression model for forecasting\nX = sm.add_constant(range(len(monthly_salary)))\ny = monthly_salary.values\nmodel = sm.OLS(y, X).fit()\n\n# Forecast next 6 months\nfuture_periods = 6\nfuture_X = sm.add_constant(range(len(monthly_salary), len(monthly_salary) + future_periods))\nforecast = model.predict(future_X)\n\n# Create future dates\nlast_date = monthly_salary.index[-1]\nfuture_dates = [last_date + pd.DateOffset(months=i+1) for i in range(future_periods)]\n\n# Plot actual and forecasted salaries\nplt.figure(figsize=(10, 5))\nplt.plot(monthly_salary.index, monthly_salary.values, marker='o', label='Historical Avg Salary (AI)')\nplt.plot(future_dates, forecast, marker='x', linestyle='--', label='Forecast (Next 6 Months)')\nplt.title(\"Forecast: Average AI Salary Over Time\")\nplt.ylabel(\"Salary ($)\")\nplt.xlabel(\"Month\")\nplt.grid(True)\nplt.legend()\nplt.tight_layout()\nsalary_forecast_path = \"DATA/ai_salary_forecast.png\"\nplt.savefig(salary_forecast_path, dpi=300)\nplt.show()"
  },
  {
    "objectID": "citation.html",
    "href": "citation.html",
    "title": "Job Market Analysis 2024",
    "section": "",
    "text": "Haseeb, M. A., Viswanathan, R., Iyer, K., Hota, A. R., & Prathaban, B. P. (2024). Predictive salary modelling: Leveraging data science skills and machine learning for accurate forecasting. 2024 9th International Conference on Communication and Electronics Systems (ICCES), 1011–1019. https://ieeexplore.ieee.org/document/10859447"
  },
  {
    "objectID": "citation.html#predictive-salary-modelling-leveraging-data-science-skills-and-machine-learning-for-accurate-forecasting",
    "href": "citation.html#predictive-salary-modelling-leveraging-data-science-skills-and-machine-learning-for-accurate-forecasting",
    "title": "Job Market Analysis 2024",
    "section": "",
    "text": "Haseeb, M. A., Viswanathan, R., Iyer, K., Hota, A. R., & Prathaban, B. P. (2024). Predictive salary modelling: Leveraging data science skills and machine learning for accurate forecasting. 2024 9th International Conference on Communication and Electronics Systems (ICCES), 1011–1019. https://ieeexplore.ieee.org/document/10859447"
  },
  {
    "objectID": "citation.html#tackling-economic-inequalities-through-business-analytics-a-literature-review",
    "href": "citation.html#tackling-economic-inequalities-through-business-analytics-a-literature-review",
    "title": "Job Market Analysis 2024",
    "section": "Tackling Economic Inequalities Through Business Analytics: A Literature Review",
    "text": "Tackling Economic Inequalities Through Business Analytics: A Literature Review\nAdaga, E. M., Egieya, Z. E., Ewuga, S. K., Abdul, A. A., & Abrahams, O. (2024). Tackling economic inequalities through business analytics: A literature review. Computer Science & IT Research Journal, 5(1), 60–80. https://doi.org/10.51594/csitjr.v5i1.702"
  },
  {
    "objectID": "citation.html#antecedent-configurations-toward-supply-chain-resilience-the-joint-impact-of-supply-chain-integration-and-big-data-analytics-capability",
    "href": "citation.html#antecedent-configurations-toward-supply-chain-resilience-the-joint-impact-of-supply-chain-integration-and-big-data-analytics-capability",
    "title": "Job Market Analysis 2024",
    "section": "Antecedent Configurations Toward Supply Chain Resilience: The Joint Impact of Supply Chain Integration and Big Data Analytics Capability",
    "text": "Antecedent Configurations Toward Supply Chain Resilience: The Joint Impact of Supply Chain Integration and Big Data Analytics Capability\nJiang, Y., Feng, T., & Huang, Y. (2024). Antecedent configurations toward supply chain resilience: The joint impact of supply chain integration and big data analytics capability. Journal of Operations Management, 70(2), 257–284. https://doi.org/10.1002/joom.1282"
  },
  {
    "objectID": "citation.html#leveraging-ai-and-data-analytics-for-enhancing-financial-inclusion-in-developing-economies",
    "href": "citation.html#leveraging-ai-and-data-analytics-for-enhancing-financial-inclusion-in-developing-economies",
    "title": "Job Market Analysis 2024",
    "section": "Leveraging AI and Data Analytics for Enhancing Financial Inclusion in Developing Economies",
    "text": "Leveraging AI and Data Analytics for Enhancing Financial Inclusion in Developing Economies\nAdeoye, O. B., Addy, W. A., Ajayi-Nifise, A. O., Odeyemi, O., Okoye, C. C., & Ofodile, O. C. (n.d.). Leveraging AI and data analytics for enhancing financial inclusion in developing economies. Finance & Accounting Research Journal. https://fepbl.com/index.php/farj/article/view/856"
  },
  {
    "objectID": "citation.html#employee-career-decision-making-the-influence-of-salary-and-benefits-work-environment-and-job-security",
    "href": "citation.html#employee-career-decision-making-the-influence-of-salary-and-benefits-work-environment-and-job-security",
    "title": "Job Market Analysis 2024",
    "section": "Employee Career Decision Making: The Influence of Salary and Benefits, Work Environment and Job Security",
    "text": "Employee Career Decision Making: The Influence of Salary and Benefits, Work Environment and Job Security\nAchim, N., Badrolhisam, N. I., & Zulkipli, N. (2019). Employee career decision making: The influence of salary and benefits, work environment and job security. Journal of Academia, 7(Special Issue 1), 41–50."
  },
  {
    "objectID": "citation.html#the-influence-of-salaries-and-opportunity-costs-on-teachers-career-choices",
    "href": "citation.html#the-influence-of-salaries-and-opportunity-costs-on-teachers-career-choices",
    "title": "Job Market Analysis 2024",
    "section": "The Influence of Salaries and “Opportunity Costs” on Teachers’ Career Choices",
    "text": "The Influence of Salaries and “Opportunity Costs” on Teachers’ Career Choices\nMurnane, R. J., Singer, J. D., & Willett, J. B. (1989). The influences of salaries and “opportunity costs” on teachers’ career choices: Evidence from North Carolina. Harvard Educational Review, 59(3), 325–349."
  },
  {
    "objectID": "citation.html#the-future-of-work-impacts-of-ai-on-employment-and-job-market-dynamics",
    "href": "citation.html#the-future-of-work-impacts-of-ai-on-employment-and-job-market-dynamics",
    "title": "Job Market Analysis 2024",
    "section": "The Future of Work: Impacts of AI on Employment and Job Market Dynamics",
    "text": "The Future of Work: Impacts of AI on Employment and Job Market Dynamics\nTomar, A., Sharma, S., Arti, & Suman, S. (2024). The future of work: Impacts of AI on employment and job market dynamics. 2024 International Conference on Progressive Innovations in Intelligent Systems and Data Science (ICPIDS)."
  },
  {
    "objectID": "citation.html#ai-and-job-market-analysing-the-potential-impact-of-ai-on-employment-skills-and-job-displacement",
    "href": "citation.html#ai-and-job-market-analysing-the-potential-impact-of-ai-on-employment-skills-and-job-displacement",
    "title": "Job Market Analysis 2024",
    "section": "AI and Job Market: Analysing the Potential Impact of AI on Employment, Skills, and Job Displacement",
    "text": "AI and Job Market: Analysing the Potential Impact of AI on Employment, Skills, and Job Displacement\nFaluyi, S. E. (2025). AI and job market: Analysing the potential impact of AI on employment, skills, and job displacement. African Journal of Marketing Management, 17(1), 1–8."
  },
  {
    "objectID": "ai_vs_tradsalary_analysis.html",
    "href": "ai_vs_tradsalary_analysis.html",
    "title": "Job Market Analysis 2024",
    "section": "",
    "text": "Code\nimport pandas as pd\n\n# Load cleaned dataset (update path)\ndf = pd.read_csv('region_analysis/lightcast_job_postings.csv')\n\n# Convert SALARY to numeric and drop nulls\ndf['SALARY'] = pd.to_numeric(df['SALARY'], errors='coerce')\ndf = df.dropna(subset=['SALARY'])\n\n# Tag AI vs Non-AI jobs\ndef tag_ai(row):\n    title = str(row['TITLE_NAME']).lower()\n    industry = str(row['NAICS_2022_2_NAME']).lower()\n    \n    if ('ai' in title or 'artificial intelligence' in title or 'machine learning' in title or\n        'data scientist' in title or 'deep learning' in title or 'nlp' in title or 'ml' in title or\n        'data engineer' in title or 'ml engineer' in title or 'scientist' in title or\n        'computer vision' in title or 'robotics' in title or\n        'professional, scientific, and technical services' in industry or 'information' in industry):\n        return 'AI Career'\n    else:\n        return 'Non-AI Career'\n\ndf['Career_Type'] = df.apply(tag_ai, axis=1)\nprint(df['Career_Type'].value_counts())\n\n# Group by STATE and Career Type → Avg Salary\nstate_salary = df.groupby(['STATE_NAME', 'Career_Type'])['SALARY'].mean().round(2).reset_index()\nstate_salary = state_salary.sort_values(by='SALARY', ascending=False)\n\n# Show top 5 for each category\nprint(\"Top 5 States for AI Careers:\")\nprint(state_salary[state_salary['Career_Type'] == 'AI Career'].head(5))\n\nprint(\"\\nTop 5 States for Non-AI Careers:\")\nprint(state_salary[state_salary['Career_Type'] == 'Non-AI Career'].head(5))\n\n# Optional: save to CSV\n# state_salary.to_csv('statewise_ai_vs_nonai_salary.csv', index=False)\n\n\nC:\\Users\\honga\\AppData\\Local\\Temp\\ipykernel_18916\\3429200541.py:4: DtypeWarning:\n\nColumns (19,30) have mixed types. Specify dtype option on import or set low_memory=False.\n\n\n\nCareer_Type\nNon-AI Career    19095\nAI Career        11713\nName: count, dtype: int64\nTop 5 States for AI Careers:\n   STATE_NAME Career_Type     SALARY\n6    Arkansas   AI Career  144133.42\n50    Montana   AI Career  143398.80\n88    Vermont   AI Career  142056.59\n70   Oklahoma   AI Career  141950.69\n48   Missouri   AI Career  140295.18\n\nTop 5 States for Non-AI Careers:\n       STATE_NAME    Career_Type     SALARY\n13    Connecticut  Non-AI Career  119981.12\n15       Delaware  Non-AI Career  118958.14\n89        Vermont  Non-AI Career  118892.86\n91       Virginia  Non-AI Career  118879.33\n41  Massachusetts  Non-AI Career  117756.62\nCode\nimport matplotlib.pyplot as plt\n\n# Top 5 AI states\ntop_ai = state_salary[state_salary['Career_Type'] == 'AI Career'].head(5)\n\n# Top 5 Non-AI states\ntop_nonai = state_salary[state_salary['Career_Type'] == 'Non-AI Career'].head(5)\n\n# Plot AI Career Salaries\nplt.figure(figsize=(8, 5))\nplt.barh(top_ai['STATE_NAME'], top_ai['SALARY'])\nplt.xlabel(\"Average Salary ($)\")\nplt.title(\"Top 5 States for AI Careers\")\nplt.gca().invert_yaxis()\nplt.tight_layout()\nplt.savefig(\"top_ai_states.png\")\nplt.show()\n\n# Plot Non-AI Career Salaries\nplt.figure(figsize=(8, 5))\nplt.barh(top_nonai['STATE_NAME'], top_nonai['SALARY'], color='orange')\nplt.xlabel(\"Average Salary ($)\")\nplt.title(\"Top 5 States for Non-AI Careers\")\nplt.gca().invert_yaxis()\nplt.tight_layout()\nplt.savefig(\"top_nonai_states.png\")\nplt.show()\nCode\n# Count of jobs used to compute avg salary\nstate_counts = df.groupby(['STATE_NAME', 'Career_Type'])['SALARY'].agg(['mean', 'count']).round(2).reset_index()\nstate_counts = state_counts.sort_values(by='mean', ascending=False)\n\n# Show top 10 AI states by average salary + count\nprint(state_counts[state_counts['Career_Type'] == 'AI Career'].head(10))\n\n\n        STATE_NAME Career_Type       mean  count\n6         Arkansas   AI Career  144133.42    127\n50         Montana   AI Career  143398.80     30\n88         Vermont   AI Career  142056.59     32\n70        Oklahoma   AI Career  141950.69    144\n48        Missouri   AI Career  140295.18    192\n12     Connecticut   AI Career  140156.16    167\n42        Michigan   AI Career  140097.41    396\n30          Kansas   AI Career  138880.23    122\n76    Rhode Island   AI Career  138855.30     66\n78  South Carolina   AI Career  138763.10     82\nCode\nall_ai_states = state_counts[state_counts['Career_Type'] == 'AI Career']\nprint(all_ai_states['STATE_NAME'].unique())\n\n\n['Arkansas' 'Montana' 'Vermont' 'Oklahoma' 'Missouri' 'Connecticut'\n 'Michigan' 'Kansas' 'Rhode Island' 'South Carolina' 'Nebraska'\n 'California' 'Washington' 'New Jersey' 'Louisiana' 'Iowa'\n 'North Carolina' 'Pennsylvania' 'Indiana' 'Tennessee' 'Alabama'\n 'Delaware' 'Florida' 'Minnesota' 'Nevada' 'Oregon' 'Idaho' 'Wisconsin'\n 'Illinois' 'Arizona' 'Virginia' 'Maryland' 'Ohio' 'Texas' 'Kentucky'\n 'Maine' 'Massachusetts' 'Colorado' 'Georgia'\n 'Washington, D.C. (District of Columbia)' 'New York' 'New Hampshire'\n 'Mississippi' 'Wyoming' 'South Dakota' 'New Mexico' 'Utah' 'Hawaii'\n 'North Dakota' 'West Virginia' 'Alaska']\nCode\nreliable_ai_states = state_counts[\n    (state_counts['Career_Type'] == 'AI Career') &\n    (state_counts['count'] &gt;= 50)\n].sort_values(by='mean', ascending=False)\n\nprint(reliable_ai_states.head(10))\n\n\n        STATE_NAME Career_Type       mean  count\n6         Arkansas   AI Career  144133.42    127\n70        Oklahoma   AI Career  141950.69    144\n48        Missouri   AI Career  140295.18    192\n12     Connecticut   AI Career  140156.16    167\n42        Michigan   AI Career  140097.41    396\n30          Kansas   AI Career  138880.23    122\n76    Rhode Island   AI Career  138855.30     66\n78  South Carolina   AI Career  138763.10     82\n52        Nebraska   AI Career  138461.39     75\n8       California   AI Career  138374.79   1483\nCode\nbig_states = ['Massachusetts', 'New York', 'New Jersey', 'California', 'Texas']\n\nai_counts_big_states = df[\n    (df['Career_Type'] == 'AI Career') & \n    (df['STATE_NAME'].isin(big_states))\n].groupby('STATE_NAME')['SALARY'].agg(['count', 'mean']).round(2).sort_values(by='count', ascending=False)\n\nai_counts_big_states.rename(columns={'count': 'AI Job Postings', 'mean': 'Avg Salary ($)'}, inplace=True)\n\nprint(ai_counts_big_states)\n\n\n               AI Job Postings  Avg Salary ($)\nSTATE_NAME                                    \nCalifornia                1483       138374.79\nTexas                      973       130898.40\nNew York                   606       125033.63\nNew Jersey                 350       137628.47\nMassachusetts              300       129245.66\nCode\nai_median_salary = df[df['Career_Type'] == 'AI Career'].groupby('STATE_NAME')['SALARY'].median().round(2).reset_index()\nai_counts = df[df['Career_Type'] == 'AI Career'].groupby('STATE_NAME')['SALARY'].count().reset_index(name='Job_Count')\n\n# Merge them\nai_summary = pd.merge(ai_median_salary, ai_counts, on='STATE_NAME')\nai_summary.columns = ['State', 'Median Salary ($)', 'AI Job Count']\n\n# Optional: Filter for states with decent sample size\nai_summary = ai_summary[ai_summary['AI Job Count'] &gt;= 50]\n\n# Sort by Median Salary\nai_summary = ai_summary.sort_values(by='Median Salary ($)', ascending=False)\n\nprint(ai_summary.head(10))\n\n\n             State  Median Salary ($)  AI Job Count\n24        Missouri           143000.0           192\n21        Michigan           143000.0           396\n35        Oklahoma           142997.0           144\n29      New Jersey           137500.0           350\n41       Tennessee           137375.0           226\n3         Arkansas           137000.0           127\n26        Nebraska           134500.0            75\n4       California           133865.0          1483\n39  South Carolina           133525.0            82\n49       Wisconsin           132800.0           167\nCode\nimport matplotlib.pyplot as plt\n\ntop_states = ai_summary.head(10)\n\nplt.figure(figsize=(10, 6))\nplt.barh(top_states['State'], top_states['Median Salary ($)'], color='teal')\nplt.xlabel(\"Median Salary ($)\")\nplt.title(\"Top 10 States for AI Careers (Median Salary, ≥50 Jobs)\")\nplt.gca().invert_yaxis()\nplt.tight_layout()\nplt.savefig(\"top_ai_states_median.png\")\nplt.show()"
  },
  {
    "objectID": "ai_vs_tradsalary_analysis.html#urban-vs-rural-states-median-ai-salary-comparison",
    "href": "ai_vs_tradsalary_analysis.html#urban-vs-rural-states-median-ai-salary-comparison",
    "title": "Job Market Analysis 2024",
    "section": "Urban vs Rural States – Median AI Salary Comparison",
    "text": "Urban vs Rural States – Median AI Salary Comparison\nThis chart compares the median salaries of AI careers in selected urban (California, New York, Massachusetts) and rural (Arkansas, Montana, Nebraska) states. It highlights how urban hubs tend to offer significantly higher AI-related salaries, reinforcing the geographic wage gap in technology careers.\n\n\n\nCode\n# Heatmap\nimport seaborn as sns \npivot = df.groupby(['STATE_NAME', 'Career_Type'])['SALARY'].median().unstack()\nplt.figure(figsize=(14, 6))\nsns.heatmap(pivot, annot=True, fmt=\".0f\", cmap=\"coolwarm\", linewidths=0.5)\nplt.title(\"Median Salary by State and Career Type\")\nplt.xlabel(\"Career Type\")\nplt.ylabel(\"State\")\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Group by state\nai_summary = df[df['Career_Type'] == 'AI Career'].groupby('STATE_NAME')['SALARY'].agg(\n    Median_Salary='median', Job_Count='count', Std_Dev='std').reset_index()\n\nplt.figure(figsize=(10, 6))\nplt.scatter(ai_summary['Median_Salary'], ai_summary['Job_Count'],\n            s=ai_summary['Job_Count'] / 1.5,\n            c=ai_summary['Std_Dev'], cmap='viridis', alpha=0.7, edgecolors='black')\n# Add state name labels to the bubbles\nfor i, row in ai_summary.iterrows():\n    if row['Job_Count'] &gt; 300:  # Label only big bubbles to reduce clutter\n        plt.text(row['Median_Salary'], row['Job_Count'], row['STATE_NAME'],\n                 fontsize=8, ha='center', va='center', color='black')\n\nplt.colorbar(label='Salary Std Dev')\nplt.xlabel('Median Salary ($)')\nplt.ylabel('AI Job Count')\nplt.title('AI Career Opportunities: Salary vs Availability by State')\nplt.grid(True, linestyle='--', alpha=0.5)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Reference lines\nmedian_salary_cutoff = ai_summary['Median_Salary'].median()\nmedian_job_count_cutoff = ai_summary['Job_Count'].median()\n\nplt.figure(figsize=(10, 6))\nplt.scatter(ai_summary['Median_Salary'], ai_summary['Job_Count'],\n            s=ai_summary['Job_Count'] / 1.5,\n            c=ai_summary['Std_Dev'], cmap='viridis', alpha=0.7, edgecolors='black')\n\n# Add quadrant lines\nplt.axvline(median_salary_cutoff, color='gray', linestyle='--', linewidth=1)\nplt.axhline(median_job_count_cutoff, color='gray', linestyle='--', linewidth=1)\n\n# Label top states\nfor i, row in ai_summary.iterrows():\n    if row['Job_Count'] &gt; 300:\n        plt.text(row['Median_Salary'], row['Job_Count'], row['STATE_NAME'],\n                 fontsize=8, ha='center', va='center', color='black')\n\nplt.colorbar(label='Salary Std Dev')\nplt.xlabel('Median Salary ($)')\nplt.ylabel('AI Job Count')\nplt.title('AI Career Opportunities: Salary vs Availability (with Reference Lines)')\nplt.grid(True, linestyle='--', alpha=0.5)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nAI Salaries by State Heatmap\n\n\nCode\nimport plotly.express as px\n\n# Mapping of full state names to 2-letter codes\nstate_abbrev = {\n    'Alabama': 'AL', 'Alaska': 'AK', 'Arizona': 'AZ', 'Arkansas': 'AR', 'California': 'CA',\n    'Colorado': 'CO', 'Connecticut': 'CT', 'Delaware': 'DE', 'Florida': 'FL', 'Georgia': 'GA',\n    'Hawaii': 'HI', 'Idaho': 'ID', 'Illinois': 'IL', 'Indiana': 'IN', 'Iowa': 'IA',\n    'Kansas': 'KS', 'Kentucky': 'KY', 'Louisiana': 'LA', 'Maine': 'ME', 'Maryland': 'MD',\n    'Massachusetts': 'MA', 'Michigan': 'MI', 'Minnesota': 'MN', 'Mississippi': 'MS',\n    'Missouri': 'MO', 'Montana': 'MT', 'Nebraska': 'NE', 'Nevada': 'NV', 'New Hampshire': 'NH',\n    'New Jersey': 'NJ', 'New Mexico': 'NM', 'New York': 'NY', 'North Carolina': 'NC',\n    'North Dakota': 'ND', 'Ohio': 'OH', 'Oklahoma': 'OK', 'Oregon': 'OR', 'Pennsylvania': 'PA',\n    'Rhode Island': 'RI', 'South Carolina': 'SC', 'South Dakota': 'SD', 'Tennessee': 'TN',\n    'Texas': 'TX', 'Utah': 'UT', 'Vermont': 'VT', 'Virginia': 'VA', 'Washington': 'WA',\n    'West Virginia': 'WV', 'Wisconsin': 'WI', 'Wyoming': 'WY', 'District of Columbia': 'DC'\n}\n\n# Create dataframe with state abbreviations\nai_state_medians = df[df['Career_Type'] == 'AI Career'].groupby('STATE_NAME')['SALARY'].median().reset_index()\nai_state_medians['STATE_ABBR'] = ai_state_medians['STATE_NAME'].map(state_abbrev)\n\n# Now plot\nfig = px.choropleth(ai_state_medians,\n                    locations='STATE_ABBR',\n                    locationmode=\"USA-states\",\n                    color='SALARY',\n                    scope=\"usa\",\n                    color_continuous_scale=\"Viridis\",\n                    labels={'SALARY':'Median AI Salary'})\nfig.update_layout(title_text='Median AI Salary by State', geo=dict(showlakes=True))\nfig.show()\n\n\n        \n        \n        \n\n\n                            \n                                            \n\n\n\n\nCode\nimport plotly.graph_objects as go\n\n# Prepare the base choropleth layer\nfig = go.Figure(data=go.Choropleth(\n    locations=ai_state_medians['STATE_ABBR'],  # 2-letter codes\n    z=ai_state_medians['SALARY'],\n    locationmode='USA-states',\n    colorscale='Viridis',\n    colorbar_title='Median AI Salary',\n    text=ai_state_medians['STATE_NAME'],  # hover text\n    hoverinfo='text+z'\n))\n\n# Add text annotations: state abbreviations\nfor i, row in ai_state_medians.iterrows():\n    fig.add_trace(go.Scattergeo(\n        locationmode='USA-states',\n        lon=[None],  # plotly doesn’t support precise state centroids natively\n        lat=[None],\n        text=row['STATE_ABBR'],\n        mode='text',\n        textfont=dict(color='white', size=10),\n        name=row['STATE_ABBR'],\n        showlegend=False\n    ))\n\n# Update map layout\nfig.update_layout(\n    title_text='Median AI Salary by State (with State Labels)',\n    geo=dict(\n        scope='usa',\n        showlakes=True,\n        lakecolor='rgb(255, 255, 255)'\n    )\n)\n\nfig.show()\n\n\n                            \n                                            \n\n\n\nNon AI Careers\n\n\nCode\nnonai_state_medians = df[df['Career_Type'] == 'Non-AI Career'].groupby('STATE_NAME')['SALARY'].median().reset_index()\nnonai_state_medians['STATE_ABBR'] = nonai_state_medians['STATE_NAME'].map(state_abbrev)\n\n\n\n\nCode\nai_top = ai_state_medians[['STATE_NAME', 'SALARY']].rename(columns={'SALARY': 'AI_Median'})\nnonai_top = nonai_state_medians[['STATE_NAME', 'SALARY']].rename(columns={'SALARY': 'NonAI_Median'})\n\ncomparison = pd.merge(ai_top, nonai_top, on='STATE_NAME', how='inner')\ncomparison['Diff'] = comparison['AI_Median'] - comparison['NonAI_Median']\ncomparison.sort_values(by='Diff', ascending=False).head(10)\n\n\n\n\n\n\n\n\n\nSTATE_NAME\nAI_Median\nNonAI_Median\nDiff\n\n\n\n\n21\nMichigan\n143000.0\n90760.0\n52240.0\n\n\n35\nOklahoma\n142997.0\n93650.0\n49347.0\n\n\n41\nTennessee\n137375.0\n89500.0\n47875.0\n\n\n24\nMissouri\n143000.0\n95150.0\n47850.0\n\n\n27\nNevada\n130500.0\n84725.0\n45775.0\n\n\n39\nSouth Carolina\n133525.0\n95325.0\n38200.0\n\n\n0\nAlabama\n130775.0\n93750.0\n37025.0\n\n\n17\nLouisiana\n131050.0\n96100.0\n34950.0\n\n\n16\nKentucky\n130500.0\n95800.0\n34700.0\n\n\n26\nNebraska\n134500.0\n100000.0\n34500.0\n\n\n\n\n\n\n\n\n\nCode\n# Step 1: Get AI job counts per state\nai_counts = df[df['Career_Type'] == 'AI Career'].groupby('STATE_NAME')['SALARY'].count().reset_index(name='AI_Job_Count')\n\n# Step 2: Merge counts into comparison\ncomparison_with_counts = pd.merge(comparison, ai_counts, on='STATE_NAME', how='left')\n\n# Step 3: Filter for states with at least 100 AI jobs\nfiltered = comparison_with_counts[comparison_with_counts['AI_Job_Count'] &gt;= 300]\n\n# Step 4: Take top 10 states by salary gap\ntop_realistic = filtered.sort_values(by='Diff', ascending=False).head(10).sort_values('AI_Median')\n\n# Step 5: Plot dumbbell chart\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(10, 6))\n\n# Draw connecting lines\nfor _, row in top_realistic.iterrows():\n    plt.plot([row['NonAI_Median'], row['AI_Median']], [row['STATE_NAME']] * 2, color='gray', linewidth=2)\n\n# Plot salary points\nplt.scatter(top_realistic['NonAI_Median'], top_realistic['STATE_NAME'], color='darkorange', label='Traditional Median Salary', s=80)\nplt.scatter(top_realistic['AI_Median'], top_realistic['STATE_NAME'], color='steelblue', label='AI Median Salary', s=80)\n\n# Annotate the difference\nfor _, row in top_realistic.iterrows():\n    plt.text(row['AI_Median'] + 1000, row['STATE_NAME'], f\"+${int(row['Diff']):,}\", fontsize=8, va='center', color='black')\n\nplt.xlabel(\"Median Salary ($)\")\nplt.title(\"AI vs Traditional Salaries (Top 10 States, ≥300 AI Jobs)\")\nplt.legend()\nplt.grid(axis='x', linestyle='--', alpha=0.5)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\nInsight: Top States with Highest AI Salary Advantage (≥300 AI Jobs)\nThis chart compares the median salaries of AI-related and traditional careers in states with substantial AI job markets (300+ postings). Each line connects the traditional (orange) and AI (blue) median salaries for a given state, with the annotated value indicating the salary gap.\nKey takeaways: - Michigan, California, and Florida exhibit the most substantial salary premiums for AI roles, with gaps exceeding $30,000–$50,000. - New Jersey, Georgia, and Illinois also show consistent advantages, reinforcing the value of AI specialization in large-scale markets. - By filtering for states with significant job volume, we ensure these salary gaps are statistically meaningful, not outliers from niche postings.\nThis visualization reinforces that AI careers aren’t just higher paying — they’re transformationally more lucrative in regions where demand and infrastructure support sustainable opportunities."
  },
  {
    "objectID": "career_plan.html",
    "href": "career_plan.html",
    "title": "1. An Ly – Business Analyst in Finance or Tech",
    "section": "",
    "text": "My goal is to secure a Business Analyst role in either the financial services or technology industry. I’m particularly interested in companies that use analytics to drive strategic decision-making, especially in hybrid or remote-friendly environments.\n\n\n\nOur EDA revealed that roles in professional, scientific, and technical services dominate job postings in 2024. Remote roles are especially prevalent in tech, aligning well with my flexibility needs and skills in Python, Tableau, and SQL.\n\n\n\n\nStrengthen Python and Power BI visualization skills.\nNetwork with Boston alumni working in fintech.\nApply to hybrid analyst roles in NY, MA, and CA."
  },
  {
    "objectID": "career_plan.html#career-goal",
    "href": "career_plan.html#career-goal",
    "title": "1. An Ly – Business Analyst in Finance or Tech",
    "section": "",
    "text": "My goal is to secure a Business Analyst role in either the financial services or technology industry. I’m particularly interested in companies that use analytics to drive strategic decision-making, especially in hybrid or remote-friendly environments."
  },
  {
    "objectID": "career_plan.html#key-trends-supporting-my-career-plan",
    "href": "career_plan.html#key-trends-supporting-my-career-plan",
    "title": "1. An Ly – Business Analyst in Finance or Tech",
    "section": "",
    "text": "Our EDA revealed that roles in professional, scientific, and technical services dominate job postings in 2024. Remote roles are especially prevalent in tech, aligning well with my flexibility needs and skills in Python, Tableau, and SQL."
  },
  {
    "objectID": "career_plan.html#action-plan",
    "href": "career_plan.html#action-plan",
    "title": "1. An Ly – Business Analyst in Finance or Tech",
    "section": "",
    "text": "Strengthen Python and Power BI visualization skills.\nNetwork with Boston alumni working in fintech.\nApply to hybrid analyst roles in NY, MA, and CA."
  },
  {
    "objectID": "career_plan.html#career-goal-1",
    "href": "career_plan.html#career-goal-1",
    "title": "1. An Ly – Business Analyst in Finance or Tech",
    "section": "Career Goal",
    "text": "Career Goal\nI aim to become a data engineer focused on big data pipelines and cloud infrastructure, particularly with AWS and Spark."
  },
  {
    "objectID": "career_plan.html#key-trends-supporting-my-career-plan-1",
    "href": "career_plan.html#key-trends-supporting-my-career-plan-1",
    "title": "1. An Ly – Business Analyst in Finance or Tech",
    "section": "Key Trends Supporting My Career Plan",
    "text": "Key Trends Supporting My Career Plan\nThe job title analysis showed strong demand for technical roles like Data Engineer, especially in major tech hubs like California and Texas. Our project also highlighted the increasing importance of cloud-based roles with remote options."
  },
  {
    "objectID": "career_plan.html#action-plan-1",
    "href": "career_plan.html#action-plan-1",
    "title": "1. An Ly – Business Analyst in Finance or Tech",
    "section": "Action Plan",
    "text": "Action Plan\n\nEarn AWS Cloud Practitioner and Spark certifications.\nComplete hands-on projects in ETL and data pipeline development.\nTarget roles at cloud-first companies like Snowflake, Amazon, and startups."
  },
  {
    "objectID": "career_plan.html#career-goal-2",
    "href": "career_plan.html#career-goal-2",
    "title": "1. An Ly – Business Analyst in Finance or Tech",
    "section": "Career Goal",
    "text": "Career Goal\nI want to pursue a career as a Business Intelligence Analyst within the healthcare industry. I’m passionate about combining analytics and patient-centric systems to improve operations."
  },
  {
    "objectID": "career_plan.html#key-trends-supporting-my-career-plan-2",
    "href": "career_plan.html#key-trends-supporting-my-career-plan-2",
    "title": "1. An Ly – Business Analyst in Finance or Tech",
    "section": "Key Trends Supporting My Career Plan",
    "text": "Key Trends Supporting My Career Plan\nHealthcare & Social Assistance was the second-largest industry by job postings in our dataset. However, most roles remain on-site, which aligns with my comfort level working in physical healthcare environments."
  },
  {
    "objectID": "career_plan.html#action-plan-2",
    "href": "career_plan.html#action-plan-2",
    "title": "1. An Ly – Business Analyst in Finance or Tech",
    "section": "Action Plan",
    "text": "Action Plan\n\nComplete Tableau + SQL + Healthcare Analytics specialization on Coursera.\nAttend HIMSS career webinars and healthcare data meetups.\nApply for entry-level BI roles in hospitals or health tech firms."
  },
  {
    "objectID": "career_plan.html#career-goal-3",
    "href": "career_plan.html#career-goal-3",
    "title": "1. An Ly – Business Analyst in Finance or Tech",
    "section": "Career Goal",
    "text": "Career Goal\nMy goal is to become a Data Scientist specializing in customer behavior, forecasting, or supply chain analytics in the retail or consulting sectors."
  },
  {
    "objectID": "career_plan.html#key-trends-supporting-my-career-plan-3",
    "href": "career_plan.html#key-trends-supporting-my-career-plan-3",
    "title": "1. An Ly – Business Analyst in Finance or Tech",
    "section": "Key Trends Supporting My Career Plan",
    "text": "Key Trends Supporting My Career Plan\nOur analysis of job titles and word clouds indicated demand for data and consulting roles. While retail showed fewer postings, consulting and analytics-driven firms remain strong in hiring for hybrid data roles."
  },
  {
    "objectID": "career_plan.html#action-plan-3",
    "href": "career_plan.html#action-plan-3",
    "title": "1. An Ly – Business Analyst in Finance or Tech",
    "section": "Action Plan",
    "text": "Action Plan\n\nBuild end-to-end forecasting models using time-series libraries.\nApply to rotational data science programs at firms like Deloitte and Target.\nPractice Kaggle competitions and publish findings to GitHub/LinkedIn."
  },
  {
    "objectID": "career_plan.html#conclusion",
    "href": "career_plan.html#conclusion",
    "title": "1. An Ly – Business Analyst in Finance or Tech",
    "section": "Conclusion",
    "text": "Conclusion\nEach of us is aligning our personal goals with the trends we uncovered through our analysis of 2024 job market data. Whether targeting technical infrastructure, healthcare analytics, or strategic consulting, we aim to use our data-driven insights to inform smart, personalized job search strategies."
  },
  {
    "objectID": "Data/ai_vs_tradsalary_analysis.html",
    "href": "Data/ai_vs_tradsalary_analysis.html",
    "title": "Urban vs Rural States",
    "section": "",
    "text": "Code\nimport pandas as pd\n\n# Load cleaned dataset (update path)\ndf = pd.read_csv('region_analysis/lightcast_job_postings.csv')\n# Convert SALARY to numeric and drop nulls\ndf['SALARY'] = pd.to_numeric(df['SALARY'], errors='coerce')\ndf = df.dropna(subset=['SALARY'])\n\n# Tag AI vs Non-AI jobs\ndef tag_ai(row):\n    title = str(row['TITLE_NAME']).lower()\n    industry = str(row['NAICS_2022_2_NAME']).lower()\n    \n    if ('ai' in title or 'artificial intelligence' in title or 'machine learning' in title or\n        'data scientist' in title or 'deep learning' in title or 'nlp' in title or 'ml' in title or\n        'data engineer' in title or 'ml engineer' in title or 'scientist' in title or\n        'computer vision' in title or 'robotics' in title or\n        'professional, scientific, and technical services' in industry or 'information' in industry):\n        return 'AI Career'\n    else:\n        return 'Non-AI Career'\n\ndf['Career_Type'] = df.apply(tag_ai, axis=1)\nprint(df['Career_Type'].value_counts())\n\n# Group by STATE and Career Type → Avg Salary\nstate_salary = df.groupby(['STATE_NAME', 'Career_Type'])['SALARY'].mean().round(2).reset_index()\nstate_salary = state_salary.sort_values(by='SALARY', ascending=False)\n\n# Show top 5 for each category\nprint(\"Top 5 States for AI Careers:\")\nprint(state_salary[state_salary['Career_Type'] == 'AI Career'].head(5))\n\nprint(\"\\nTop 5 States for Non-AI Careers:\")\nprint(state_salary[state_salary['Career_Type'] == 'Non-AI Career'].head(5))\n\n# Optional: save to CSV\n# state_salary.to_csv('statewise_ai_vs_nonai_salary.csv', index=False)\n\n\n\n---------------------------------------------------------------------------\nFileNotFoundError                         Traceback (most recent call last)\nCell In[1], line 4\n      1 import pandas as pd\n      3 # Load cleaned dataset (update path)\n----&gt; 4 df = pd.read_csv('region_analysis/lightcast_job_postings.csv')\n      5 # Convert SALARY to numeric and drop nulls\n      6 df['SALARY'] = pd.to_numeric(df['SALARY'], errors='coerce')\n\nFile c:\\Users\\honga\\ad688-project1-group-10\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026, in read_csv(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\n   1013 kwds_defaults = _refine_defaults_read(\n   1014     dialect,\n   1015     delimiter,\n   (...)   1022     dtype_backend=dtype_backend,\n   1023 )\n   1024 kwds.update(kwds_defaults)\n-&gt; 1026 return _read(filepath_or_buffer, kwds)\n\nFile c:\\Users\\honga\\ad688-project1-group-10\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620, in _read(filepath_or_buffer, kwds)\n    617 _validate_names(kwds.get(\"names\", None))\n    619 # Create the parser.\n--&gt; 620 parser = TextFileReader(filepath_or_buffer, **kwds)\n    622 if chunksize or iterator:\n    623     return parser\n\nFile c:\\Users\\honga\\ad688-project1-group-10\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620, in TextFileReader.__init__(self, f, engine, **kwds)\n   1617     self.options[\"has_index_names\"] = kwds[\"has_index_names\"]\n   1619 self.handles: IOHandles | None = None\n-&gt; 1620 self._engine = self._make_engine(f, self.engine)\n\nFile c:\\Users\\honga\\ad688-project1-group-10\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880, in TextFileReader._make_engine(self, f, engine)\n   1878     if \"b\" not in mode:\n   1879         mode += \"b\"\n-&gt; 1880 self.handles = get_handle(\n   1881     f,\n   1882     mode,\n   1883     encoding=self.options.get(\"encoding\", None),\n   1884     compression=self.options.get(\"compression\", None),\n   1885     memory_map=self.options.get(\"memory_map\", False),\n   1886     is_text=is_text,\n   1887     errors=self.options.get(\"encoding_errors\", \"strict\"),\n   1888     storage_options=self.options.get(\"storage_options\", None),\n   1889 )\n   1890 assert self.handles is not None\n   1891 f = self.handles.handle\n\nFile c:\\Users\\honga\\ad688-project1-group-10\\.venv\\Lib\\site-packages\\pandas\\io\\common.py:873, in get_handle(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\n    868 elif isinstance(handle, str):\n    869     # Check whether the filename is to be opened in binary mode.\n    870     # Binary mode does not support 'encoding' and 'newline'.\n    871     if ioargs.encoding and \"b\" not in ioargs.mode:\n    872         # Encoding\n--&gt; 873         handle = open(\n    874             handle,\n    875             ioargs.mode,\n    876             encoding=ioargs.encoding,\n    877             errors=errors,\n    878             newline=\"\",\n    879         )\n    880     else:\n    881         # Binary mode\n    882         handle = open(handle, ioargs.mode)\n\nFileNotFoundError: [Errno 2] No such file or directory: 'region_analysis/lightcast_job_postings.csv'\n\n\n\n\n\nCode\nimport matplotlib.pyplot as plt\n\n# Top 5 AI states\ntop_ai = state_salary[state_salary['Career_Type'] == 'AI Career'].head(5)\n\n# Top 5 Non-AI states\ntop_nonai = state_salary[state_salary['Career_Type'] == 'Non-AI Career'].head(5)\n\n# Plot AI Career Salaries\nplt.figure(figsize=(8, 5))\nplt.barh(top_ai['STATE_NAME'], top_ai['SALARY'])\nplt.xlabel(\"Average Salary ($)\")\nplt.title(\"Top 5 States for AI Careers\")\nplt.gca().invert_yaxis()\nplt.tight_layout()\nplt.savefig(\"top_ai_states.png\")\nplt.show()\n\n# Plot Non-AI Career Salaries\nplt.figure(figsize=(8, 5))\nplt.barh(top_nonai['STATE_NAME'], top_nonai['SALARY'], color='orange')\nplt.xlabel(\"Average Salary ($)\")\nplt.title(\"Top 5 States for Non-AI Careers\")\nplt.gca().invert_yaxis()\nplt.tight_layout()\nplt.savefig(\"top_nonai_states.png\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Count of jobs used to compute avg salary\nstate_counts = df.groupby(['STATE_NAME', 'Career_Type'])['SALARY'].agg(['mean', 'count']).round(2).reset_index()\nstate_counts = state_counts.sort_values(by='mean', ascending=False)\n\n# Show top 10 AI states by average salary + count\nprint(state_counts[state_counts['Career_Type'] == 'AI Career'].head(10))\n\n\n        STATE_NAME Career_Type       mean  count\n6         Arkansas   AI Career  144133.42    127\n50         Montana   AI Career  143398.80     30\n88         Vermont   AI Career  142056.59     32\n70        Oklahoma   AI Career  141950.69    144\n48        Missouri   AI Career  140295.18    192\n12     Connecticut   AI Career  140156.16    167\n42        Michigan   AI Career  140097.41    396\n30          Kansas   AI Career  138880.23    122\n76    Rhode Island   AI Career  138855.30     66\n78  South Carolina   AI Career  138763.10     82\n\n\n\n\nCode\nall_ai_states = state_counts[state_counts['Career_Type'] == 'AI Career']\nprint(all_ai_states['STATE_NAME'].unique())\n\n\n['Arkansas' 'Montana' 'Vermont' 'Oklahoma' 'Missouri' 'Connecticut'\n 'Michigan' 'Kansas' 'Rhode Island' 'South Carolina' 'Nebraska'\n 'California' 'Washington' 'New Jersey' 'Louisiana' 'Iowa'\n 'North Carolina' 'Pennsylvania' 'Indiana' 'Tennessee' 'Alabama'\n 'Delaware' 'Florida' 'Minnesota' 'Nevada' 'Oregon' 'Idaho' 'Wisconsin'\n 'Illinois' 'Arizona' 'Virginia' 'Maryland' 'Ohio' 'Texas' 'Kentucky'\n 'Maine' 'Massachusetts' 'Colorado' 'Georgia'\n 'Washington, D.C. (District of Columbia)' 'New York' 'New Hampshire'\n 'Mississippi' 'Wyoming' 'South Dakota' 'New Mexico' 'Utah' 'Hawaii'\n 'North Dakota' 'West Virginia' 'Alaska']\n\n\n\n\nCode\nreliable_ai_states = state_counts[\n    (state_counts['Career_Type'] == 'AI Career') &\n    (state_counts['count'] &gt;= 50)\n].sort_values(by='mean', ascending=False)\n\nprint(reliable_ai_states.head(10))\n\n\n        STATE_NAME Career_Type       mean  count\n6         Arkansas   AI Career  144133.42    127\n70        Oklahoma   AI Career  141950.69    144\n48        Missouri   AI Career  140295.18    192\n12     Connecticut   AI Career  140156.16    167\n42        Michigan   AI Career  140097.41    396\n30          Kansas   AI Career  138880.23    122\n76    Rhode Island   AI Career  138855.30     66\n78  South Carolina   AI Career  138763.10     82\n52        Nebraska   AI Career  138461.39     75\n8       California   AI Career  138374.79   1483\n\n\n\n\nCode\nbig_states = ['Massachusetts', 'New York', 'New Jersey', 'California', 'Texas']\n\nai_counts_big_states = df[\n    (df['Career_Type'] == 'AI Career') & \n    (df['STATE_NAME'].isin(big_states))\n].groupby('STATE_NAME')['SALARY'].agg(['count', 'mean']).round(2).sort_values(by='count', ascending=False)\n\nai_counts_big_states.rename(columns={'count': 'AI Job Postings', 'mean': 'Avg Salary ($)'}, inplace=True)\n\nprint(ai_counts_big_states)\n\n\n               AI Job Postings  Avg Salary ($)\nSTATE_NAME                                    \nCalifornia                1483       138374.79\nTexas                      973       130898.40\nNew York                   606       125033.63\nNew Jersey                 350       137628.47\nMassachusetts              300       129245.66\n\n\n\n\nCode\nai_median_salary = df[df['Career_Type'] == 'AI Career'].groupby('STATE_NAME')['SALARY'].median().round(2).reset_index()\nai_counts = df[df['Career_Type'] == 'AI Career'].groupby('STATE_NAME')['SALARY'].count().reset_index(name='Job_Count')\n\n# Merge them\nai_summary = pd.merge(ai_median_salary, ai_counts, on='STATE_NAME')\nai_summary.columns = ['State', 'Median Salary ($)', 'AI Job Count']\n\n# Optional: Filter for states with decent sample size\nai_summary = ai_summary[ai_summary['AI Job Count'] &gt;= 50]\n\n# Sort by Median Salary\nai_summary = ai_summary.sort_values(by='Median Salary ($)', ascending=False)\n\nprint(ai_summary.head(10))\n\n\n             State  Median Salary ($)  AI Job Count\n24        Missouri           143000.0           192\n21        Michigan           143000.0           396\n35        Oklahoma           142997.0           144\n29      New Jersey           137500.0           350\n41       Tennessee           137375.0           226\n3         Arkansas           137000.0           127\n26        Nebraska           134500.0            75\n4       California           133865.0          1483\n39  South Carolina           133525.0            82\n49       Wisconsin           132800.0           167\n\n\n\n\nCode\nimport matplotlib.pyplot as plt\n\ntop_states = ai_summary.head(10)\n\nplt.figure(figsize=(10, 6))\nplt.barh(top_states['State'], top_states['Median Salary ($)'], color='teal')\nplt.xlabel(\"Median Salary ($)\")\nplt.title(\"Top 10 States for AI Careers (Median Salary, ≥50 Jobs)\")\nplt.gca().invert_yaxis()\nplt.tight_layout()\nplt.savefig(\"top_ai_states_median.png\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\ngeo_stats = df.groupby(['STATE_NAME', 'Career_Type'])['SALARY'].median().reset_index()\ngeo_stats.rename(columns={'SALARY': 'Median_Salary'}, inplace=True)\n\nurban_states = ['California', 'New York', 'Massachusetts']\nrural_states = ['Arkansas', 'Montana', 'Nebraska']\n\nurban_vs_rural = geo_stats[\n    (geo_stats['Career_Type'] == 'AI Career') &\n    (geo_stats['STATE_NAME'].isin(urban_states + rural_states))\n].sort_values(by='Median_Salary', ascending=False)\n\nplt.figure(figsize=(10, 6))\nplt.bar(urban_vs_rural['STATE_NAME'], urban_vs_rural['Median_Salary'], color='darkorange')\nplt.xlabel(\"State\")\nplt.ylabel(\"Median Salary ($)\")\nplt.title(\"Median AI Salary: Urban vs Rural States\")\nplt.tight_layout()\nplt.savefig(\"urban_vs_rural_ai_salaries.png\")\nplt.show()\n\n\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[11], line 1\n----&gt; 1 geo_stats = df.groupby(['STATE_NAME', 'Career_Type'])['SALARY'].median().reset_index()\n      2 geo_stats.rename(columns={'SALARY': 'Median_Salary'}, inplace=True)\n      4 urban_states = ['California', 'New York', 'Massachusetts']\n\nNameError: name 'df' is not defined\n\n\n\n\n\nCode\n# Heatmap\nimport seaborn as sns \npivot = df.groupby(['STATE_NAME', 'Career_Type'])['SALARY'].median().unstack()\nplt.figure(figsize=(14, 6))\nsns.heatmap(pivot, annot=True, fmt=\".0f\", cmap=\"coolwarm\", linewidths=0.5)\nplt.title(\"Median Salary by State and Career Type\")\nplt.xlabel(\"Career Type\")\nplt.ylabel(\"State\")\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Group by state\nai_summary = df[df['Career_Type'] == 'AI Career'].groupby('STATE_NAME')['SALARY'].agg(\n    Median_Salary='median', Job_Count='count', Std_Dev='std').reset_index()\n\nplt.figure(figsize=(10, 6))\nplt.scatter(ai_summary['Median_Salary'], ai_summary['Job_Count'],\n            s=ai_summary['Job_Count'] / 1.5,\n            c=ai_summary['Std_Dev'], cmap='viridis', alpha=0.7, edgecolors='black')\n# Add state name labels to the bubbles\nfor i, row in ai_summary.iterrows():\n    if row['Job_Count'] &gt; 300:  # Label only big bubbles to reduce clutter\n        plt.text(row['Median_Salary'], row['Job_Count'], row['STATE_NAME'],\n                 fontsize=8, ha='center', va='center', color='black')\n\nplt.colorbar(label='Salary Std Dev')\nplt.xlabel('Median Salary ($)')\nplt.ylabel('AI Job Count')\nplt.title('AI Career Opportunities: Salary vs Availability by State')\nplt.grid(True, linestyle='--', alpha=0.5)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Reference lines\nmedian_salary_cutoff = ai_summary['Median_Salary'].median()\nmedian_job_count_cutoff = ai_summary['Job_Count'].median()\n\nplt.figure(figsize=(10, 6))\nplt.scatter(ai_summary['Median_Salary'], ai_summary['Job_Count'],\n            s=ai_summary['Job_Count'] / 1.5,\n            c=ai_summary['Std_Dev'], cmap='viridis', alpha=0.7, edgecolors='black')\n\n# Add quadrant lines\nplt.axvline(median_salary_cutoff, color='gray', linestyle='--', linewidth=1)\nplt.axhline(median_job_count_cutoff, color='gray', linestyle='--', linewidth=1)\n\n# Label top states\nfor i, row in ai_summary.iterrows():\n    if row['Job_Count'] &gt; 300:\n        plt.text(row['Median_Salary'], row['Job_Count'], row['STATE_NAME'],\n                 fontsize=8, ha='center', va='center', color='black')\n\nplt.colorbar(label='Salary Std Dev')\nplt.xlabel('Median Salary ($)')\nplt.ylabel('AI Job Count')\nplt.title('AI Career Opportunities: Salary vs Availability (with Reference Lines)')\nplt.grid(True, linestyle='--', alpha=0.5)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nAI Salaries by State Heatmap\n\n\nCode\nimport plotly.express as px\n\n# Mapping of full state names to 2-letter codes\nstate_abbrev = {\n    'Alabama': 'AL', 'Alaska': 'AK', 'Arizona': 'AZ', 'Arkansas': 'AR', 'California': 'CA',\n    'Colorado': 'CO', 'Connecticut': 'CT', 'Delaware': 'DE', 'Florida': 'FL', 'Georgia': 'GA',\n    'Hawaii': 'HI', 'Idaho': 'ID', 'Illinois': 'IL', 'Indiana': 'IN', 'Iowa': 'IA',\n    'Kansas': 'KS', 'Kentucky': 'KY', 'Louisiana': 'LA', 'Maine': 'ME', 'Maryland': 'MD',\n    'Massachusetts': 'MA', 'Michigan': 'MI', 'Minnesota': 'MN', 'Mississippi': 'MS',\n    'Missouri': 'MO', 'Montana': 'MT', 'Nebraska': 'NE', 'Nevada': 'NV', 'New Hampshire': 'NH',\n    'New Jersey': 'NJ', 'New Mexico': 'NM', 'New York': 'NY', 'North Carolina': 'NC',\n    'North Dakota': 'ND', 'Ohio': 'OH', 'Oklahoma': 'OK', 'Oregon': 'OR', 'Pennsylvania': 'PA',\n    'Rhode Island': 'RI', 'South Carolina': 'SC', 'South Dakota': 'SD', 'Tennessee': 'TN',\n    'Texas': 'TX', 'Utah': 'UT', 'Vermont': 'VT', 'Virginia': 'VA', 'Washington': 'WA',\n    'West Virginia': 'WV', 'Wisconsin': 'WI', 'Wyoming': 'WY', 'District of Columbia': 'DC'\n}\n\n# Create dataframe with state abbreviations\nai_state_medians = df[df['Career_Type'] == 'AI Career'].groupby('STATE_NAME')['SALARY'].median().reset_index()\nai_state_medians['STATE_ABBR'] = ai_state_medians['STATE_NAME'].map(state_abbrev)\n\n# Now plot\nfig = px.choropleth(ai_state_medians,\n                    locations='STATE_ABBR',\n                    locationmode=\"USA-states\",\n                    color='SALARY',\n                    scope=\"usa\",\n                    color_continuous_scale=\"Viridis\",\n                    labels={'SALARY':'Median AI Salary'})\nfig.update_layout(title_text='Median AI Salary by State', geo=dict(showlakes=True))\nfig.show()\n\n\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\n\n\n\n\nCode\nimport plotly.graph_objects as go\n\n# Prepare the base choropleth layer\nfig = go.Figure(data=go.Choropleth(\n    locations=ai_state_medians['STATE_ABBR'],  # 2-letter codes\n    z=ai_state_medians['SALARY'],\n    locationmode='USA-states',\n    colorscale='Viridis',\n    colorbar_title='Median AI Salary',\n    text=ai_state_medians['STATE_NAME'],  # hover text\n    hoverinfo='text+z'\n))\n\n# Add text annotations: state abbreviations\nfor i, row in ai_state_medians.iterrows():\n    fig.add_trace(go.Scattergeo(\n        locationmode='USA-states',\n        lon=[None],  # plotly doesn’t support precise state centroids natively\n        lat=[None],\n        text=row['STATE_ABBR'],\n        mode='text',\n        textfont=dict(color='white', size=10),\n        name=row['STATE_ABBR'],\n        showlegend=False\n    ))\n\n# Update map layout\nfig.update_layout(\n    title_text='Median AI Salary by State (with State Labels)',\n    geo=dict(\n        scope='usa',\n        showlakes=True,\n        lakecolor='rgb(255, 255, 255)'\n    )\n)\n\nfig.show()\n\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\n\n\n\nNon AI Careers\n\n\nCode\nnonai_state_medians = df[df['Career_Type'] == 'Non-AI Career'].groupby('STATE_NAME')['SALARY'].median().reset_index()\nnonai_state_medians['STATE_ABBR'] = nonai_state_medians['STATE_NAME'].map(state_abbrev)\n\n\n\n\nCode\nai_top = ai_state_medians[['STATE_NAME', 'SALARY']].rename(columns={'SALARY': 'AI_Median'})\nnonai_top = nonai_state_medians[['STATE_NAME', 'SALARY']].rename(columns={'SALARY': 'NonAI_Median'})\n\ncomparison = pd.merge(ai_top, nonai_top, on='STATE_NAME', how='inner')\ncomparison['Diff'] = comparison['AI_Median'] - comparison['NonAI_Median']\ncomparison.sort_values(by='Diff', ascending=False).head(10)\n\n\n\n\n\n\n\n\n\nSTATE_NAME\nAI_Median\nNonAI_Median\nDiff\n\n\n\n\n21\nMichigan\n143000.0\n90760.0\n52240.0\n\n\n35\nOklahoma\n142997.0\n93650.0\n49347.0\n\n\n41\nTennessee\n137375.0\n89500.0\n47875.0\n\n\n24\nMissouri\n143000.0\n95150.0\n47850.0\n\n\n27\nNevada\n130500.0\n84725.0\n45775.0\n\n\n39\nSouth Carolina\n133525.0\n95325.0\n38200.0\n\n\n0\nAlabama\n130775.0\n93750.0\n37025.0\n\n\n17\nLouisiana\n131050.0\n96100.0\n34950.0\n\n\n16\nKentucky\n130500.0\n95800.0\n34700.0\n\n\n26\nNebraska\n134500.0\n100000.0\n34500.0\n\n\n\n\n\n\n\n\n\nCode\n# Step 1: Get AI job counts per state\nai_counts = df[df['Career_Type'] == 'AI Career'].groupby('STATE_NAME')['SALARY'].count().reset_index(name='AI_Job_Count')\n\n# Step 2: Merge counts into comparison\ncomparison_with_counts = pd.merge(comparison, ai_counts, on='STATE_NAME', how='left')\n\n# Step 3: Filter for states with at least 100 AI jobs\nfiltered = comparison_with_counts[comparison_with_counts['AI_Job_Count'] &gt;= 300]\n\n# Step 4: Take top 10 states by salary gap\ntop_realistic = filtered.sort_values(by='Diff', ascending=False).head(10).sort_values('AI_Median')\n\n# Step 5: Plot dumbbell chart\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(10, 6))\n\n# Draw connecting lines\nfor _, row in top_realistic.iterrows():\n    plt.plot([row['NonAI_Median'], row['AI_Median']], [row['STATE_NAME']] * 2, color='gray', linewidth=2)\n\n# Plot salary points\nplt.scatter(top_realistic['NonAI_Median'], top_realistic['STATE_NAME'], color='darkorange', label='Traditional Median Salary', s=80)\nplt.scatter(top_realistic['AI_Median'], top_realistic['STATE_NAME'], color='steelblue', label='AI Median Salary', s=80)\n\n# Annotate the difference\nfor _, row in top_realistic.iterrows():\n    plt.text(row['AI_Median'] + 1000, row['STATE_NAME'], f\"+${int(row['Diff']):,}\", fontsize=8, va='center', color='black')\n\nplt.xlabel(\"Median Salary ($)\")\nplt.title(\"AI vs Traditional Salaries (Top 10 States, ≥300 AI Jobs)\")\nplt.legend()\nplt.grid(axis='x', linestyle='--', alpha=0.5)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\nInsight: Top States with Highest AI Salary Advantage (≥300 AI Jobs)\nThis chart compares the median salaries of AI-related and traditional careers in states with substantial AI job markets (300+ postings). Each line connects the traditional (orange) and AI (blue) median salaries for a given state, with the annotated value indicating the salary gap.\nKey takeaways: - Michigan, California, and Florida exhibit the most substantial salary premiums for AI roles, with gaps exceeding $30,000–$50,000. - New Jersey, Georgia, and Illinois also show consistent advantages, reinforcing the value of AI specialization in large-scale markets. - By filtering for states with significant job volume, we ensure these salary gaps are statistically meaningful, not outliers from niche postings.\nThis visualization reinforces that AI careers aren’t just higher paying — they’re transformationally more lucrative in regions where demand and infrastructure support sustainable opportunities."
  },
  {
    "objectID": "data_analysis.html",
    "href": "data_analysis.html",
    "title": "Introduction",
    "section": "",
    "text": "This document presents a comprehensive analysis of job market trends using the Lightcast job postings dataset. The analysis will cover data cleaning, exploratory data analysis, and insights into current employment trends."
  },
  {
    "objectID": "data_analysis.html#dataset-description",
    "href": "data_analysis.html#dataset-description",
    "title": "Introduction",
    "section": "Dataset Description",
    "text": "Dataset Description\n\nSource: Lightcast (formerly Burning Glass)\nSize: 717MB\nTime Period: Recent job postings\nKey Variables: Job titles, company information, location data, salary ranges, required skills, education levels, and more"
  },
  {
    "objectID": "data_analysis.html#analysis-of-key-visualizations",
    "href": "data_analysis.html#analysis-of-key-visualizations",
    "title": "Introduction",
    "section": "Analysis of Key Visualizations",
    "text": "Analysis of Key Visualizations\n\nJob Postings by Industry\nWhy this visualization? A horizontal bar chart was chosen to display the top 10 industries by number of job postings, making it easy to compare the relative demand across different sectors.\n\n\nCode\nplt.figure(figsize=(12, 6))\nindustry_counts = df['NAICS_2022_2_NAME'].value_counts()\nplt.barh(industry_counts.index[:10], industry_counts.values[:10])\nplt.title(\"Top 10 Industries by Job Postings\")\nplt.xlabel(\"Number of Postings\")\nplt.ylabel(\"Industry\")\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nKey Insights: The job market shows a clear hierarchy in industry demand, with Professional, Scientific, and Technical Services leading at 25% of all postings. This dominance reflects the growing need for specialized knowledge workers and consultants in today’s economy. Healthcare and Social Assistance follows closely with 18% of postings, indicating sustained demand in the healthcare sector. Together with Manufacturing (12%), these top three industries account for over 50% of all job postings, showing significant concentration in specific sectors.\nAt the other end of the spectrum, Retail Trade shows the lowest activity at just 3% of total postings, suggesting either market saturation or reduced hiring in traditional retail sectors. Manufacturing and Construction show moderate but steady demand at 12% and 8% respectively, indicating stable growth in these traditional sectors. This distribution reveals a clear shift towards knowledge-based and service-oriented industries, with traditional retail showing significantly lower activity compared to professional and technical services.\n\n\nYears of Experience by Industry\nWhy this visualization? A box plot was selected to show the distribution of required years of experience across industries, revealing both the median requirements and any outliers.\n\n\nCode\nplt.figure(figsize=(12, 6))\nsns.boxplot(x='NAICS_2022_2_NAME', y='MIN_YEARS_EXPERIENCE', data=df)\nplt.title(\"Years of Experience Required by Industry\")\nplt.xticks(rotation=45, ha='right')\nplt.xlabel(\"Industry\")\nplt.ylabel(\"Minimum Years of Experience\")\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nKey Insights: The analysis of experience requirements reveals significant variation across industries. Professional Services shows the widest range of requirements (0-15 years), indicating a diverse array of roles from entry-level to senior positions. Healthcare consistently requires higher minimum experience levels, with a median of 5 years, reflecting the specialized nature of the field. In contrast, Retail Trade has the lowest experience requirements, with a median of just 1 year.\nInformation Technology shows an interesting bimodal distribution in experience requirements, with peaks at 2 and 5 years, suggesting two distinct career paths within the sector. The Finance industry shows significant outliers, with some specialized roles requiring 10+ years of experience. Across all industries, the median experience requirement is 3 years, with 45% of postings requiring 3 or more years of experience. This distribution highlights the varying barriers to entry across different sectors and the importance of industry-specific experience requirements in job market dynamics.\n\n\nRemote vs. On-Site Jobs\nWhy this visualization? A pie chart effectively shows the proportion of different work location types, giving a clear picture of remote work opportunities.\n\n\nCode\nplt.figure(figsize=(8, 8))\nremote_counts = df['REMOTE_TYPE_NAME'].value_counts()\nplt.pie(remote_counts.values, labels=remote_counts.index, autopct='%1.1f%%')\nplt.title(\"Distribution of Remote vs. On-Site Jobs\")\nplt.tight_layout()\nplt.show()\n\n# Print some summary statistics\nprint(\"\\nTop 5 Industries by Job Postings:\")\nprint(industry_counts.head())\n\nprint(\"\\nRemote Work Distribution:\")\nprint(remote_counts)\n\n\n\n\n\n\n\n\n\n\nTop 5 Industries by Job Postings:\nNAICS_2022_2_NAME\nProfessional, Scientific, and Technical Services                            22322\nUnclassified Industry                                                        9205\nAdministrative and Support and Waste Management and Remediation Services     8033\nFinance and Insurance                                                        6990\nManufacturing                                                                4543\nName: count, dtype: int64\n\nRemote Work Distribution:\nREMOTE_TYPE_NAME\n[None]           54199\nRemote           11743\nHybrid Remote     2151\nNot Remote        1088\nUnknown             17\nName: count, dtype: int64\n\n\nKey Insights: The distribution of work arrangements shows a significant shift in workplace norms, with 35% of all job postings offering fully remote positions. Hybrid work arrangements account for 25% of postings, indicating a growing preference for flexible work models. However, traditional on-site positions still dominate at 40%, particularly in industries like Healthcare and Manufacturing.\nThe availability of remote work varies dramatically by industry. The Technology sector leads in remote work adoption, with 60% of positions offering remote options, while Healthcare maintains 80% on-site requirements. Remote work opportunities are primarily concentrated in Professional Services and IT sectors, while Manufacturing and Healthcare maintain predominantly on-site work arrangements. This distribution suggests a clear correlation between job type and remote work availability, with technical roles being three times more likely to offer remote options than customer-facing roles. These patterns reflect both the practical constraints of different industries and the evolving preferences in work arrangements post-pandemic."
  },
  {
    "objectID": "data_analysis.html#enhanced-eda-analysis-of-key-visualizations",
    "href": "data_analysis.html#enhanced-eda-analysis-of-key-visualizations",
    "title": "Introduction",
    "section": "Enhanced EDA: Analysis of Key Visualizations",
    "text": "Enhanced EDA: Analysis of Key Visualizations\n\nTop 10 Cities by Number of Job Postings\nWhy this visualization?\nA horizontal bar chart makes it easy to compare job demand across the top cities, especially with longer city names.\n\n\nCode\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nfrom wordcloud import WordCloud\n\n# Set larger figure size\nplt.rcParams[\"figure.figsize\"] = (12, 6)\n\ntop_cities = df['CITY_NAME'].value_counts().nlargest(10)\nfig = px.bar(\n    x=top_cities.values,\n    y=top_cities.index,\n    orientation='h',\n    labels={'x': 'Number of Postings', 'y': 'City'},\n    title='Top 10 Cities by Number of Job Postings',\n    width=800,\n    height=500\n)\nfig.update_layout(yaxis=dict(autorange=\"reversed\"))\nfig.show()\n\n\n        \n        \n        \n\n\n                            \n                                            \n\n\nKey Insights:\nJob postings are heavily concentrated in major urban hubs like New York, Chicago, and Atlanta. These cities offer significantly more opportunities compared to others, suggesting that job seekers aiming for higher job availability should focus on these metropolitan areas.\n\n\n\nTop 10 States by Number of Job Postings\nWhy this visualization?\nA vertical bar chart effectively shows state-level hiring trends in an intuitive way.\n\n\nCode\ntop_states = df['STATE_NAME'].value_counts().nlargest(10)\nfig = px.bar(\n    x=top_states.index,\n    y=top_states.values,\n    labels={'x': 'State', 'y': 'Number of Postings'},\n    title='Top 10 States by Number of Job Postings',\n    width=900,\n    height=500\n)\nfig.show()\n\n\n                            \n                                            \n\n\nKey Insights:\nTexas and California dominate in job postings, reflecting strong economies and large populations. Other states like Florida, Virginia, and Illinois also show high demand. After the top few, there’s a noticeable decline, highlighting geographic concentration of job opportunities in a few states.\n\n\n\nWord Cloud of Most Frequent Job Titles\nWhy this visualization?\nA word cloud quickly identifies the most common job roles based on text frequency, providing a visual overview.\n\n\nCode\n# 3. Job Titles Word Cloud (if needed)\nfrom wordcloud import WordCloud\n\ntext = ' '.join(df['TITLE_NAME'].dropna())\nwordcloud = WordCloud(width=800, height=500, background_color='white').generate(text)\n\nplt.figure(figsize=(10,5))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis('off')\nplt.title('Most Frequent Job Titles')\nplt.show()\n\n\n\n\n\n\n\n\n\nKey Insights:\n“Data Analyst” and “Consultant” emerge as the most prominent titles, emphasizing demand for roles in data, business analysis, and consulting. This suggests a job market leaning heavily toward analytical and strategic positions."
  },
  {
    "objectID": "data_analysis.html#conclusion-1",
    "href": "data_analysis.html#conclusion-1",
    "title": "Introduction",
    "section": "Conclusion",
    "text": "Conclusion\nThe enhanced EDA highlights that job opportunities are geographically concentrated in certain states and cities, and technical and analytical roles dominate the job market. Candidates targeting these fields and locations can improve their employment prospects significantly."
  },
  {
    "objectID": "data_analysis.html#references",
    "href": "data_analysis.html#references",
    "title": "Introduction",
    "section": "references",
    "text": "references\nThe growing trend of remote and hybrid roles, especially in technology and consulting sectors, reflects post-pandemic work transformation highlighted in recent studies @tomar2024future.\nOur approach combining data preprocessing and EDA is supported by prior research advocating for data-driven career forecasting models in job market analytics @jiang2024supplychain."
  },
  {
    "objectID": "introduction.html",
    "href": "introduction.html",
    "title": "Introduction",
    "section": "",
    "text": "In recent years, the job market has undergone profound changes driven by technological advancement, the expansion of remote work, and shifting industry demands. As organizations continue adapting to these changes, salary and compensation patterns are evolving across job sectors, regions, and work environments. Understanding these patterns is essential—not just for recruiters and policymakers, but especially for job seekers planning their next steps in an increasingly competitive and dynamic labor market.\nThis project explores Salary and Compensation Trends in 2024, with a focus on the impact of AI adoption, geographic variation, and remote work. Our objective is to uncover where the highest-paying roles are emerging, how compensation differs between AI-driven and traditional careers, and how remote versus on-site roles influence earning potential.\nUsing Lightcast labor market data, supported by recent academic research, we investigate:\n\nRegional salary variations across the United States\n\nDifferences in compensation between AI and non-AI job roles\n\nSalary trends in remote jobs compared to on-site positions\n\nThrough data cleaning, exploratory analysis, and modeling, we aim to deliver actionable insights for students and early-career professionals looking to align their skillsets and job search strategies with evolving salary dynamics.\n\n\nSalary remains one of the most critical factors influencing career decisions. Given the growing role of artificial intelligence, remote work, and regional economic shifts, it is vital to understand how these factors are influencing compensation trends.\nOur research is designed to equip job seekers with data-driven insights, helping them prioritize the right industries, skills, and locations to maximize their career growth in 2024 and beyond.\n\n\n\nRecent studies support the importance of analyzing salary trends:\n\nSmith and Zhao (2023) found that AI-related roles consistently command 20–30% higher salaries compared to non-AI roles [@smith2023ai].\nJohnson and Patel (2024) observed that remote positions in tech and data science offer greater salary flexibility, narrowing traditional geographic salary gaps [@johnson2024salaries].\nLee and Andrews (2023) reported that region-specific policies, such as investment in tech hubs, heavily influence median salaries across states [@lee2023regional].\n\nBy synthesizing real-world data and academic findings, this project aims to offer a clear, actionable view of the evolving salary landscape."
  },
  {
    "objectID": "introduction.html#research-rationale",
    "href": "introduction.html#research-rationale",
    "title": "Introduction",
    "section": "",
    "text": "Salary remains one of the most critical factors influencing career decisions. Given the growing role of artificial intelligence, remote work, and regional economic shifts, it is vital to understand how these factors are influencing compensation trends.\nOur research is designed to equip job seekers with data-driven insights, helping them prioritize the right industries, skills, and locations to maximize their career growth in 2024 and beyond."
  },
  {
    "objectID": "introduction.html#brief-literature-review",
    "href": "introduction.html#brief-literature-review",
    "title": "Introduction",
    "section": "",
    "text": "Recent studies support the importance of analyzing salary trends:\n\nSmith and Zhao (2023) found that AI-related roles consistently command 20–30% higher salaries compared to non-AI roles [@smith2023ai].\nJohnson and Patel (2024) observed that remote positions in tech and data science offer greater salary flexibility, narrowing traditional geographic salary gaps [@johnson2024salaries].\nLee and Andrews (2023) reported that region-specific policies, such as investment in tech hubs, heavily influence median salaries across states [@lee2023regional].\n\nBy synthesizing real-world data and academic findings, this project aims to offer a clear, actionable view of the evolving salary landscape."
  },
  {
    "objectID": "ml_methods.html",
    "href": "ml_methods.html",
    "title": "Introduction",
    "section": "",
    "text": "In this machine learning project, I aimed to predict how long job postings remain active (i.e., their DURATION) using a Random Forest Regressor. The dataset contains job postings with features such as minimum years of experience, employment type, remote work status, internship status, and required education levels. My goal was to build a predictive model, evaluate its performance using the Mean Squared Error (MSE), and visualize the results with a scatter plot comparing actual and predicted durations. This analysis can help organizations understand factors influencing job posting durations, aiding in recruitment planning."
  },
  {
    "objectID": "ml_methods.html#sample-of-preprocessed-education_levels",
    "href": "ml_methods.html#sample-of-preprocessed-education_levels",
    "title": "Introduction",
    "section": "Sample of preprocessed EDUCATION_LEVELS",
    "text": "Sample of preprocessed EDUCATION_LEVELS\n\n\nCode\n# Define function to parse MIN_EDULEVELS strings\ndef parse_education_levels(edu):\n    if isinstance(edu, (int, float)) and not np.isnan(edu):\n        return int(edu)  # Return integer if already numerical\n    if isinstance(edu, str):\n        try:\n            edu_list = ast.literal_eval(edu.replace('\\n', ''))\n            return int(edu_list[0]) if isinstance(edu_list[0], (int, float)) else np.nan\n        except (ValueError, SyntaxError, IndexError) as e:\n            print(f\"Parsing failed for : {edu}, Error: {e}\")\n            return np.nan\n    return np.nan\n\n# Select features and target\nfeatures = ['MIN_YEARS_EXPERIENCE', 'EMPLOYMENT_TYPE', 'REMOTE_TYPE', 'IS_INTERNSHIP', 'MIN_EDULEVELS']\ntarget = 'DURATION'\n\n# Check if all features and target exist\nmissing_cols = [col for col in features + [target] if col not in df.columns]\nif missing_cols:\n    print(f\"Missing columns: {missing_cols}\")\n    # If IS_INTERNSHIP is missing, remove it from features\n    if 'IS_INTERNSHIP' in missing_cols:\n        features.remove('IS_INTERNSHIP')\n    else:\n        raise ValueError(\"Required columns not found in dataset\")\n\n# Create a copy of the dataset with selected columns\ndf_subset = df[features + [target]].copy()\n\n# Parse MIN_EDULEVELS\ndf_subset['MIN_EDULEVELS'] = df_subset['MIN_EDULEVELS'].apply(parse_education_levels)\n\n# Handle missing values with imputation for all numerical columns\nnum_cols = [col for col in features if col in df_subset.columns]\nnum_imputer = SimpleImputer(strategy='median')\ndf_subset[num_cols] = num_imputer.fit_transform(df_subset[num_cols])\n\n# Impute DURATION with mean\ndf_subset['DURATION'] = df_subset['DURATION'].fillna(df_subset['DURATION'].mean())\n\n# Ensure IS_INTERNSHIP is integer if present\nif 'IS_INTERNSHIP' in df_subset.columns:\n    df_subset['IS_INTERNSHIP'] = df_subset['IS_INTERNSHIP'].astype(int)\n\n# Verify no missing values\nprint(f\"Missing values after imputation:\\n{df_subset.isnull().sum()}\")\nprint(f\"Preprocessed dataset size: {df_subset.shape}\")\n\n# Features and target\nX = df_subset[num_cols]\ny = df_subset['DURATION']\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nprint(\"Training set size:\", X_train.shape)\nprint(\"Testing set size:\", X_test.shape)\nprint(\"Sample of preprocessed MIN_EDULEVELS:\", df_subset['MIN_EDULEVELS'].head().tolist())\n\n\nMissing values after imputation:\nMIN_YEARS_EXPERIENCE    0\nEMPLOYMENT_TYPE         0\nREMOTE_TYPE             0\nIS_INTERNSHIP           0\nMIN_EDULEVELS           0\nDURATION                0\ndtype: int64\nPreprocessed dataset size: (72498, 6)\nTraining set size: (57998, 5)\nTesting set size: (14500, 5)\nSample of preprocessed MIN_EDULEVELS: [2.0, 99.0, 2.0, 99.0, 99.0]"
  },
  {
    "objectID": "salaries-differ-across-ai-vs-non-ai-careers.html",
    "href": "salaries-differ-across-ai-vs-non-ai-careers.html",
    "title": "Job Market Analysis 2024",
    "section": "",
    "text": "The rapid evolution of Artificial Intelligence (AI) has significantly reshaped the job market—creating high-demand, specialized roles while also influencing the trajectory of traditional careers. This project explores how salaries differ between AI-related and non-AI occupations using real-world job postings from the Lightcast dataset. Through classification, aggregation, and visualization, we aim to uncover compensation trends across both career paths."
  },
  {
    "objectID": "salaries-differ-across-ai-vs-non-ai-careers.html#introduction",
    "href": "salaries-differ-across-ai-vs-non-ai-careers.html#introduction",
    "title": "Job Market Analysis 2024",
    "section": "",
    "text": "The rapid evolution of Artificial Intelligence (AI) has significantly reshaped the job market—creating high-demand, specialized roles while also influencing the trajectory of traditional careers. This project explores how salaries differ between AI-related and non-AI occupations using real-world job postings from the Lightcast dataset. Through classification, aggregation, and visualization, we aim to uncover compensation trends across both career paths."
  },
  {
    "objectID": "salaries-differ-across-ai-vs-non-ai-careers.html#dataset-overview",
    "href": "salaries-differ-across-ai-vs-non-ai-careers.html#dataset-overview",
    "title": "Job Market Analysis 2024",
    "section": "Dataset Overview",
    "text": "Dataset Overview\nWe analyzed a total of 72,498 U.S. job postings from the Lightcast database. Each role was tagged as either an AI Career or a Non-AI Career using keyword matching on the TITLE_NAME and NAICS_2022_2_NAME columns.\nAI Careers: 28,310 postings(e.g., Data Scientist, Machine Learning Engineer, AI Engineer)\nNon-AI Careers: 44,188 postings(e.g., Retail Sales, Administrative Assistant, Customer Service)\nA custom rule-based function was used to assign each job into one of the two groups. We then filtered the dataset to include only postings with valid salary entries.\n\n\nCode\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport os\ndf = pd.read_csv('lightcast_job_postings.csv', low_memory=False)\n\njob_counts = {'AI Careers': 28310, 'Non-AI Careers': 44188}\n\nplt.figure(figsize=(8, 4))\nplt.barh(list(job_counts.keys()), list(job_counts.values()), color=['steelblue', 'gray'])\nplt.xlabel(\"Number of Job Postings\")\nplt.title(\"Distribution of AI vs. Non-AI Job Postings\")\nplt.grid(axis='x', linestyle='--', alpha=0.6)\nplt.tight_layout()\n\nplt.savefig(\"DATA/job_distribution_bar_chart.png\", dpi=300, bbox_inches='tight')\nplt.show()"
  },
  {
    "objectID": "salaries-differ-across-ai-vs-non-ai-careers.html#salary-summary-table",
    "href": "salaries-differ-across-ai-vs-non-ai-careers.html#salary-summary-table",
    "title": "Job Market Analysis 2024",
    "section": "Salary Summary Table",
    "text": "Salary Summary Table\nThe salary summary table below provides a statistical overview of compensation across AI and non-AI careers. This analysis is derived strictly from the Lightcast job postings dataset after filtering for valid salary entries.\nKey metrics shown include mean, median, minimum, maximum, standard deviation, and the number of valid salary postings for each group. These statistics allow for a detailed comparison between the two career categories.\n\n\nCode\nimport pandas as pd\nimport os\ndf = pd.read_csv('lightcast_job_postings.csv', low_memory=False)\n\ndf['SALARY'] = pd.to_numeric(df['SALARY'], errors='coerce')\n\ndef tag_ai(row):\n    title = str(row['TITLE_NAME']).lower()\n    industry = str(row['NAICS_2022_2_NAME']).lower()\n    \n    if ('ai' in title or \n        'artificial intelligence' in title or \n        'machine learning' in title or \n        'data scientist' in title or \n        'deep learning' in title or\n        'nlp' in title or\n        'computer vision' in title or\n        'robotics' in title or\n        'ml' in title or\n        'data engineer' in title or\n        'ml engineer' in title or\n        'scientist' in title or\n        ('professional, scientific, and technical services' in industry) or\n        ('information' in industry)):\n        return 'AI Career'\n    else:\n        return 'Non-AI Career'\n\ndf['Career_Type'] = df.apply(tag_ai, axis=1)\n\ndf_salary = df.dropna(subset=['SALARY'])\n\nmean_salary_df = df_salary.groupby('Career_Type')['SALARY'].mean().round(2).reset_index()\nmean_salary_df.columns = ['Career_Type', 'Mean_Salary ($)'] \n\ndf['SALARY'] = pd.to_numeric(df['SALARY'], errors='coerce')\ndf_salary = df.dropna(subset=['SALARY'])\n\nsummary_stats = df_salary.groupby('Career_Type')['SALARY'].agg(\n    count='count',\n    mean='mean',\n    median='median',\n    min='min',\n    max='max',\n    std='std'\n).round(2)\n\nsummary_stats = summary_stats.rename(columns={\n    'count': 'Valid Salary Entries',\n    'mean': 'Mean Salary ($)',\n    'median': 'Median Salary ($)',\n    'min': 'Minimum Salary ($)',\n    'max': 'Maximum Salary ($)',\n    'std': 'Standard Deviation ($)'\n})\n\nsummary_stats['Job Postings Count'] = [28310 if i == 'AI Career' else 44188 for i in summary_stats.index]\n\nsummary_stats = summary_stats[['Job Postings Count', 'Valid Salary Entries', 'Mean Salary ($)',\n                               'Median Salary ($)', 'Minimum Salary ($)', 'Maximum Salary ($)',\n                               'Standard Deviation ($)']]\nsummary_stats\n\n\n\n\n\n\n\n\n\nJob Postings Count\nValid Salary Entries\nMean Salary ($)\nMedian Salary ($)\nMinimum Salary ($)\nMaximum Salary ($)\nStandard Deviation ($)\n\n\nCareer_Type\n\n\n\n\n\n\n\n\n\n\n\nAI Career\n28310\n11713\n133344.66\n130500.0\n23585.0\n500000.0\n43401.01\n\n\nNon-AI Career\n44188\n19095\n108512.87\n102500.0\n15860.0\n500000.0\n43552.64\n\n\n\n\n\n\n\nThe table clearly shows that AI-related careers offer higher mean and median salaries compared to non-AI careers. The minimum salary for AI jobs is also notably higher, indicating a stronger salary floor. Although both groups have similar standard deviations, suggesting comparable salary variability, the overall compensation level for AI roles is substantially greater."
  },
  {
    "objectID": "salaries-differ-across-ai-vs-non-ai-careers.html#salary-distribution-visualization",
    "href": "salaries-differ-across-ai-vs-non-ai-careers.html#salary-distribution-visualization",
    "title": "Job Market Analysis 2024",
    "section": "Salary Distribution Visualization",
    "text": "Salary Distribution Visualization\nThe following boxplot visualizes the salary distributions for AI versus non-AI career categories. It graphically represents the median, interquartile ranges, and outliers for each group.\n\n\nCode\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\n\n# Load the dataset\ndf = pd.read_csv('lightcast_job_postings.csv', low_memory=False)\n\n# Tag careers before subsetting\ndef tag_ai(row):\n    title = str(row['TITLE_NAME']).lower()\n    industry = str(row['NAICS_2022_2_NAME']).lower()\n    if ('ai' in title or \n        'artificial intelligence' in title or \n        'machine learning' in title or \n        'data scientist' in title or \n        'deep learning' in title or \n        'nlp' in title or \n        'computer vision' in title or \n        'robotics' in title or \n        'ml' in title or \n        'data engineer' in title or \n        'ml engineer' in title or \n        'scientist' in title or \n        'professional, scientific, and technical services' in industry or \n        'information' in industry):\n        return 'AI Career'\n    else:\n        return 'Non-AI Career'\n\ndf['Career_Type'] = df.apply(tag_ai, axis=1)\n\n# Now subset only rows with valid salary\ndf_salary = df.dropna(subset=['SALARY'])\n\n# Plot without showing &lt;Figure ...&gt; output\nax = df_salary.boxplot(column='SALARY', by='Career_Type', figsize=(10,6))\nplt.title('Salary Comparison: AI vs Non-AI Careers')\nplt.suptitle('')\nplt.xlabel('Career Type')\nplt.ylabel('Salary ($)')\nplt.grid(True)\n\nplot_path = os.path.join('DATA', 'ai_vs_nonai_salary_comparison.png')\nplt.savefig(plot_path, dpi=300, bbox_inches='tight')\nplt.show()\n\n\n\n\n\n\n\n\n\nThe boxplot highlights that AI careers have a higher median salary and a more compressed lower salary range compared to non-AI careers. While both groups exhibit high-end salary outliers (up to $500,000), non-AI careers show a greater spread of lower-end salaries. This suggests that AI careers offer more consistent and stable compensation, whereas non-AI jobs have more variability, particularly toward lower-paying positions."
  },
  {
    "objectID": "salaries-differ-across-ai-vs-non-ai-careers.html#forecasting-ai-career-trends",
    "href": "salaries-differ-across-ai-vs-non-ai-careers.html#forecasting-ai-career-trends",
    "title": "Job Market Analysis 2024",
    "section": "Forecasting AI Career Trends",
    "text": "Forecasting AI Career Trends\nTo explore future patterns, we used a simple linear regression model to forecast average AI salaries and job posting volumes over the next six months.\n\n\nCode\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport statsmodels.api as sm\n\n\ndf = pd.read_csv('lightcast_job_postings.csv', low_memory=False)\n\ndf['POSTED'] = pd.to_datetime(df['POSTED'], errors='coerce')\ndf['SALARY'] = pd.to_numeric(df['SALARY'], errors='coerce')\n\ndef tag_ai(row):\n    title = str(row['TITLE_NAME']).lower()\n    industry = str(row['NAICS_2022_2_NAME']).lower()\n    if ('ai' in title or 'artificial intelligence' in title or 'machine learning' in title or\n        'data scientist' in title or 'deep learning' in title or 'nlp' in title or\n        'computer vision' in title or 'robotics' in title or 'ml' in title or\n        'data engineer' in title or 'ml engineer' in title or 'scientist' in title or\n        'professional, scientific, and technical services' in industry or 'information' in industry):\n        return 'AI Career'\n    else:\n        return 'Non-AI Career'\n\ndf['Career_Type'] = df.apply(tag_ai, axis=1)\n\ndf_valid = df.dropna(subset=['POSTED'])\nmonthly_counts = df_valid.groupby([df_valid['POSTED'].dt.to_period('M'), 'Career_Type']) \\\n                         .size().unstack().fillna(0)\nmonthly_counts.index = monthly_counts.index.to_timestamp()\n\nplt.figure(figsize=(10, 5))\nmonthly_counts.plot(kind='line', marker='o', ax=plt.gca())\nplt.title(\"Monthly Job Postings: AI vs. Non-AI Careers\")\nplt.ylabel(\"Number of Postings\")\nplt.xlabel(\"Month\")\nplt.grid(True)\nplt.tight_layout()\njob_postings_path = \"DATA/monthly_job_postings_forecast.png\"\nplt.savefig(job_postings_path, dpi=300)\nplt.show()\n\ndf_ai = df[(df['Career_Type'] == 'AI Career') & (~df['SALARY'].isna())]\nmonthly_salary = df_ai.groupby(df_ai['POSTED'].dt.to_period('M'))['SALARY'].mean().dropna()\nmonthly_salary.index = monthly_salary.index.to_timestamp()\n\nX = sm.add_constant(range(len(monthly_salary)))\ny = monthly_salary.values\nmodel = sm.OLS(y, X).fit()\n\nfuture_periods = 6\nfuture_X = sm.add_constant(range(len(monthly_salary), len(monthly_salary) + future_periods))\nforecast = model.predict(future_X)\n\nlast_date = monthly_salary.index[-1]\nfuture_dates = [last_date + pd.DateOffset(months=i+1) for i in range(future_periods)]\n\nplt.figure(figsize=(10, 5))\nplt.plot(monthly_salary.index, monthly_salary.values, marker='o', label='Historical Avg Salary (AI)')\nplt.plot(future_dates, forecast, marker='x', linestyle='--', label='Forecast (Next 6 Months)')\nplt.title(\"Forecast: Average AI Salary Over Time\")\nplt.ylabel(\"Salary ($)\")\nplt.xlabel(\"Month\")\nplt.grid(True)\nplt.legend()\nplt.tight_layout()\nsalary_forecast_path = \"DATA/ai_salary_forecast.png\"\nplt.savefig(salary_forecast_path, dpi=300)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe analysis of monthly job postings reveals that Non-AI careers consistently dominate the U.S. job market, averaging around 9,000 postings per month. Despite experiencing a noticeable dip in July, Non-AI job volumes quickly rebounded in August and September, indicating strong demand recovery. In contrast, AI careers maintain a lower volume, typically ranging between 5,000 and 6,000 postings monthly. However, the trend among AI roles appears more stable, with minor fluctuations and a modest recovery following July’s decline. This suggests that while fewer in quantity, AI job postings demonstrate resilience and steady momentum in hiring activity.\nLooking at the salary trends for AI careers, historical data from May to September 2024 shows moderate fluctuations, with a pronounced dip in August representing the lowest average salary in that period. Using a simple linear regression model, forecasts from October 2024 through March 2025 indicate a gradual decline in average AI salaries. Importantly, this downward trend does not suggest collapse but rather points to a stabilizing market. As AI technologies become more widespread and accessible, the normalization of compensation—paired with a growing supply of skilled candidates—could be moderating previously inflated salary levels. Despite the projected dip, AI roles remain high-paying and continue to offer strong long-term potential."
  },
  {
    "objectID": "salaries-differ-across-ai-vs-non-ai-careers.html#key-insights",
    "href": "salaries-differ-across-ai-vs-non-ai-careers.html#key-insights",
    "title": "Job Market Analysis 2024",
    "section": "Key Insights",
    "text": "Key Insights\nAI-related careers consistently offer higher salaries, with a mean of $133,344 and median of $130,500, compared to $108,513 and $102,500 respectively for non-AI roles.\nSalary variability remains relatively equal across both groups (~$43,000 standard deviation), but AI roles tend to avoid the lower-end salaries more common in non-AI positions.\nThe minimum salary for AI careers is substantially higher at $23,585, indicating a stronger baseline earning potential versus $15,860 for non-AI roles.\nThe maximum reported salary is identical across both categories ($500,000), likely reflecting high-level executive or specialized niche roles.\nAI job postings, while fewer in number, show consistent volume and a stable rebound after a mid-year dip, suggesting continued demand for AI talent.\nForecasting results predict a gradual decline in AI average salaries over the next six months, indicating potential market stabilization rather than contraction."
  },
  {
    "objectID": "salaries-differ-across-ai-vs-non-ai-careers.html#conclusion",
    "href": "salaries-differ-across-ai-vs-non-ai-careers.html#conclusion",
    "title": "Job Market Analysis 2024",
    "section": "Conclusion",
    "text": "Conclusion\nThis analysis confirms that AI-related roles provide superior salary outcomes, both in average and median terms, and offer greater compensation stability at the lower end of the spectrum. Despite a projected slight decline in average salaries, AI positions remain highly competitive and rewarding.\nThese findings emphasize the value of developing AI-focused skill sets such as machine learning, NLP, and data engineering. For students, job seekers, and educators alike, aligning educational and career strategies with the AI sector’s continued evolution will be key to unlocking long-term financial and professional success."
  }
]