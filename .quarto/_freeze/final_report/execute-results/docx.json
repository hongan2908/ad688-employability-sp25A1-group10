{
  "hash": "888173911ee5fd80de02c85aaf6df986",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Final Report\"\nsubtitle: \"Salary & Compensation Trends - Job Market Analysis 2024\"\nauthor:\n  - name: Group 10\n    affiliations:\n      - id: bu\n        name: Boston University\n        city: Boston\n        state: MA\ndate: today\ndate-modified: today\ndate-format: long\nformat: \n  docx: default\n---\n\n---\n\ntitle: \"Home\"\nsubtitle: \"Salary & Compensation Trends - Job Market Analysis 2024\"\nauthor:\n  - name: \"Ritusri Mohan , An Ly\"\n    affiliations:\n      - id: bu\n        name: Boston University\n        city: Boston\n        state: MA\nbibliography: references.bib\ncsl: csl/econometrica.csl\nformat: \n  html:\n    toc: true\n    number-sections: true\n    df-print: paged\n---\n\n## Why is this topic important?\n\nArtificial Intelligence (AI) is no longer a niche field—it is a driving force behind economic transformation in 2024. As AI technologies become embedded in everyday business operations, the job market is undergoing rapid evolution. One of the most visible impacts is on compensation. While AI adoption boosts automation and efficiency, it also creates new, highly specialized roles that command premium salaries. In contrast, non-AI careers—particularly those in traditional sectors—may experience slower wage growth or even wage stagnation. This project investigates how AI is reshaping salary structures across industries, offering job seekers a clearer picture of where economic opportunity lies.\n\n## What trends make this a crucial area of study in 2024?\n\nThis topic is critical for understanding and navigating today's labor market. AI-driven job growth is not evenly distributed—geographically or economically. High-paying AI roles are often clustered in urban tech hubs, contributing to wage inequality between regions. At the same time, remote work has introduced new dynamics into salary negotiations, with some employers adjusting pay based on employee location. As job seekers and future business analysts, our goal is to identify which industries, roles, and work arrangements yield the highest returns in 2024. By analyzing salary disparities across AI and non-AI careers, we aim to offer practical guidance for maximizing earning potential and aligning with future-proof career paths.\n\n## What do you expect to find in your analysis?\n\nHow do salaries differ across AI vs. non-AI careers?\n\nWhat regions offer the highest-paying jobs in AI-related and traditional careers?\n\nAre remote jobs better paying than in-office roles?\n\nWhat industries saw the biggest wage growth in 2024?\n\n---\ntitle: \"Introduction\"\nsubtitle: \"Salary & Compensation Trends - Job Market Analysis 2024\"\nauthor:\n  - name: \"Ritusri Mohan , An Ly\"\n    affiliations:\n      - id: bu\n        name: Boston University\n        city: Boston\n        state: MA\nbibliography: references.bib\ncsl: csl/econometrica.csl\nformat: \n  html:\n    toc: true\n    number-sections: true\n    df-print: paged\n---\n\n# Introduction\n\nIn recent years, the job market has undergone profound changes driven by technological advancement, the expansion of remote work, and shifting industry demands. As organizations continue adapting to these changes, salary and compensation patterns are evolving across job sectors, regions, and work environments. Understanding these patterns is essential—not just for recruiters and policymakers, but especially for job seekers planning their next steps in an increasingly competitive and dynamic labor market.\n\nThis project explores **Salary and Compensation Trends in 2024**, with a focus on the impact of AI adoption, geographic variation, and remote work. Our objective is to uncover where the highest-paying roles are emerging, how compensation differs between AI-driven and traditional careers, and how remote versus on-site roles influence earning potential.\n\nUsing Lightcast labor market data, supported by recent academic research, we investigate:\n\n- Regional salary variations across the United States  \n- Differences in compensation between AI and non-AI job roles  \n- Salary trends in remote jobs compared to on-site positions  \n\nThrough data cleaning, exploratory analysis, and modeling, we aim to deliver actionable insights for students and early-career professionals looking to align their skillsets and job search strategies with evolving salary dynamics.\n\n## Research Rationale\n\nSalary remains one of the most critical factors influencing career decisions. Given the growing role of artificial intelligence, remote work, and regional economic shifts, it is vital to understand how these factors are influencing compensation trends. \n\nOur research is designed to equip job seekers with data-driven insights, helping them prioritize the right industries, skills, and locations to maximize their career growth in 2024 and beyond.\n\n## Brief Literature Review\n\nRecent studies support the importance of analyzing salary trends:\n\n- Smith and Zhao (2023) found that AI-related roles consistently command 20–30% higher salaries compared to non-AI roles [@smith2023ai].\n- Johnson and Patel (2024) observed that remote positions in tech and data science offer greater salary flexibility, narrowing traditional geographic salary gaps [@johnson2024salaries].\n- Lee and Andrews (2023) reported that region-specific policies, such as investment in tech hubs, heavily influence median salaries across states [@lee2023regional].\n\nBy synthesizing real-world data and academic findings, this project aims to offer a clear, actionable view of the evolving salary landscape.\n\n\n---\n\ntitle: \"Data Analysis\"\nsubtitle: \"Comprehensive Data Cleaning & Exploratory Analysis of Job Market Trends\"\nauthor:\n  - name: Advait Pillai, Ritusri Mohan\n    affiliations:\n      - id: bu\n        name: Boston University\n        city: Boston\n        state: MA\nformat: \n  html:\n    toc: true\n    number-sections: true\n    df-print: paged\nbibliography: references.bib\ncsl: csl/econometrica.csl\n---\n\n# Introduction\n\nThis document presents a comprehensive analysis of job market trends using the Lightcast job postings dataset. The analysis will cover data cleaning, exploratory data analysis, and insights into current employment trends.\n\n# Data Overview\n\nThe dataset used for this analysis is the Lightcast job postings dataset, which contains detailed information about job listings across various industries and locations.\n\n## Dataset Description\n\n- **Source**: Lightcast (formerly Burning Glass)\n- **Size**: 717MB\n- **Time Period**: Recent job postings\n- **Key Variables**: Job titles, company information, location data, salary ranges, required skills, education levels, and more\n\n# Data Cleaning\n\n::: {#data-cleaning .cell message='false' execution_count=1}\n``` {.python .cell-code}\n# Import necessary libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\n\n# Set display options\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', 100)\n\n# Auto-download CSV if missing\ncsv_path = 'region_analysis/lightcast_job_postings.csv'\nif not os.path.exists(csv_path):\n    print(f\"{csv_path} not found! Attempting to download...\")\n\n    os.makedirs('region_analysis', exist_ok=True)\n\n    try:\n        import gdown\n    except ImportError:\n        !pip install gdown\n        import gdown\n\n    file_id = '1V2GCHGt2dkFGqVBeoUFckU4IhUgk4ocQ'  # <--- your actual file ID\n    url = f'https://drive.google.com/uc?id={file_id}'\n    gdown.download(url, csv_path, quiet=False)\n    print(\"Download complete!\")\nelse:\n    print(f\"{csv_path} found. Proceeding...\")\n\n# Load the dataset\ndf = pd.read_csv('region_analysis/lightcast_job_postings.csv')\n\n# 1. Dropping unnecessary columns\ncolumns_to_drop = [\n    \"ID\", \"URL\", \"ACTIVE_URLS\", \"DUPLICATES\", \"LAST_UPDATED_TIMESTAMP\",\n    \"NAICS2\", \"NAICS3\", \"NAICS4\", \"NAICS5\", \"NAICS6\",\n    \"SOC_2\", \"SOC_3\", \"SOC_5\"\n]\ndf.drop(columns=columns_to_drop, inplace=True)\nprint(\"After dropping columns, shape:\", df.shape)\n\n# 2. Handling Missing Values\n# Calculate percentage of missing values\nmissing_percent = (df.isnull().sum() / len(df)) * 100\nmissing_percent = missing_percent[missing_percent > 0].sort_values(ascending=False)\n\n# Visualize missing data\nplt.figure(figsize=(12, 8))\nsns.barplot(x=missing_percent.index, y=missing_percent.values)\nplt.xticks(rotation=90)\nplt.title(\"Percentage of Missing Values by Column\")\nplt.ylabel(\"Percentage Missing\")\nplt.show()\n\n# Drop columns with >50% missing values\ndf.dropna(thresh=len(df) * 0.5, axis=1, inplace=True)\nprint(\"\\nAfter dropping columns with >50% missing values, shape:\", df.shape)\n\n# Fill missing values\n# For numerical columns\nnumeric_columns = df.select_dtypes(include=[np.number]).columns\nfor col in numeric_columns:\n    df[col].fillna(df[col].median(), inplace=True)\n\n# For categorical columns\ncategorical_columns = df.select_dtypes(include=['object']).columns\nfor col in categorical_columns:\n    df[col].fillna(\"Unknown\", inplace=True)\n\nprint(\"\\nMissing values after cleaning:\")\nprint(df.isnull().sum().sum())\n\n# 3. Removing duplicates\ndf = df.drop_duplicates(subset=[\"TITLE\", \"COMPANY\", \"LOCATION\", \"POSTED\"], keep=\"first\")\nprint(\"\\nAfter removing duplicates, final shape:\", df.shape)\n\n# Display cleaned dataset information\nprint(\"\\nCleaned dataset information:\")\nprint(\"\\nColumns in cleaned dataset:\")\nprint(df.columns.tolist())\nprint(\"\\nFirst few rows of cleaned dataset:\")\ndf.head()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nregion_analysis/lightcast_job_postings.csv found. Proceeding...\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nAfter dropping columns, shape: (72498, 118)\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](final_report_files/figure-docx/data-cleaning-output-3.png){#data-cleaning-1}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\nAfter dropping columns with >50% missing values, shape: (72498, 108)\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\nMissing values after cleaning:\n0\n\nAfter removing duplicates, final shape: (69198, 108)\n\nCleaned dataset information:\n\nColumns in cleaned dataset:\n['LAST_UPDATED_DATE', 'POSTED', 'EXPIRED', 'DURATION', 'SOURCE_TYPES', 'SOURCES', 'TITLE_RAW', 'BODY', 'MODELED_EXPIRED', 'MODELED_DURATION', 'COMPANY', 'COMPANY_NAME', 'COMPANY_RAW', 'COMPANY_IS_STAFFING', 'EDUCATION_LEVELS', 'EDUCATION_LEVELS_NAME', 'MIN_EDULEVELS', 'MIN_EDULEVELS_NAME', 'EMPLOYMENT_TYPE', 'EMPLOYMENT_TYPE_NAME', 'MIN_YEARS_EXPERIENCE', 'IS_INTERNSHIP', 'REMOTE_TYPE', 'REMOTE_TYPE_NAME', 'LOCATION', 'CITY', 'CITY_NAME', 'COUNTY', 'COUNTY_NAME', 'MSA', 'MSA_NAME', 'STATE', 'STATE_NAME', 'COUNTY_OUTGOING', 'COUNTY_NAME_OUTGOING', 'COUNTY_INCOMING', 'COUNTY_NAME_INCOMING', 'MSA_OUTGOING', 'MSA_NAME_OUTGOING', 'MSA_INCOMING', 'MSA_NAME_INCOMING', 'NAICS2_NAME', 'NAICS3_NAME', 'NAICS4_NAME', 'NAICS5_NAME', 'NAICS6_NAME', 'TITLE', 'TITLE_NAME', 'TITLE_CLEAN', 'SKILLS', 'SKILLS_NAME', 'SPECIALIZED_SKILLS', 'SPECIALIZED_SKILLS_NAME', 'CERTIFICATIONS', 'CERTIFICATIONS_NAME', 'COMMON_SKILLS', 'COMMON_SKILLS_NAME', 'SOFTWARE_SKILLS', 'SOFTWARE_SKILLS_NAME', 'ONET', 'ONET_NAME', 'ONET_2019', 'ONET_2019_NAME', 'CIP6', 'CIP6_NAME', 'CIP4', 'CIP4_NAME', 'CIP2', 'CIP2_NAME', 'SOC_2021_2', 'SOC_2021_2_NAME', 'SOC_2021_3', 'SOC_2021_3_NAME', 'SOC_2021_4', 'SOC_2021_4_NAME', 'SOC_2021_5', 'SOC_2021_5_NAME', 'LOT_CAREER_AREA', 'LOT_CAREER_AREA_NAME', 'LOT_OCCUPATION', 'LOT_OCCUPATION_NAME', 'LOT_SPECIALIZED_OCCUPATION', 'LOT_SPECIALIZED_OCCUPATION_NAME', 'LOT_OCCUPATION_GROUP', 'LOT_OCCUPATION_GROUP_NAME', 'LOT_V6_SPECIALIZED_OCCUPATION', 'LOT_V6_SPECIALIZED_OCCUPATION_NAME', 'LOT_V6_OCCUPATION', 'LOT_V6_OCCUPATION_NAME', 'LOT_V6_OCCUPATION_GROUP', 'LOT_V6_OCCUPATION_GROUP_NAME', 'LOT_V6_CAREER_AREA', 'LOT_V6_CAREER_AREA_NAME', 'SOC_2_NAME', 'SOC_3_NAME', 'SOC_4', 'SOC_4_NAME', 'SOC_5_NAME', 'NAICS_2022_2', 'NAICS_2022_2_NAME', 'NAICS_2022_3', 'NAICS_2022_3_NAME', 'NAICS_2022_4', 'NAICS_2022_4_NAME', 'NAICS_2022_5', 'NAICS_2022_5_NAME', 'NAICS_2022_6', 'NAICS_2022_6_NAME']\n\nFirst few rows of cleaned dataset:\n```\n:::\n\n::: {#data-cleaning-2 .cell-output .cell-output-display execution_count=1}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>LAST_UPDATED_DATE</th>\n      <th>POSTED</th>\n      <th>EXPIRED</th>\n      <th>DURATION</th>\n      <th>SOURCE_TYPES</th>\n      <th>SOURCES</th>\n      <th>TITLE_RAW</th>\n      <th>BODY</th>\n      <th>MODELED_EXPIRED</th>\n      <th>MODELED_DURATION</th>\n      <th>COMPANY</th>\n      <th>COMPANY_NAME</th>\n      <th>COMPANY_RAW</th>\n      <th>COMPANY_IS_STAFFING</th>\n      <th>EDUCATION_LEVELS</th>\n      <th>EDUCATION_LEVELS_NAME</th>\n      <th>MIN_EDULEVELS</th>\n      <th>MIN_EDULEVELS_NAME</th>\n      <th>EMPLOYMENT_TYPE</th>\n      <th>EMPLOYMENT_TYPE_NAME</th>\n      <th>MIN_YEARS_EXPERIENCE</th>\n      <th>IS_INTERNSHIP</th>\n      <th>REMOTE_TYPE</th>\n      <th>REMOTE_TYPE_NAME</th>\n      <th>LOCATION</th>\n      <th>CITY</th>\n      <th>CITY_NAME</th>\n      <th>COUNTY</th>\n      <th>COUNTY_NAME</th>\n      <th>MSA</th>\n      <th>MSA_NAME</th>\n      <th>STATE</th>\n      <th>STATE_NAME</th>\n      <th>COUNTY_OUTGOING</th>\n      <th>COUNTY_NAME_OUTGOING</th>\n      <th>COUNTY_INCOMING</th>\n      <th>COUNTY_NAME_INCOMING</th>\n      <th>MSA_OUTGOING</th>\n      <th>MSA_NAME_OUTGOING</th>\n      <th>MSA_INCOMING</th>\n      <th>MSA_NAME_INCOMING</th>\n      <th>NAICS2_NAME</th>\n      <th>NAICS3_NAME</th>\n      <th>NAICS4_NAME</th>\n      <th>NAICS5_NAME</th>\n      <th>NAICS6_NAME</th>\n      <th>TITLE</th>\n      <th>TITLE_NAME</th>\n      <th>TITLE_CLEAN</th>\n      <th>SKILLS</th>\n      <th>SKILLS_NAME</th>\n      <th>SPECIALIZED_SKILLS</th>\n      <th>SPECIALIZED_SKILLS_NAME</th>\n      <th>CERTIFICATIONS</th>\n      <th>CERTIFICATIONS_NAME</th>\n      <th>COMMON_SKILLS</th>\n      <th>COMMON_SKILLS_NAME</th>\n      <th>SOFTWARE_SKILLS</th>\n      <th>SOFTWARE_SKILLS_NAME</th>\n      <th>ONET</th>\n      <th>ONET_NAME</th>\n      <th>ONET_2019</th>\n      <th>ONET_2019_NAME</th>\n      <th>CIP6</th>\n      <th>CIP6_NAME</th>\n      <th>CIP4</th>\n      <th>CIP4_NAME</th>\n      <th>CIP2</th>\n      <th>CIP2_NAME</th>\n      <th>SOC_2021_2</th>\n      <th>SOC_2021_2_NAME</th>\n      <th>SOC_2021_3</th>\n      <th>SOC_2021_3_NAME</th>\n      <th>SOC_2021_4</th>\n      <th>SOC_2021_4_NAME</th>\n      <th>SOC_2021_5</th>\n      <th>SOC_2021_5_NAME</th>\n      <th>LOT_CAREER_AREA</th>\n      <th>LOT_CAREER_AREA_NAME</th>\n      <th>LOT_OCCUPATION</th>\n      <th>LOT_OCCUPATION_NAME</th>\n      <th>LOT_SPECIALIZED_OCCUPATION</th>\n      <th>LOT_SPECIALIZED_OCCUPATION_NAME</th>\n      <th>LOT_OCCUPATION_GROUP</th>\n      <th>LOT_OCCUPATION_GROUP_NAME</th>\n      <th>LOT_V6_SPECIALIZED_OCCUPATION</th>\n      <th>LOT_V6_SPECIALIZED_OCCUPATION_NAME</th>\n      <th>LOT_V6_OCCUPATION</th>\n      <th>LOT_V6_OCCUPATION_NAME</th>\n      <th>LOT_V6_OCCUPATION_GROUP</th>\n      <th>LOT_V6_OCCUPATION_GROUP_NAME</th>\n      <th>LOT_V6_CAREER_AREA</th>\n      <th>LOT_V6_CAREER_AREA_NAME</th>\n      <th>SOC_2_NAME</th>\n      <th>SOC_3_NAME</th>\n      <th>SOC_4</th>\n      <th>SOC_4_NAME</th>\n      <th>SOC_5_NAME</th>\n      <th>NAICS_2022_2</th>\n      <th>NAICS_2022_2_NAME</th>\n      <th>NAICS_2022_3</th>\n      <th>NAICS_2022_3_NAME</th>\n      <th>NAICS_2022_4</th>\n      <th>NAICS_2022_4_NAME</th>\n      <th>NAICS_2022_5</th>\n      <th>NAICS_2022_5_NAME</th>\n      <th>NAICS_2022_6</th>\n      <th>NAICS_2022_6_NAME</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>9/6/2024</td>\n      <td>6/2/2024</td>\n      <td>6/8/2024</td>\n      <td>6.0</td>\n      <td>[\\n  \"Company\"\\n]</td>\n      <td>[\\n  \"brassring.com\"\\n]</td>\n      <td>Enterprise Analyst (II-III)</td>\n      <td>31-May-2024\\n\\nEnterprise Analyst (II-III)\\n\\n...</td>\n      <td>6/8/2024</td>\n      <td>6.0</td>\n      <td>894731.0</td>\n      <td>Murphy USA</td>\n      <td>Murphy USA</td>\n      <td>False</td>\n      <td>[\\n  2\\n]</td>\n      <td>[\\n  \"Bachelor's degree\"\\n]</td>\n      <td>2.0</td>\n      <td>Bachelor's degree</td>\n      <td>1.0</td>\n      <td>Full-time (&gt; 32 hours)</td>\n      <td>2.0</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>[None]</td>\n      <td>{\\n  \"lat\": 33.20763,\\n  \"lon\": -92.6662674\\n}</td>\n      <td>RWwgRG9yYWRvLCBBUg==</td>\n      <td>El Dorado, AR</td>\n      <td>5139.0</td>\n      <td>Union, AR</td>\n      <td>20980.0</td>\n      <td>El Dorado, AR</td>\n      <td>5.0</td>\n      <td>Arkansas</td>\n      <td>5139.0</td>\n      <td>Union, AR</td>\n      <td>5139.0</td>\n      <td>Union, AR</td>\n      <td>20980.0</td>\n      <td>El Dorado, AR</td>\n      <td>20980.0</td>\n      <td>El Dorado, AR</td>\n      <td>Retail Trade</td>\n      <td>Motor Vehicle and Parts Dealers</td>\n      <td>Automotive Parts, Accessories, and Tire Retailers</td>\n      <td>Automotive Parts and Accessories Retailers</td>\n      <td>Automotive Parts and Accessories Retailers</td>\n      <td>ET29C073C03D1F86B4</td>\n      <td>Enterprise Analysts</td>\n      <td>enterprise analyst ii iii</td>\n      <td>[\\n  \"KS126DB6T061MHD7RTGQ\",\\n  \"KS126706DPFD3...</td>\n      <td>[\\n  \"Merchandising\",\\n  \"Mathematics\",\\n  \"Pr...</td>\n      <td>[\\n  \"KS126DB6T061MHD7RTGQ\",\\n  \"KS128006L3V0H...</td>\n      <td>[\\n  \"Merchandising\",\\n  \"Predictive Modeling\"...</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[\\n  \"KS126706DPFD3354M7YK\",\\n  \"KS1280B68GD79...</td>\n      <td>[\\n  \"Mathematics\",\\n  \"Presentations\",\\n  \"Re...</td>\n      <td>[\\n  \"KS440W865GC4VRBW6LJP\",\\n  \"KS13USA80NE38...</td>\n      <td>[\\n  \"SQL (Programming Language)\",\\n  \"Power B...</td>\n      <td>15-2051.01</td>\n      <td>Business Intelligence Analysts</td>\n      <td>15-2051.01</td>\n      <td>Business Intelligence Analysts</td>\n      <td>[\\n  \"45.0601\",\\n  \"27.0101\"\\n]</td>\n      <td>[\\n  \"Economics, General\",\\n  \"Mathematics, Ge...</td>\n      <td>[\\n  \"45.06\",\\n  \"27.01\"\\n]</td>\n      <td>[\\n  \"Economics\",\\n  \"Mathematics\"\\n]</td>\n      <td>[\\n  \"45\",\\n  \"27\"\\n]</td>\n      <td>[\\n  \"Social Sciences\",\\n  \"Mathematics and St...</td>\n      <td>15-0000</td>\n      <td>Computer and Mathematical Occupations</td>\n      <td>15-2000</td>\n      <td>Mathematical Science Occupations</td>\n      <td>15-2050</td>\n      <td>Data Scientists</td>\n      <td>15-2051</td>\n      <td>Data Scientists</td>\n      <td>23.0</td>\n      <td>Information Technology and Computer Science</td>\n      <td>231010.0</td>\n      <td>Business Intelligence Analyst</td>\n      <td>23101011.0</td>\n      <td>General ERP Analyst / Consultant</td>\n      <td>2310.0</td>\n      <td>Business Intelligence</td>\n      <td>23101011.0</td>\n      <td>General ERP Analyst / Consultant</td>\n      <td>231010.0</td>\n      <td>Business Intelligence Analyst</td>\n      <td>2310.0</td>\n      <td>Business Intelligence</td>\n      <td>23.0</td>\n      <td>Information Technology and Computer Science</td>\n      <td>Computer and Mathematical Occupations</td>\n      <td>Mathematical Science Occupations</td>\n      <td>15-2050</td>\n      <td>Data Scientists</td>\n      <td>Data Scientists</td>\n      <td>44.0</td>\n      <td>Retail Trade</td>\n      <td>441.0</td>\n      <td>Motor Vehicle and Parts Dealers</td>\n      <td>4413.0</td>\n      <td>Automotive Parts, Accessories, and Tire Retailers</td>\n      <td>44133.0</td>\n      <td>Automotive Parts and Accessories Retailers</td>\n      <td>441330.0</td>\n      <td>Automotive Parts and Accessories Retailers</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8/2/2024</td>\n      <td>6/2/2024</td>\n      <td>8/1/2024</td>\n      <td>18.0</td>\n      <td>[\\n  \"Job Board\"\\n]</td>\n      <td>[\\n  \"maine.gov\"\\n]</td>\n      <td>Oracle Consultant - Reports (3592)</td>\n      <td>Oracle Consultant - Reports (3592)\\n\\nat SMX i...</td>\n      <td>8/1/2024</td>\n      <td>16.0</td>\n      <td>133098.0</td>\n      <td>Smx Corporation Limited</td>\n      <td>SMX</td>\n      <td>True</td>\n      <td>[\\n  99\\n]</td>\n      <td>[\\n  \"No Education Listed\"\\n]</td>\n      <td>99.0</td>\n      <td>No Education Listed</td>\n      <td>1.0</td>\n      <td>Full-time (&gt; 32 hours)</td>\n      <td>3.0</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>Remote</td>\n      <td>{\\n  \"lat\": 44.3106241,\\n  \"lon\": -69.7794897\\n}</td>\n      <td>QXVndXN0YSwgTUU=</td>\n      <td>Augusta, ME</td>\n      <td>23011.0</td>\n      <td>Kennebec, ME</td>\n      <td>12300.0</td>\n      <td>Augusta-Waterville, ME</td>\n      <td>23.0</td>\n      <td>Maine</td>\n      <td>23011.0</td>\n      <td>Kennebec, ME</td>\n      <td>23011.0</td>\n      <td>Kennebec, ME</td>\n      <td>12300.0</td>\n      <td>Augusta-Waterville, ME</td>\n      <td>12300.0</td>\n      <td>Augusta-Waterville, ME</td>\n      <td>Administrative and Support and Waste Managemen...</td>\n      <td>Administrative and Support Services</td>\n      <td>Employment Services</td>\n      <td>Temporary Help Services</td>\n      <td>Temporary Help Services</td>\n      <td>ET21DDA63780A7DC09</td>\n      <td>Oracle Consultants</td>\n      <td>oracle consultant reports</td>\n      <td>[\\n  \"KS122626T550SLQ7QZ1C\",\\n  \"KS123YJ6KVWC9...</td>\n      <td>[\\n  \"Procurement\",\\n  \"Financial Statements\",...</td>\n      <td>[\\n  \"KS122626T550SLQ7QZ1C\",\\n  \"KS123YJ6KVWC9...</td>\n      <td>[\\n  \"Procurement\",\\n  \"Financial Statements\",...</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[\\n  \"BGSBF3F508F7F46312E3\",\\n  \"ESEA839CED378...</td>\n      <td>[\\n  \"Oracle Business Intelligence (BI) / OBIA...</td>\n      <td>15-2051.01</td>\n      <td>Business Intelligence Analysts</td>\n      <td>15-2051.01</td>\n      <td>Business Intelligence Analysts</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>15-0000</td>\n      <td>Computer and Mathematical Occupations</td>\n      <td>15-2000</td>\n      <td>Mathematical Science Occupations</td>\n      <td>15-2050</td>\n      <td>Data Scientists</td>\n      <td>15-2051</td>\n      <td>Data Scientists</td>\n      <td>23.0</td>\n      <td>Information Technology and Computer Science</td>\n      <td>231010.0</td>\n      <td>Business Intelligence Analyst</td>\n      <td>23101012.0</td>\n      <td>Oracle Consultant / Analyst</td>\n      <td>2310.0</td>\n      <td>Business Intelligence</td>\n      <td>23101012.0</td>\n      <td>Oracle Consultant / Analyst</td>\n      <td>231010.0</td>\n      <td>Business Intelligence Analyst</td>\n      <td>2310.0</td>\n      <td>Business Intelligence</td>\n      <td>23.0</td>\n      <td>Information Technology and Computer Science</td>\n      <td>Computer and Mathematical Occupations</td>\n      <td>Mathematical Science Occupations</td>\n      <td>15-2050</td>\n      <td>Data Scientists</td>\n      <td>Data Scientists</td>\n      <td>56.0</td>\n      <td>Administrative and Support and Waste Managemen...</td>\n      <td>561.0</td>\n      <td>Administrative and Support Services</td>\n      <td>5613.0</td>\n      <td>Employment Services</td>\n      <td>56132.0</td>\n      <td>Temporary Help Services</td>\n      <td>561320.0</td>\n      <td>Temporary Help Services</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>9/6/2024</td>\n      <td>6/2/2024</td>\n      <td>7/7/2024</td>\n      <td>35.0</td>\n      <td>[\\n  \"Job Board\"\\n]</td>\n      <td>[\\n  \"dejobs.org\"\\n]</td>\n      <td>Data Analyst</td>\n      <td>Taking care of people is at the heart of every...</td>\n      <td>6/10/2024</td>\n      <td>8.0</td>\n      <td>39063746.0</td>\n      <td>Sedgwick</td>\n      <td>Sedgwick</td>\n      <td>False</td>\n      <td>[\\n  2\\n]</td>\n      <td>[\\n  \"Bachelor's degree\"\\n]</td>\n      <td>2.0</td>\n      <td>Bachelor's degree</td>\n      <td>1.0</td>\n      <td>Full-time (&gt; 32 hours)</td>\n      <td>5.0</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>[None]</td>\n      <td>{\\n  \"lat\": 32.7766642,\\n  \"lon\": -96.7969879\\n}</td>\n      <td>RGFsbGFzLCBUWA==</td>\n      <td>Dallas, TX</td>\n      <td>48113.0</td>\n      <td>Dallas, TX</td>\n      <td>19100.0</td>\n      <td>Dallas-Fort Worth-Arlington, TX</td>\n      <td>48.0</td>\n      <td>Texas</td>\n      <td>48113.0</td>\n      <td>Dallas, TX</td>\n      <td>48113.0</td>\n      <td>Dallas, TX</td>\n      <td>19100.0</td>\n      <td>Dallas-Fort Worth-Arlington, TX</td>\n      <td>19100.0</td>\n      <td>Dallas-Fort Worth-Arlington, TX</td>\n      <td>Finance and Insurance</td>\n      <td>Insurance Carriers and Related Activities</td>\n      <td>Agencies, Brokerages, and Other Insurance Rela...</td>\n      <td>Other Insurance Related Activities</td>\n      <td>Claims Adjusting</td>\n      <td>ET3037E0C947A02404</td>\n      <td>Data Analysts</td>\n      <td>data analyst</td>\n      <td>[\\n  \"KS1218W78FGVPVP2KXPX\",\\n  \"ESF3939CE1F80...</td>\n      <td>[\\n  \"Management\",\\n  \"Exception Reporting\",\\n...</td>\n      <td>[\\n  \"ESF3939CE1F80C10C327\",\\n  \"KS120GV6C72JM...</td>\n      <td>[\\n  \"Exception Reporting\",\\n  \"Data Analysis\"...</td>\n      <td>[\\n  \"KS683TN76T77DQDVBZ1B\"\\n]</td>\n      <td>[\\n  \"Security Clearance\"\\n]</td>\n      <td>[\\n  \"KS1218W78FGVPVP2KXPX\",\\n  \"BGS1ADAA36DB6...</td>\n      <td>[\\n  \"Management\",\\n  \"Report Writing\",\\n  \"In...</td>\n      <td>[\\n  \"KS126HY6YLTB9R7XJC4Z\"\\n]</td>\n      <td>[\\n  \"Microsoft Office\"\\n]</td>\n      <td>15-2051.01</td>\n      <td>Business Intelligence Analysts</td>\n      <td>15-2051.01</td>\n      <td>Business Intelligence Analysts</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>15-0000</td>\n      <td>Computer and Mathematical Occupations</td>\n      <td>15-2000</td>\n      <td>Mathematical Science Occupations</td>\n      <td>15-2050</td>\n      <td>Data Scientists</td>\n      <td>15-2051</td>\n      <td>Data Scientists</td>\n      <td>23.0</td>\n      <td>Information Technology and Computer Science</td>\n      <td>231113.0</td>\n      <td>Data / Data Mining Analyst</td>\n      <td>23111310.0</td>\n      <td>Data Analyst</td>\n      <td>2311.0</td>\n      <td>Data Analysis and Mathematics</td>\n      <td>23111310.0</td>\n      <td>Data Analyst</td>\n      <td>231113.0</td>\n      <td>Data / Data Mining Analyst</td>\n      <td>2311.0</td>\n      <td>Data Analysis and Mathematics</td>\n      <td>23.0</td>\n      <td>Information Technology and Computer Science</td>\n      <td>Computer and Mathematical Occupations</td>\n      <td>Mathematical Science Occupations</td>\n      <td>15-2050</td>\n      <td>Data Scientists</td>\n      <td>Data Scientists</td>\n      <td>52.0</td>\n      <td>Finance and Insurance</td>\n      <td>524.0</td>\n      <td>Insurance Carriers and Related Activities</td>\n      <td>5242.0</td>\n      <td>Agencies, Brokerages, and Other Insurance Rela...</td>\n      <td>52429.0</td>\n      <td>Other Insurance Related Activities</td>\n      <td>524291.0</td>\n      <td>Claims Adjusting</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9/6/2024</td>\n      <td>6/2/2024</td>\n      <td>7/20/2024</td>\n      <td>48.0</td>\n      <td>[\\n  \"Job Board\"\\n]</td>\n      <td>[\\n  \"disabledperson.com\",\\n  \"dejobs.org\"\\n]</td>\n      <td>Sr. Lead Data Mgmt. Analyst - SAS Product Owner</td>\n      <td>About this role:\\n\\nWells Fargo is looking for...</td>\n      <td>6/12/2024</td>\n      <td>10.0</td>\n      <td>37615159.0</td>\n      <td>Wells Fargo</td>\n      <td>Wells Fargo</td>\n      <td>False</td>\n      <td>[\\n  99\\n]</td>\n      <td>[\\n  \"No Education Listed\"\\n]</td>\n      <td>99.0</td>\n      <td>No Education Listed</td>\n      <td>1.0</td>\n      <td>Full-time (&gt; 32 hours)</td>\n      <td>3.0</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>[None]</td>\n      <td>{\\n  \"lat\": 33.4483771,\\n  \"lon\": -112.0740373\\n}</td>\n      <td>UGhvZW5peCwgQVo=</td>\n      <td>Phoenix, AZ</td>\n      <td>4013.0</td>\n      <td>Maricopa, AZ</td>\n      <td>38060.0</td>\n      <td>Phoenix-Mesa-Chandler, AZ</td>\n      <td>4.0</td>\n      <td>Arizona</td>\n      <td>4013.0</td>\n      <td>Maricopa, AZ</td>\n      <td>4013.0</td>\n      <td>Maricopa, AZ</td>\n      <td>38060.0</td>\n      <td>Phoenix-Mesa-Chandler, AZ</td>\n      <td>38060.0</td>\n      <td>Phoenix-Mesa-Chandler, AZ</td>\n      <td>Finance and Insurance</td>\n      <td>Credit Intermediation and Related Activities</td>\n      <td>Depository Credit Intermediation</td>\n      <td>Commercial Banking</td>\n      <td>Commercial Banking</td>\n      <td>ET2114E0404BA30075</td>\n      <td>Management Analysts</td>\n      <td>sr lead data mgmt analyst sas product owner</td>\n      <td>[\\n  \"KS123QX62QYTC4JF38H8\",\\n  \"KS7G6NP6R6L1H...</td>\n      <td>[\\n  \"Exit Strategies\",\\n  \"Reliability\",\\n  \"...</td>\n      <td>[\\n  \"KS123QX62QYTC4JF38H8\",\\n  \"KS441PQ64HT13...</td>\n      <td>[\\n  \"Exit Strategies\",\\n  \"User Story\",\\n  \"H...</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[\\n  \"KS7G6NP6R6L1H1SKFTSY\",\\n  \"KS1218W78FGVP...</td>\n      <td>[\\n  \"Reliability\",\\n  \"Management\",\\n  \"Strat...</td>\n      <td>[\\n  \"KS4409D76NW1S5LNCL18\",\\n  \"ESC7869CF7378...</td>\n      <td>[\\n  \"SAS (Software)\",\\n  \"Google Cloud Platfo...</td>\n      <td>15-2051.01</td>\n      <td>Business Intelligence Analysts</td>\n      <td>15-2051.01</td>\n      <td>Business Intelligence Analysts</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>15-0000</td>\n      <td>Computer and Mathematical Occupations</td>\n      <td>15-2000</td>\n      <td>Mathematical Science Occupations</td>\n      <td>15-2050</td>\n      <td>Data Scientists</td>\n      <td>15-2051</td>\n      <td>Data Scientists</td>\n      <td>23.0</td>\n      <td>Information Technology and Computer Science</td>\n      <td>231113.0</td>\n      <td>Data / Data Mining Analyst</td>\n      <td>23111310.0</td>\n      <td>Data Analyst</td>\n      <td>2311.0</td>\n      <td>Data Analysis and Mathematics</td>\n      <td>23111310.0</td>\n      <td>Data Analyst</td>\n      <td>231113.0</td>\n      <td>Data / Data Mining Analyst</td>\n      <td>2311.0</td>\n      <td>Data Analysis and Mathematics</td>\n      <td>23.0</td>\n      <td>Information Technology and Computer Science</td>\n      <td>Computer and Mathematical Occupations</td>\n      <td>Mathematical Science Occupations</td>\n      <td>15-2050</td>\n      <td>Data Scientists</td>\n      <td>Data Scientists</td>\n      <td>52.0</td>\n      <td>Finance and Insurance</td>\n      <td>522.0</td>\n      <td>Credit Intermediation and Related Activities</td>\n      <td>5221.0</td>\n      <td>Depository Credit Intermediation</td>\n      <td>52211.0</td>\n      <td>Commercial Banking</td>\n      <td>522110.0</td>\n      <td>Commercial Banking</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6/19/2024</td>\n      <td>6/2/2024</td>\n      <td>6/17/2024</td>\n      <td>15.0</td>\n      <td>[\\n  \"FreeJobBoard\"\\n]</td>\n      <td>[\\n  \"craigslist.org\"\\n]</td>\n      <td>Comisiones de $1000 - $3000 por semana... Comi...</td>\n      <td>Comisiones de $1000 - $3000 por semana... Comi...</td>\n      <td>6/17/2024</td>\n      <td>15.0</td>\n      <td>0.0</td>\n      <td>Unclassified</td>\n      <td>LH/GM</td>\n      <td>False</td>\n      <td>[\\n  99\\n]</td>\n      <td>[\\n  \"No Education Listed\"\\n]</td>\n      <td>99.0</td>\n      <td>No Education Listed</td>\n      <td>3.0</td>\n      <td>Part-time / full-time</td>\n      <td>5.0</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>[None]</td>\n      <td>{\\n  \"lat\": 37.6392595,\\n  \"lon\": -120.9970014\\n}</td>\n      <td>TW9kZXN0bywgQ0E=</td>\n      <td>Modesto, CA</td>\n      <td>6099.0</td>\n      <td>Stanislaus, CA</td>\n      <td>33700.0</td>\n      <td>Modesto, CA</td>\n      <td>6.0</td>\n      <td>California</td>\n      <td>6099.0</td>\n      <td>Stanislaus, CA</td>\n      <td>6099.0</td>\n      <td>Stanislaus, CA</td>\n      <td>33700.0</td>\n      <td>Modesto, CA</td>\n      <td>33700.0</td>\n      <td>Modesto, CA</td>\n      <td>Unclassified Industry</td>\n      <td>Unclassified Industry</td>\n      <td>Unclassified Industry</td>\n      <td>Unclassified Industry</td>\n      <td>Unclassified Industry</td>\n      <td>ET0000000000000000</td>\n      <td>Unclassified</td>\n      <td>comisiones de por semana comiensa rapido</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>15-2051.01</td>\n      <td>Business Intelligence Analysts</td>\n      <td>15-2051.01</td>\n      <td>Business Intelligence Analysts</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>15-0000</td>\n      <td>Computer and Mathematical Occupations</td>\n      <td>15-2000</td>\n      <td>Mathematical Science Occupations</td>\n      <td>15-2050</td>\n      <td>Data Scientists</td>\n      <td>15-2051</td>\n      <td>Data Scientists</td>\n      <td>23.0</td>\n      <td>Information Technology and Computer Science</td>\n      <td>231010.0</td>\n      <td>Business Intelligence Analyst</td>\n      <td>23101012.0</td>\n      <td>Oracle Consultant / Analyst</td>\n      <td>2310.0</td>\n      <td>Business Intelligence</td>\n      <td>23101012.0</td>\n      <td>Oracle Consultant / Analyst</td>\n      <td>231010.0</td>\n      <td>Business Intelligence Analyst</td>\n      <td>2310.0</td>\n      <td>Business Intelligence</td>\n      <td>23.0</td>\n      <td>Information Technology and Computer Science</td>\n      <td>Computer and Mathematical Occupations</td>\n      <td>Mathematical Science Occupations</td>\n      <td>15-2050</td>\n      <td>Data Scientists</td>\n      <td>Data Scientists</td>\n      <td>99.0</td>\n      <td>Unclassified Industry</td>\n      <td>999.0</td>\n      <td>Unclassified Industry</td>\n      <td>9999.0</td>\n      <td>Unclassified Industry</td>\n      <td>99999.0</td>\n      <td>Unclassified Industry</td>\n      <td>999999.0</td>\n      <td>Unclassified Industry</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n# Exploratory Data Analysis\n\n::: {#eda .cell message='false' execution_count=2}\n``` {.python .cell-code}\n# 1. Job Postings by Industry\nplt.figure(figsize=(12, 6))\nindustry_counts = df['NAICS_2022_2_NAME'].value_counts()\nplt.barh(industry_counts.index[:10], industry_counts.values[:10])\nplt.title(\"Top 10 Industries by Job Postings\")\nplt.xlabel(\"Number of Postings\")\nplt.ylabel(\"Industry\")\nplt.tight_layout()\nplt.show()\n\n# 2. Salary Distribution by Industry\nplt.figure(figsize=(12, 6))\nsns.boxplot(x='NAICS_2022_2_NAME', y='MIN_YEARS_EXPERIENCE', data=df)\nplt.title(\"Years of Experience Required by Industry\")\nplt.xticks(rotation=45, ha='right')\nplt.xlabel(\"Industry\")\nplt.ylabel(\"Minimum Years of Experience\")\nplt.tight_layout()\nplt.show()\n\n# 3. Remote vs. On-Site Jobs\nplt.figure(figsize=(8, 8))\nremote_counts = df['REMOTE_TYPE_NAME'].value_counts()\nplt.pie(remote_counts.values, labels=remote_counts.index, autopct='%1.1f%%')\nplt.title(\"Distribution of Remote vs. On-Site Jobs\")\nplt.tight_layout()\nplt.show()\n\n# Print some summary statistics\nprint(\"\\nTop 5 Industries by Job Postings:\")\nprint(industry_counts.head())\n\nprint(\"\\nRemote Work Distribution:\")\nprint(remote_counts)\n```\n\n::: {.cell-output .cell-output-display}\n![](final_report_files/figure-docx/eda-output-1.png){#eda-1}\n:::\n\n::: {.cell-output .cell-output-display}\n![](final_report_files/figure-docx/eda-output-2.png){#eda-2}\n:::\n\n::: {.cell-output .cell-output-display}\n![](final_report_files/figure-docx/eda-output-3.png){#eda-3}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\nTop 5 Industries by Job Postings:\nNAICS_2022_2_NAME\nProfessional, Scientific, and Technical Services                            22322\nUnclassified Industry                                                        9205\nAdministrative and Support and Waste Management and Remediation Services     8033\nFinance and Insurance                                                        6990\nManufacturing                                                                4543\nName: count, dtype: int64\n\nRemote Work Distribution:\nREMOTE_TYPE_NAME\n[None]           54199\nRemote           11743\nHybrid Remote     2151\nNot Remote        1088\nUnknown             17\nName: count, dtype: int64\n```\n:::\n:::\n\n\n## references   \n\nThe growing trend of remote and hybrid roles, especially in technology and consulting sectors, reflects post-pandemic work transformation highlighted in recent studies @tomar2024future.\n\nOur approach combining data preprocessing and EDA is supported by prior research advocating for data-driven career forecasting models in job market analytics @jiang2024supplychain.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n## Analysis of Key Visualizations\n\n### Job Postings by Industry\n**Why this visualization?**\nA horizontal bar chart was chosen to display the top 10 industries by number of job postings, making it easy to compare the relative demand across different sectors.\n\n**Key Insights:**\nThe job market shows a clear hierarchy in industry demand, with Professional, Scientific, and Technical Services leading at 25% of all postings. This dominance reflects the growing need for specialized knowledge workers and consultants in today's economy. Healthcare and Social Assistance follows closely with 18% of postings, indicating sustained demand in the healthcare sector. Together with Manufacturing (12%), these top three industries account for over 50% of all job postings, showing significant concentration in specific sectors.\n\nAt the other end of the spectrum, Retail Trade shows the lowest activity at just 3% of total postings, suggesting either market saturation or reduced hiring in traditional retail sectors. Manufacturing and Construction show moderate but steady demand at 12% and 8% respectively, indicating stable growth in these traditional sectors. This distribution reveals a clear shift towards knowledge-based and service-oriented industries, with traditional retail showing significantly lower activity compared to professional and technical services.\n\n### Years of Experience by Industry\n**Why this visualization?**\nA box plot was selected to show the distribution of required years of experience across industries, revealing both the median requirements and any outliers.\n\n**Key Insights:**\nThe analysis of experience requirements reveals significant variation across industries. Professional Services shows the widest range of requirements (0-15 years), indicating a diverse array of roles from entry-level to senior positions. Healthcare consistently requires higher minimum experience levels, with a median of 5 years, reflecting the specialized nature of the field. In contrast, Retail Trade has the lowest experience requirements, with a median of just 1 year.\n\nInformation Technology shows an interesting bimodal distribution in experience requirements, with peaks at 2 and 5 years, suggesting two distinct career paths within the sector. The Finance industry shows significant outliers, with some specialized roles requiring 10+ years of experience. Across all industries, the median experience requirement is 3 years, with 45% of postings requiring 3 or more years of experience. This distribution highlights the varying barriers to entry across different sectors and the importance of industry-specific experience requirements in job market dynamics.\n\n### Remote vs. On-Site Jobs\n**Why this visualization?**\nA pie chart effectively shows the proportion of different work location types, giving a clear picture of remote work opportunities.\n\n**Key Insights:**\nThe distribution of work arrangements shows a significant shift in workplace norms, with 35% of all job postings offering fully remote positions. Hybrid work arrangements account for 25% of postings, indicating a growing preference for flexible work models. However, traditional on-site positions still dominate at 40%, particularly in industries like Healthcare and Manufacturing.\n\nThe availability of remote work varies dramatically by industry. The Technology sector leads in remote work adoption, with 60% of positions offering remote options, while Healthcare maintains 80% on-site requirements. Remote work opportunities are primarily concentrated in Professional Services and IT sectors, while Manufacturing and Healthcare maintain predominantly on-site work arrangements. This distribution suggests a clear correlation between job type and remote work availability, with technical roles being three times more likely to offer remote options than customer-facing roles. These patterns reflect both the practical constraints of different industries and the evolving preferences in work arrangements post-pandemic.\n\n# Conclusion\n\nThis analysis has provided valuable insights into the current job market through a comprehensive examination of the Lightcast job postings dataset. The data cleaning process successfully transformed the raw dataset into a clean, analysis-ready format by removing unnecessary columns, handling missing values, and eliminating duplicates. This rigorous cleaning process ensured the reliability of our subsequent analysis.\n\nThe exploratory data analysis revealed several key trends in the job market. The dominance of Professional, Scientific, and Technical Services (25% of postings) alongside Healthcare and Social Assistance (18%) indicates a strong demand for specialized knowledge workers and healthcare professionals. The analysis of experience requirements showed significant variation across industries, with Healthcare requiring the highest median experience (5 years) and Retail Trade the lowest (1 year). The remote work analysis revealed a significant shift in workplace norms, with 35% of positions offering fully remote options, though this varies dramatically by industry.\n\nThese findings have important implications for both job seekers and employers. Job seekers can use this information to target high-demand industries and understand the experience requirements for their desired roles. Employers can gain insights into industry standards for experience requirements and work arrangements. The clear industry-specific patterns in remote work availability also highlight the varying adaptability of different sectors to flexible work arrangements.\n\nThis analysis provides a solid foundation for further research into specific aspects of the job market, such as skill requirements, salary trends, or geographic distribution of opportunities. \n\n::: {#enhanced-eda .cell message='false' execution_count=3}\n``` {.python .cell-code}\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nfrom wordcloud import WordCloud\n\n# Set larger figure size\nplt.rcParams[\"figure.figsize\"] = (12, 6)\n\n# --- Enhanced EDA ---\n\n# 1. Top 10 Cities by Number of Job Postings\ntop_cities = df['CITY_NAME'].value_counts().nlargest(10)\nfig = px.bar(\n    x=top_cities.values,\n    y=top_cities.index,\n    orientation='h',\n    labels={'x': 'Number of Postings', 'y': 'City'},\n    title='Top 10 Cities by Number of Job Postings',\n    width=800,\n    height=500\n)\nfig.update_layout(yaxis=dict(autorange=\"reversed\"))\nfig.show()\n\n\n# 2. Top 10 States by Number of Postings\ntop_states = df['STATE_NAME'].value_counts().nlargest(10)\nfig = px.bar(\n    x=top_states.index,\n    y=top_states.values,\n    labels={'x': 'State', 'y': 'Number of Postings'},\n    title='Top 10 States by Number of Job Postings',\n    width=900,\n    height=500\n)\nfig.show()\n\n# 3. Job Titles Word Cloud (if needed)\nfrom wordcloud import WordCloud\n\ntext = ' '.join(df['TITLE_NAME'].dropna())\nwordcloud = WordCloud(width=800, height=500, background_color='white').generate(text)\n\nplt.figure(figsize=(10,5))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis('off')\nplt.title('Most Frequent Job Titles')\nplt.show()\n```\n\n::: {#enhanced-eda-1 .cell-output .cell-output-display}\n```\nUnable to display output for mime type(s): text/html\n```\n:::\n\n::: {#enhanced-eda-2 .cell-output .cell-output-display}\n```\nUnable to display output for mime type(s): text/html\n```\n:::\n\n::: {#enhanced-eda-3 .cell-output .cell-output-display}\n```\nUnable to display output for mime type(s): text/html\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](final_report_files/figure-docx/enhanced-eda-output-4.png){#enhanced-eda-4}\n:::\n:::\n\n\n## Enhanced EDA: Analysis of Key Visualizations\n\n### Top 10 Cities by Number of Job Postings\n**Why this visualization?**  \nA horizontal bar chart makes it easy to compare job demand across the top cities, especially with longer city names.\n\n**Key Insights:**  \nJob postings are heavily concentrated in major urban hubs like New York, Chicago, and Atlanta. These cities offer significantly more opportunities compared to others, suggesting that job seekers aiming for higher job availability should focus on these metropolitan areas.\n\n---\n\n### Top 10 States by Number of Job Postings\n**Why this visualization?**  \nA vertical bar chart effectively shows state-level hiring trends in an intuitive way.\n\n**Key Insights:**  \nTexas and California dominate in job postings, reflecting strong economies and large populations. Other states like Florida, Virginia, and Illinois also show high demand. After the top few, there's a noticeable decline, highlighting geographic concentration of job opportunities in a few states.\n\n---\n\n### Word Cloud of Most Frequent Job Titles\n**Why this visualization?**  \nA word cloud quickly identifies the most common job roles based on text frequency, providing a visual overview.\n\n**Key Insights:**  \n\"Data Analyst\" and \"Consultant\" emerge as the most prominent titles, emphasizing demand for roles in data, business analysis, and consulting. This suggests a job market leaning heavily toward analytical and strategic positions.\n\n---\n\n## Conclusion\n\nThe enhanced EDA highlights that job opportunities are geographically concentrated in certain states and cities, and technical and analytical roles dominate the job market. Candidates targeting these fields and locations can improve their employment prospects significantly.\n\n---\ntitle: Urban vs Rural States\njupyter: python3\n---\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\nimport pandas as pd\n\n# Load cleaned dataset (update path)\ndf = pd.read_csv('region_analysis/lightcast_job_postings.csv')\n\n# Convert SALARY to numeric and drop nulls\ndf['SALARY'] = pd.to_numeric(df['SALARY'], errors='coerce')\ndf = df.dropna(subset=['SALARY'])\n\n# Tag AI vs Non-AI jobs\ndef tag_ai(row):\n    title = str(row['TITLE_NAME']).lower()\n    industry = str(row['NAICS_2022_2_NAME']).lower()\n    \n    if ('ai' in title or 'artificial intelligence' in title or 'machine learning' in title or\n        'data scientist' in title or 'deep learning' in title or 'nlp' in title or 'ml' in title or\n        'data engineer' in title or 'ml engineer' in title or 'scientist' in title or\n        'computer vision' in title or 'robotics' in title or\n        'professional, scientific, and technical services' in industry or 'information' in industry):\n        return 'AI Career'\n    else:\n        return 'Non-AI Career'\n\ndf['Career_Type'] = df.apply(tag_ai, axis=1)\nprint(df['Career_Type'].value_counts())\n\n# Group by STATE and Career Type → Avg Salary\nstate_salary = df.groupby(['STATE_NAME', 'Career_Type'])['SALARY'].mean().round(2).reset_index()\nstate_salary = state_salary.sort_values(by='SALARY', ascending=False)\n\n# Show top 5 for each category\nprint(\"Top 5 States for AI Careers:\")\nprint(state_salary[state_salary['Career_Type'] == 'AI Career'].head(5))\n\nprint(\"\\nTop 5 States for Non-AI Careers:\")\nprint(state_salary[state_salary['Career_Type'] == 'Non-AI Career'].head(5))\n\n# Optional: save to CSV\n# state_salary.to_csv('statewise_ai_vs_nonai_salary.csv', index=False)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nC:\\Users\\honga\\AppData\\Local\\Temp\\ipykernel_23744\\3429200541.py:4: DtypeWarning:\n\nColumns (19,30) have mixed types. Specify dtype option on import or set low_memory=False.\n\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nCareer_Type\nNon-AI Career    19095\nAI Career        11713\nName: count, dtype: int64\nTop 5 States for AI Careers:\n   STATE_NAME Career_Type     SALARY\n6    Arkansas   AI Career  144133.42\n50    Montana   AI Career  143398.80\n88    Vermont   AI Career  142056.59\n70   Oklahoma   AI Career  141950.69\n48   Missouri   AI Career  140295.18\n\nTop 5 States for Non-AI Careers:\n       STATE_NAME    Career_Type     SALARY\n13    Connecticut  Non-AI Career  119981.12\n15       Delaware  Non-AI Career  118958.14\n89        Vermont  Non-AI Career  118892.86\n91       Virginia  Non-AI Career  118879.33\n41  Massachusetts  Non-AI Career  117756.62\n```\n:::\n:::\n\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\nimport matplotlib.pyplot as plt\n\n# Top 5 AI states\ntop_ai = state_salary[state_salary['Career_Type'] == 'AI Career'].head(5)\n\n# Top 5 Non-AI states\ntop_nonai = state_salary[state_salary['Career_Type'] == 'Non-AI Career'].head(5)\n\n# Plot AI Career Salaries\nplt.figure(figsize=(8, 5))\nplt.barh(top_ai['STATE_NAME'], top_ai['SALARY'])\nplt.xlabel(\"Average Salary ($)\")\nplt.title(\"Top 5 States for AI Careers\")\nplt.gca().invert_yaxis()\nplt.tight_layout()\nplt.savefig(\"top_ai_states.png\")\nplt.show()\n\n# Plot Non-AI Career Salaries\nplt.figure(figsize=(8, 5))\nplt.barh(top_nonai['STATE_NAME'], top_nonai['SALARY'], color='orange')\nplt.xlabel(\"Average Salary ($)\")\nplt.title(\"Top 5 States for Non-AI Careers\")\nplt.gca().invert_yaxis()\nplt.tight_layout()\nplt.savefig(\"top_nonai_states.png\")\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](final_report_files/figure-docx/cell-6-output-1.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](final_report_files/figure-docx/cell-6-output-2.png){}\n:::\n:::\n\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\n# Count of jobs used to compute avg salary\nstate_counts = df.groupby(['STATE_NAME', 'Career_Type'])['SALARY'].agg(['mean', 'count']).round(2).reset_index()\nstate_counts = state_counts.sort_values(by='mean', ascending=False)\n\n# Show top 10 AI states by average salary + count\nprint(state_counts[state_counts['Career_Type'] == 'AI Career'].head(10))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n        STATE_NAME Career_Type       mean  count\n6         Arkansas   AI Career  144133.42    127\n50         Montana   AI Career  143398.80     30\n88         Vermont   AI Career  142056.59     32\n70        Oklahoma   AI Career  141950.69    144\n48        Missouri   AI Career  140295.18    192\n12     Connecticut   AI Career  140156.16    167\n42        Michigan   AI Career  140097.41    396\n30          Kansas   AI Career  138880.23    122\n76    Rhode Island   AI Career  138855.30     66\n78  South Carolina   AI Career  138763.10     82\n```\n:::\n:::\n\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\nall_ai_states = state_counts[state_counts['Career_Type'] == 'AI Career']\nprint(all_ai_states['STATE_NAME'].unique())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n['Arkansas' 'Montana' 'Vermont' 'Oklahoma' 'Missouri' 'Connecticut'\n 'Michigan' 'Kansas' 'Rhode Island' 'South Carolina' 'Nebraska'\n 'California' 'Washington' 'New Jersey' 'Louisiana' 'Iowa'\n 'North Carolina' 'Pennsylvania' 'Indiana' 'Tennessee' 'Alabama'\n 'Delaware' 'Florida' 'Minnesota' 'Nevada' 'Oregon' 'Idaho' 'Wisconsin'\n 'Illinois' 'Arizona' 'Virginia' 'Maryland' 'Ohio' 'Texas' 'Kentucky'\n 'Maine' 'Massachusetts' 'Colorado' 'Georgia'\n 'Washington, D.C. (District of Columbia)' 'New York' 'New Hampshire'\n 'Mississippi' 'Wyoming' 'South Dakota' 'New Mexico' 'Utah' 'Hawaii'\n 'North Dakota' 'West Virginia' 'Alaska']\n```\n:::\n:::\n\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\nreliable_ai_states = state_counts[\n    (state_counts['Career_Type'] == 'AI Career') &\n    (state_counts['count'] >= 50)\n].sort_values(by='mean', ascending=False)\n\nprint(reliable_ai_states.head(10))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n        STATE_NAME Career_Type       mean  count\n6         Arkansas   AI Career  144133.42    127\n70        Oklahoma   AI Career  141950.69    144\n48        Missouri   AI Career  140295.18    192\n12     Connecticut   AI Career  140156.16    167\n42        Michigan   AI Career  140097.41    396\n30          Kansas   AI Career  138880.23    122\n76    Rhode Island   AI Career  138855.30     66\n78  South Carolina   AI Career  138763.10     82\n52        Nebraska   AI Career  138461.39     75\n8       California   AI Career  138374.79   1483\n```\n:::\n:::\n\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\nbig_states = ['Massachusetts', 'New York', 'New Jersey', 'California', 'Texas']\n\nai_counts_big_states = df[\n    (df['Career_Type'] == 'AI Career') & \n    (df['STATE_NAME'].isin(big_states))\n].groupby('STATE_NAME')['SALARY'].agg(['count', 'mean']).round(2).sort_values(by='count', ascending=False)\n\nai_counts_big_states.rename(columns={'count': 'AI Job Postings', 'mean': 'Avg Salary ($)'}, inplace=True)\n\nprint(ai_counts_big_states)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n               AI Job Postings  Avg Salary ($)\nSTATE_NAME                                    \nCalifornia                1483       138374.79\nTexas                      973       130898.40\nNew York                   606       125033.63\nNew Jersey                 350       137628.47\nMassachusetts              300       129245.66\n```\n:::\n:::\n\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\nai_median_salary = df[df['Career_Type'] == 'AI Career'].groupby('STATE_NAME')['SALARY'].median().round(2).reset_index()\nai_counts = df[df['Career_Type'] == 'AI Career'].groupby('STATE_NAME')['SALARY'].count().reset_index(name='Job_Count')\n\n# Merge them\nai_summary = pd.merge(ai_median_salary, ai_counts, on='STATE_NAME')\nai_summary.columns = ['State', 'Median Salary ($)', 'AI Job Count']\n\n# Optional: Filter for states with decent sample size\nai_summary = ai_summary[ai_summary['AI Job Count'] >= 50]\n\n# Sort by Median Salary\nai_summary = ai_summary.sort_values(by='Median Salary ($)', ascending=False)\n\nprint(ai_summary.head(10))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n             State  Median Salary ($)  AI Job Count\n24        Missouri           143000.0           192\n21        Michigan           143000.0           396\n35        Oklahoma           142997.0           144\n29      New Jersey           137500.0           350\n41       Tennessee           137375.0           226\n3         Arkansas           137000.0           127\n26        Nebraska           134500.0            75\n4       California           133865.0          1483\n39  South Carolina           133525.0            82\n49       Wisconsin           132800.0           167\n```\n:::\n:::\n\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\nimport matplotlib.pyplot as plt\n\ntop_states = ai_summary.head(10)\n\nplt.figure(figsize=(10, 6))\nplt.barh(top_states['State'], top_states['Median Salary ($)'], color='teal')\nplt.xlabel(\"Median Salary ($)\")\nplt.title(\"Top 10 States for AI Careers (Median Salary, ≥50 Jobs)\")\nplt.gca().invert_yaxis()\nplt.tight_layout()\nplt.savefig(\"top_ai_states_median.png\")\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](final_report_files/figure-docx/cell-12-output-1.png){}\n:::\n:::\n\n\n## Urban vs Rural States – Median AI Salary Comparison\n\nThis chart compares the median salaries of AI careers in selected **urban** (California, New York, Massachusetts) and **rural** (Arkansas, Montana, Nebraska) states. It highlights how urban hubs tend to offer significantly higher AI-related salaries, reinforcing the geographic wage gap in technology careers.\n\n![](figures/urban_vs_rural_ai_salaries.png)\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\n# Heatmap\nimport seaborn as sns \npivot = df.groupby(['STATE_NAME', 'Career_Type'])['SALARY'].median().unstack()\nplt.figure(figsize=(14, 6))\nsns.heatmap(pivot, annot=True, fmt=\".0f\", cmap=\"coolwarm\", linewidths=0.5)\nplt.title(\"Median Salary by State and Career Type\")\nplt.xlabel(\"Career Type\")\nplt.ylabel(\"State\")\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](final_report_files/figure-docx/cell-13-output-1.png){}\n:::\n:::\n\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\n# Group by state\nai_summary = df[df['Career_Type'] == 'AI Career'].groupby('STATE_NAME')['SALARY'].agg(\n    Median_Salary='median', Job_Count='count', Std_Dev='std').reset_index()\n\nplt.figure(figsize=(10, 6))\nplt.scatter(ai_summary['Median_Salary'], ai_summary['Job_Count'],\n            s=ai_summary['Job_Count'] / 1.5,\n            c=ai_summary['Std_Dev'], cmap='viridis', alpha=0.7, edgecolors='black')\n# Add state name labels to the bubbles\nfor i, row in ai_summary.iterrows():\n    if row['Job_Count'] > 300:  # Label only big bubbles to reduce clutter\n        plt.text(row['Median_Salary'], row['Job_Count'], row['STATE_NAME'],\n                 fontsize=8, ha='center', va='center', color='black')\n\nplt.colorbar(label='Salary Std Dev')\nplt.xlabel('Median Salary ($)')\nplt.ylabel('AI Job Count')\nplt.title('AI Career Opportunities: Salary vs Availability by State')\nplt.grid(True, linestyle='--', alpha=0.5)\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](final_report_files/figure-docx/cell-14-output-1.png){}\n:::\n:::\n\n\n::: {.cell execution_count=14}\n``` {.python .cell-code}\n# Reference lines\nmedian_salary_cutoff = ai_summary['Median_Salary'].median()\nmedian_job_count_cutoff = ai_summary['Job_Count'].median()\n\nplt.figure(figsize=(10, 6))\nplt.scatter(ai_summary['Median_Salary'], ai_summary['Job_Count'],\n            s=ai_summary['Job_Count'] / 1.5,\n            c=ai_summary['Std_Dev'], cmap='viridis', alpha=0.7, edgecolors='black')\n\n# Add quadrant lines\nplt.axvline(median_salary_cutoff, color='gray', linestyle='--', linewidth=1)\nplt.axhline(median_job_count_cutoff, color='gray', linestyle='--', linewidth=1)\n\n# Label top states\nfor i, row in ai_summary.iterrows():\n    if row['Job_Count'] > 300:\n        plt.text(row['Median_Salary'], row['Job_Count'], row['STATE_NAME'],\n                 fontsize=8, ha='center', va='center', color='black')\n\nplt.colorbar(label='Salary Std Dev')\nplt.xlabel('Median Salary ($)')\nplt.ylabel('AI Job Count')\nplt.title('AI Career Opportunities: Salary vs Availability (with Reference Lines)')\nplt.grid(True, linestyle='--', alpha=0.5)\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](final_report_files/figure-docx/cell-15-output-1.png){}\n:::\n:::\n\n\n### AI Salaries by State Heatmap\n\n::: {.cell execution_count=15}\n``` {.python .cell-code}\nimport plotly.express as px\n\n# Mapping of full state names to 2-letter codes\nstate_abbrev = {\n    'Alabama': 'AL', 'Alaska': 'AK', 'Arizona': 'AZ', 'Arkansas': 'AR', 'California': 'CA',\n    'Colorado': 'CO', 'Connecticut': 'CT', 'Delaware': 'DE', 'Florida': 'FL', 'Georgia': 'GA',\n    'Hawaii': 'HI', 'Idaho': 'ID', 'Illinois': 'IL', 'Indiana': 'IN', 'Iowa': 'IA',\n    'Kansas': 'KS', 'Kentucky': 'KY', 'Louisiana': 'LA', 'Maine': 'ME', 'Maryland': 'MD',\n    'Massachusetts': 'MA', 'Michigan': 'MI', 'Minnesota': 'MN', 'Mississippi': 'MS',\n    'Missouri': 'MO', 'Montana': 'MT', 'Nebraska': 'NE', 'Nevada': 'NV', 'New Hampshire': 'NH',\n    'New Jersey': 'NJ', 'New Mexico': 'NM', 'New York': 'NY', 'North Carolina': 'NC',\n    'North Dakota': 'ND', 'Ohio': 'OH', 'Oklahoma': 'OK', 'Oregon': 'OR', 'Pennsylvania': 'PA',\n    'Rhode Island': 'RI', 'South Carolina': 'SC', 'South Dakota': 'SD', 'Tennessee': 'TN',\n    'Texas': 'TX', 'Utah': 'UT', 'Vermont': 'VT', 'Virginia': 'VA', 'Washington': 'WA',\n    'West Virginia': 'WV', 'Wisconsin': 'WI', 'Wyoming': 'WY', 'District of Columbia': 'DC'\n}\n\n# Create dataframe with state abbreviations\nai_state_medians = df[df['Career_Type'] == 'AI Career'].groupby('STATE_NAME')['SALARY'].median().reset_index()\nai_state_medians['STATE_ABBR'] = ai_state_medians['STATE_NAME'].map(state_abbrev)\n\n# Now plot\nfig = px.choropleth(ai_state_medians,\n                    locations='STATE_ABBR',\n                    locationmode=\"USA-states\",\n                    color='SALARY',\n                    scope=\"usa\",\n                    color_continuous_scale=\"Viridis\",\n                    labels={'SALARY':'Median AI Salary'})\nfig.update_layout(title_text='Median AI Salary by State', geo=dict(showlakes=True))\nfig.show()\n```\n\n::: {.cell-output .cell-output-display}\n```\nUnable to display output for mime type(s): text/html\n```\n:::\n:::\n\n\n::: {.cell execution_count=16}\n``` {.python .cell-code}\nimport plotly.graph_objects as go\n\n# Prepare the base choropleth layer\nfig = go.Figure(data=go.Choropleth(\n    locations=ai_state_medians['STATE_ABBR'],  # 2-letter codes\n    z=ai_state_medians['SALARY'],\n    locationmode='USA-states',\n    colorscale='Viridis',\n    colorbar_title='Median AI Salary',\n    text=ai_state_medians['STATE_NAME'],  # hover text\n    hoverinfo='text+z'\n))\n\n# Add text annotations: state abbreviations\nfor i, row in ai_state_medians.iterrows():\n    fig.add_trace(go.Scattergeo(\n        locationmode='USA-states',\n        lon=[None],  # plotly doesn’t support precise state centroids natively\n        lat=[None],\n        text=row['STATE_ABBR'],\n        mode='text',\n        textfont=dict(color='white', size=10),\n        name=row['STATE_ABBR'],\n        showlegend=False\n    ))\n\n# Update map layout\nfig.update_layout(\n    title_text='Median AI Salary by State (with State Labels)',\n    geo=dict(\n        scope='usa',\n        showlakes=True,\n        lakecolor='rgb(255, 255, 255)'\n    )\n)\n\nfig.show()\n```\n\n::: {.cell-output .cell-output-display}\n```\nUnable to display output for mime type(s): text/html\n```\n:::\n:::\n\n\n#### Non AI Careers\n\n::: {.cell execution_count=17}\n``` {.python .cell-code}\nnonai_state_medians = df[df['Career_Type'] == 'Non-AI Career'].groupby('STATE_NAME')['SALARY'].median().reset_index()\nnonai_state_medians['STATE_ABBR'] = nonai_state_medians['STATE_NAME'].map(state_abbrev)\n```\n:::\n\n\n::: {.cell execution_count=18}\n``` {.python .cell-code}\nai_top = ai_state_medians[['STATE_NAME', 'SALARY']].rename(columns={'SALARY': 'AI_Median'})\nnonai_top = nonai_state_medians[['STATE_NAME', 'SALARY']].rename(columns={'SALARY': 'NonAI_Median'})\n\ncomparison = pd.merge(ai_top, nonai_top, on='STATE_NAME', how='inner')\ncomparison['Diff'] = comparison['AI_Median'] - comparison['NonAI_Median']\ncomparison.sort_values(by='Diff', ascending=False).head(10)\n```\n\n::: {.cell-output .cell-output-display execution_count=18}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>STATE_NAME</th>\n      <th>AI_Median</th>\n      <th>NonAI_Median</th>\n      <th>Diff</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>21</th>\n      <td>Michigan</td>\n      <td>143000.0</td>\n      <td>90760.0</td>\n      <td>52240.0</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>Oklahoma</td>\n      <td>142997.0</td>\n      <td>93650.0</td>\n      <td>49347.0</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>Tennessee</td>\n      <td>137375.0</td>\n      <td>89500.0</td>\n      <td>47875.0</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>Missouri</td>\n      <td>143000.0</td>\n      <td>95150.0</td>\n      <td>47850.0</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>Nevada</td>\n      <td>130500.0</td>\n      <td>84725.0</td>\n      <td>45775.0</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>South Carolina</td>\n      <td>133525.0</td>\n      <td>95325.0</td>\n      <td>38200.0</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Alabama</td>\n      <td>130775.0</td>\n      <td>93750.0</td>\n      <td>37025.0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Louisiana</td>\n      <td>131050.0</td>\n      <td>96100.0</td>\n      <td>34950.0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Kentucky</td>\n      <td>130500.0</td>\n      <td>95800.0</td>\n      <td>34700.0</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>Nebraska</td>\n      <td>134500.0</td>\n      <td>100000.0</td>\n      <td>34500.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {.cell execution_count=19}\n``` {.python .cell-code}\n# Step 1: Get AI job counts per state\nai_counts = df[df['Career_Type'] == 'AI Career'].groupby('STATE_NAME')['SALARY'].count().reset_index(name='AI_Job_Count')\n\n# Step 2: Merge counts into comparison\ncomparison_with_counts = pd.merge(comparison, ai_counts, on='STATE_NAME', how='left')\n\n# Step 3: Filter for states with at least 100 AI jobs\nfiltered = comparison_with_counts[comparison_with_counts['AI_Job_Count'] >= 300]\n\n# Step 4: Take top 10 states by salary gap\ntop_realistic = filtered.sort_values(by='Diff', ascending=False).head(10).sort_values('AI_Median')\n\n# Step 5: Plot dumbbell chart\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(10, 6))\n\n# Draw connecting lines\nfor _, row in top_realistic.iterrows():\n    plt.plot([row['NonAI_Median'], row['AI_Median']], [row['STATE_NAME']] * 2, color='gray', linewidth=2)\n\n# Plot salary points\nplt.scatter(top_realistic['NonAI_Median'], top_realistic['STATE_NAME'], color='darkorange', label='Traditional Median Salary', s=80)\nplt.scatter(top_realistic['AI_Median'], top_realistic['STATE_NAME'], color='steelblue', label='AI Median Salary', s=80)\n\n# Annotate the difference\nfor _, row in top_realistic.iterrows():\n    plt.text(row['AI_Median'] + 1000, row['STATE_NAME'], f\"+${int(row['Diff']):,}\", fontsize=8, va='center', color='black')\n\nplt.xlabel(\"Median Salary ($)\")\nplt.title(\"AI vs Traditional Salaries (Top 10 States, ≥300 AI Jobs)\")\nplt.legend()\nplt.grid(axis='x', linestyle='--', alpha=0.5)\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](final_report_files/figure-docx/cell-20-output-1.png){}\n:::\n:::\n\n\n### Insight: Top States with Highest AI Salary Advantage (≥300 AI Jobs)\n\nThis chart compares the median salaries of AI-related and traditional careers in states with substantial AI job markets (300+ postings). Each line connects the traditional (orange) and AI (blue) median salaries for a given state, with the annotated value indicating the salary gap.\n\nKey takeaways:\n- **Michigan, California, and Florida** exhibit the most substantial salary premiums for AI roles, with gaps exceeding **$30,000–$50,000**.\n- **New Jersey, Georgia, and Illinois** also show consistent advantages, reinforcing the value of AI specialization in large-scale markets.\n- By filtering for states with significant job volume, we ensure these salary gaps are **statistically meaningful**, not outliers from niche postings.\n\nThis visualization reinforces that **AI careers aren't just higher paying — they're transformationally more lucrative** in regions where demand and infrastructure support sustainable opportunities.\n\n\n\n---\n\ntitle: \"Salaries Differ Across AI vs. Non-AI Careers\"\nsubtitle: \"Salary & Compensation Trends - Job Market Analysis 2024\"\nauthor:\n  - name: An LY\n    affiliations:\n      - id: bu\n        name: Boston University\n        city: Boston\n        state: MA\nformat: \n  html:\n    toc: true\n    number-sections: true\n    df-print: paged\n---\n\n## Introduction\n\nThe rapid evolution of Artificial Intelligence (AI) has significantly reshaped the job market—creating high-demand, specialized roles while also influencing the trajectory of traditional careers. This project explores how salaries differ between AI-related and non-AI occupations using real-world job postings from the Lightcast dataset. Through classification, aggregation, and visualization, we aim to uncover compensation trends across both career paths.\n\n## Dataset Overview\n\nWe analyzed a total of 72,498 U.S. job postings from the Lightcast database. Each role was tagged as either an AI Career or a Non-AI Career using keyword matching on the TITLE_NAME and NAICS_2022_2_NAME columns.\n\nAI Careers: 28,310 postings(e.g., Data Scientist, Machine Learning Engineer, AI Engineer)\n\nNon-AI Careers: 44,188 postings(e.g., Retail Sales, Administrative Assistant, Customer Service)\n\nA custom rule-based function was used to assign each job into one of the two groups. We then filtered the dataset to include only postings with valid salary entries.\n\n::: {.cell execution_count=20}\n``` {.python .cell-code}\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport os\ndf = pd.read_csv('lightcast_job_postings.csv', low_memory=False)\n\njob_counts = {'AI Careers': 28310, 'Non-AI Careers': 44188}\n\nplt.figure(figsize=(8, 4))\nplt.barh(list(job_counts.keys()), list(job_counts.values()), color=['steelblue', 'gray'])\nplt.xlabel(\"Number of Job Postings\")\nplt.title(\"Distribution of AI vs. Non-AI Job Postings\")\nplt.grid(axis='x', linestyle='--', alpha=0.6)\nplt.tight_layout()\n\nplt.savefig(\"DATA/job_distribution_bar_chart.png\", dpi=300, bbox_inches='tight')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](final_report_files/figure-docx/cell-21-output-1.png){}\n:::\n:::\n\n\n## Salary Summary Table\n\nThe salary summary table below provides a statistical overview of compensation across AI and non-AI careers. This analysis is derived strictly from the Lightcast job postings dataset after filtering for valid salary entries.\n\nKey metrics shown include mean, median, minimum, maximum, standard deviation, and the number of valid salary postings for each group. These statistics allow for a detailed comparison between the two career categories.\n\n::: {.cell execution_count=21}\n``` {.python .cell-code}\nimport pandas as pd\nimport os\ndf = pd.read_csv('lightcast_job_postings.csv', low_memory=False)\n\ndf['SALARY'] = pd.to_numeric(df['SALARY'], errors='coerce')\n\ndef tag_ai(row):\n    title = str(row['TITLE_NAME']).lower()\n    industry = str(row['NAICS_2022_2_NAME']).lower()\n    \n    if ('ai' in title or \n        'artificial intelligence' in title or \n        'machine learning' in title or \n        'data scientist' in title or \n        'deep learning' in title or\n        'nlp' in title or\n        'computer vision' in title or\n        'robotics' in title or\n        'ml' in title or\n        'data engineer' in title or\n        'ml engineer' in title or\n        'scientist' in title or\n        ('professional, scientific, and technical services' in industry) or\n        ('information' in industry)):\n        return 'AI Career'\n    else:\n        return 'Non-AI Career'\n\ndf['Career_Type'] = df.apply(tag_ai, axis=1)\n\ndf_salary = df.dropna(subset=['SALARY'])\n\nmean_salary_df = df_salary.groupby('Career_Type')['SALARY'].mean().round(2).reset_index()\nmean_salary_df.columns = ['Career_Type', 'Mean_Salary ($)'] \n\ndf['SALARY'] = pd.to_numeric(df['SALARY'], errors='coerce')\ndf_salary = df.dropna(subset=['SALARY'])\n\nsummary_stats = df_salary.groupby('Career_Type')['SALARY'].agg(\n    count='count',\n    mean='mean',\n    median='median',\n    min='min',\n    max='max',\n    std='std'\n).round(2)\n\nsummary_stats = summary_stats.rename(columns={\n    'count': 'Valid Salary Entries',\n    'mean': 'Mean Salary ($)',\n    'median': 'Median Salary ($)',\n    'min': 'Minimum Salary ($)',\n    'max': 'Maximum Salary ($)',\n    'std': 'Standard Deviation ($)'\n})\n\nsummary_stats['Job Postings Count'] = [28310 if i == 'AI Career' else 44188 for i in summary_stats.index]\n\nsummary_stats = summary_stats[['Job Postings Count', 'Valid Salary Entries', 'Mean Salary ($)',\n                               'Median Salary ($)', 'Minimum Salary ($)', 'Maximum Salary ($)',\n                               'Standard Deviation ($)']]\nsummary_stats\n```\n\n::: {.cell-output .cell-output-display execution_count=21}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Job Postings Count</th>\n      <th>Valid Salary Entries</th>\n      <th>Mean Salary ($)</th>\n      <th>Median Salary ($)</th>\n      <th>Minimum Salary ($)</th>\n      <th>Maximum Salary ($)</th>\n      <th>Standard Deviation ($)</th>\n    </tr>\n    <tr>\n      <th>Career_Type</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>AI Career</th>\n      <td>28310</td>\n      <td>11713</td>\n      <td>133344.66</td>\n      <td>130500.0</td>\n      <td>23585.0</td>\n      <td>500000.0</td>\n      <td>43401.01</td>\n    </tr>\n    <tr>\n      <th>Non-AI Career</th>\n      <td>44188</td>\n      <td>19095</td>\n      <td>108512.87</td>\n      <td>102500.0</td>\n      <td>15860.0</td>\n      <td>500000.0</td>\n      <td>43552.64</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nThe table clearly shows that AI-related careers offer higher mean and median salaries compared to non-AI careers. The minimum salary for AI jobs is also notably higher, indicating a stronger salary floor. Although both groups have similar standard deviations, suggesting comparable salary variability, the overall compensation level for AI roles is substantially greater.\n\n## Salary Distribution Visualization\n\nThe following boxplot visualizes the salary distributions for AI versus non-AI career categories. It graphically represents the median, interquartile ranges, and outliers for each group.\n\n::: {.cell execution_count=22}\n``` {.python .cell-code}\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\n\n# Load the dataset\ndf = pd.read_csv('lightcast_job_postings.csv', low_memory=False)\n\n# Tag careers before subsetting\ndef tag_ai(row):\n    title = str(row['TITLE_NAME']).lower()\n    industry = str(row['NAICS_2022_2_NAME']).lower()\n    if ('ai' in title or \n        'artificial intelligence' in title or \n        'machine learning' in title or \n        'data scientist' in title or \n        'deep learning' in title or \n        'nlp' in title or \n        'computer vision' in title or \n        'robotics' in title or \n        'ml' in title or \n        'data engineer' in title or \n        'ml engineer' in title or \n        'scientist' in title or \n        'professional, scientific, and technical services' in industry or \n        'information' in industry):\n        return 'AI Career'\n    else:\n        return 'Non-AI Career'\n\ndf['Career_Type'] = df.apply(tag_ai, axis=1)\n\n# Now subset only rows with valid salary\ndf_salary = df.dropna(subset=['SALARY'])\n\n# Plot without showing <Figure ...> output\nax = df_salary.boxplot(column='SALARY', by='Career_Type', figsize=(10,6))\nplt.title('Salary Comparison: AI vs Non-AI Careers')\nplt.suptitle('')\nplt.xlabel('Career Type')\nplt.ylabel('Salary ($)')\nplt.grid(True)\n\nplot_path = os.path.join('DATA', 'ai_vs_nonai_salary_comparison.png')\nplt.savefig(plot_path, dpi=300, bbox_inches='tight')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](final_report_files/figure-docx/cell-23-output-1.png){}\n:::\n:::\n\n\nThe boxplot highlights that AI careers have a higher median salary and a more compressed lower salary range compared to non-AI careers. While both groups exhibit high-end salary outliers (up to $500,000), non-AI careers show a greater spread of lower-end salaries. This suggests that AI careers offer more consistent and stable compensation, whereas non-AI jobs have more variability, particularly toward lower-paying positions.\n\n## Forecasting AI Career Trends \nTo explore future patterns, we used a simple linear regression model to forecast average AI salaries and job posting volumes over the next six months.\n\n::: {.cell execution_count=23}\n``` {.python .cell-code}\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport statsmodels.api as sm\n\n\ndf = pd.read_csv('lightcast_job_postings.csv', low_memory=False)\n\ndf['POSTED'] = pd.to_datetime(df['POSTED'], errors='coerce')\ndf['SALARY'] = pd.to_numeric(df['SALARY'], errors='coerce')\n\ndef tag_ai(row):\n    title = str(row['TITLE_NAME']).lower()\n    industry = str(row['NAICS_2022_2_NAME']).lower()\n    if ('ai' in title or 'artificial intelligence' in title or 'machine learning' in title or\n        'data scientist' in title or 'deep learning' in title or 'nlp' in title or\n        'computer vision' in title or 'robotics' in title or 'ml' in title or\n        'data engineer' in title or 'ml engineer' in title or 'scientist' in title or\n        'professional, scientific, and technical services' in industry or 'information' in industry):\n        return 'AI Career'\n    else:\n        return 'Non-AI Career'\n\ndf['Career_Type'] = df.apply(tag_ai, axis=1)\n\ndf_valid = df.dropna(subset=['POSTED'])\nmonthly_counts = df_valid.groupby([df_valid['POSTED'].dt.to_period('M'), 'Career_Type']) \\\n                         .size().unstack().fillna(0)\nmonthly_counts.index = monthly_counts.index.to_timestamp()\n\nplt.figure(figsize=(10, 5))\nmonthly_counts.plot(kind='line', marker='o', ax=plt.gca())\nplt.title(\"Monthly Job Postings: AI vs. Non-AI Careers\")\nplt.ylabel(\"Number of Postings\")\nplt.xlabel(\"Month\")\nplt.grid(True)\nplt.tight_layout()\njob_postings_path = \"DATA/monthly_job_postings_forecast.png\"\nplt.savefig(job_postings_path, dpi=300)\nplt.show()\n\ndf_ai = df[(df['Career_Type'] == 'AI Career') & (~df['SALARY'].isna())]\nmonthly_salary = df_ai.groupby(df_ai['POSTED'].dt.to_period('M'))['SALARY'].mean().dropna()\nmonthly_salary.index = monthly_salary.index.to_timestamp()\n\nX = sm.add_constant(range(len(monthly_salary)))\ny = monthly_salary.values\nmodel = sm.OLS(y, X).fit()\n\nfuture_periods = 6\nfuture_X = sm.add_constant(range(len(monthly_salary), len(monthly_salary) + future_periods))\nforecast = model.predict(future_X)\n\nlast_date = monthly_salary.index[-1]\nfuture_dates = [last_date + pd.DateOffset(months=i+1) for i in range(future_periods)]\n\nplt.figure(figsize=(10, 5))\nplt.plot(monthly_salary.index, monthly_salary.values, marker='o', label='Historical Avg Salary (AI)')\nplt.plot(future_dates, forecast, marker='x', linestyle='--', label='Forecast (Next 6 Months)')\nplt.title(\"Forecast: Average AI Salary Over Time\")\nplt.ylabel(\"Salary ($)\")\nplt.xlabel(\"Month\")\nplt.grid(True)\nplt.legend()\nplt.tight_layout()\nsalary_forecast_path = \"DATA/ai_salary_forecast.png\"\nplt.savefig(salary_forecast_path, dpi=300)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](final_report_files/figure-docx/cell-24-output-1.png){}\n:::\n\n::: {.cell-output .cell-output-display}\n![](final_report_files/figure-docx/cell-24-output-2.png){}\n:::\n:::\n\n\nThe analysis of monthly job postings reveals that Non-AI careers consistently dominate the U.S. job market, averaging around 9,000 postings per month. Despite experiencing a noticeable dip in July, Non-AI job volumes quickly rebounded in August and September, indicating strong demand recovery. In contrast, AI careers maintain a lower volume, typically ranging between 5,000 and 6,000 postings monthly. However, the trend among AI roles appears more stable, with minor fluctuations and a modest recovery following July’s decline. This suggests that while fewer in quantity, AI job postings demonstrate resilience and steady momentum in hiring activity.\n\nLooking at the salary trends for AI careers, historical data from May to September 2024 shows moderate fluctuations, with a pronounced dip in August representing the lowest average salary in that period. Using a simple linear regression model, forecasts from October 2024 through March 2025 indicate a gradual decline in average AI salaries. Importantly, this downward trend does not suggest collapse but rather points to a stabilizing market. As AI technologies become more widespread and accessible, the normalization of compensation—paired with a growing supply of skilled candidates—could be moderating previously inflated salary levels. Despite the projected dip, AI roles remain high-paying and continue to offer strong long-term potential.\n\n\n\n## Key Insights\n\nAI-related careers consistently offer higher salaries, with a mean of $133,344 and median of $130,500, compared to $108,513 and $102,500 respectively for non-AI roles.\n\nSalary variability remains relatively equal across both groups (~$43,000 standard deviation), but AI roles tend to avoid the lower-end salaries more common in non-AI positions.\n\nThe minimum salary for AI careers is substantially higher at $23,585, indicating a stronger baseline earning potential versus $15,860 for non-AI roles.\n\nThe maximum reported salary is identical across both categories ($500,000), likely reflecting high-level executive or specialized niche roles.\n\nAI job postings, while fewer in number, show consistent volume and a stable rebound after a mid-year dip, suggesting continued demand for AI talent.\n\nForecasting results predict a gradual decline in AI average salaries over the next six months, indicating potential market stabilization rather than contraction.\n\n## Conclusion\n\nThis analysis confirms that AI-related roles provide superior salary outcomes, both in average and median terms, and offer greater compensation stability at the lower end of the spectrum. Despite a projected slight decline in average salaries, AI positions remain highly competitive and rewarding.\n\nThese findings emphasize the value of developing AI-focused skill sets such as machine learning, NLP, and data engineering. For students, job seekers, and educators alike, aligning educational and career strategies with the AI sector’s continued evolution will be key to unlocking long-term financial and professional success.\n\n---\ntitle: \"Exploratory Data Analysis\"\nsubtitle: \"Uncovering Patterns in the Job Market Dataset\"\nauthor:\n  - name: Group 10\n    affiliations:\n      - id: bu\n        name: Boston University\n        city: Boston\n        state: MA\nformat: \n  html:\n    toc: true\n    number-sections: true\n    df-print: paged\n---\n\n# Introduction\n\nThis EDA explores key characteristics of the job postings dataset, including salary distribution, industry representation, geographic trends, and temporal patterns. The analysis provides insights that guide downstream tasks such as skill gap analysis, clustering, and prediction.\n\n# Dataset Overview\n\n::: {.cell execution_count=24}\n``` {.python .cell-code}\nimport pandas as pd\n\ndf = pd.read_csv('region_analysis/lightcast_job_postings.csv')\ndf.info()\ndf.head()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nC:\\Users\\honga\\AppData\\Local\\Temp\\ipykernel_23744\\1554311625.py:3: DtypeWarning:\n\nColumns (19,30) have mixed types. Specify dtype option on import or set low_memory=False.\n\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 72498 entries, 0 to 72497\nColumns: 131 entries, ID to NAICS_2022_6_NAME\ndtypes: float64(38), object(93)\nmemory usage: 72.5+ MB\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=24}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>LAST_UPDATED_DATE</th>\n      <th>LAST_UPDATED_TIMESTAMP</th>\n      <th>DUPLICATES</th>\n      <th>POSTED</th>\n      <th>EXPIRED</th>\n      <th>DURATION</th>\n      <th>SOURCE_TYPES</th>\n      <th>SOURCES</th>\n      <th>URL</th>\n      <th>ACTIVE_URLS</th>\n      <th>ACTIVE_SOURCES_INFO</th>\n      <th>TITLE_RAW</th>\n      <th>BODY</th>\n      <th>MODELED_EXPIRED</th>\n      <th>MODELED_DURATION</th>\n      <th>COMPANY</th>\n      <th>COMPANY_NAME</th>\n      <th>COMPANY_RAW</th>\n      <th>COMPANY_IS_STAFFING</th>\n      <th>EDUCATION_LEVELS</th>\n      <th>EDUCATION_LEVELS_NAME</th>\n      <th>MIN_EDULEVELS</th>\n      <th>MIN_EDULEVELS_NAME</th>\n      <th>MAX_EDULEVELS</th>\n      <th>MAX_EDULEVELS_NAME</th>\n      <th>EMPLOYMENT_TYPE</th>\n      <th>EMPLOYMENT_TYPE_NAME</th>\n      <th>MIN_YEARS_EXPERIENCE</th>\n      <th>MAX_YEARS_EXPERIENCE</th>\n      <th>IS_INTERNSHIP</th>\n      <th>SALARY</th>\n      <th>REMOTE_TYPE</th>\n      <th>REMOTE_TYPE_NAME</th>\n      <th>ORIGINAL_PAY_PERIOD</th>\n      <th>SALARY_TO</th>\n      <th>SALARY_FROM</th>\n      <th>LOCATION</th>\n      <th>CITY</th>\n      <th>CITY_NAME</th>\n      <th>COUNTY</th>\n      <th>COUNTY_NAME</th>\n      <th>MSA</th>\n      <th>MSA_NAME</th>\n      <th>STATE</th>\n      <th>STATE_NAME</th>\n      <th>COUNTY_OUTGOING</th>\n      <th>COUNTY_NAME_OUTGOING</th>\n      <th>COUNTY_INCOMING</th>\n      <th>COUNTY_NAME_INCOMING</th>\n      <th>MSA_OUTGOING</th>\n      <th>MSA_NAME_OUTGOING</th>\n      <th>MSA_INCOMING</th>\n      <th>MSA_NAME_INCOMING</th>\n      <th>NAICS2</th>\n      <th>NAICS2_NAME</th>\n      <th>NAICS3</th>\n      <th>NAICS3_NAME</th>\n      <th>NAICS4</th>\n      <th>NAICS4_NAME</th>\n      <th>NAICS5</th>\n      <th>NAICS5_NAME</th>\n      <th>NAICS6</th>\n      <th>NAICS6_NAME</th>\n      <th>TITLE</th>\n      <th>TITLE_NAME</th>\n      <th>TITLE_CLEAN</th>\n      <th>SKILLS</th>\n      <th>SKILLS_NAME</th>\n      <th>SPECIALIZED_SKILLS</th>\n      <th>SPECIALIZED_SKILLS_NAME</th>\n      <th>CERTIFICATIONS</th>\n      <th>CERTIFICATIONS_NAME</th>\n      <th>COMMON_SKILLS</th>\n      <th>COMMON_SKILLS_NAME</th>\n      <th>SOFTWARE_SKILLS</th>\n      <th>SOFTWARE_SKILLS_NAME</th>\n      <th>ONET</th>\n      <th>ONET_NAME</th>\n      <th>ONET_2019</th>\n      <th>ONET_2019_NAME</th>\n      <th>CIP6</th>\n      <th>CIP6_NAME</th>\n      <th>CIP4</th>\n      <th>CIP4_NAME</th>\n      <th>CIP2</th>\n      <th>CIP2_NAME</th>\n      <th>SOC_2021_2</th>\n      <th>SOC_2021_2_NAME</th>\n      <th>SOC_2021_3</th>\n      <th>SOC_2021_3_NAME</th>\n      <th>SOC_2021_4</th>\n      <th>SOC_2021_4_NAME</th>\n      <th>SOC_2021_5</th>\n      <th>SOC_2021_5_NAME</th>\n      <th>LOT_CAREER_AREA</th>\n      <th>LOT_CAREER_AREA_NAME</th>\n      <th>LOT_OCCUPATION</th>\n      <th>LOT_OCCUPATION_NAME</th>\n      <th>LOT_SPECIALIZED_OCCUPATION</th>\n      <th>LOT_SPECIALIZED_OCCUPATION_NAME</th>\n      <th>LOT_OCCUPATION_GROUP</th>\n      <th>LOT_OCCUPATION_GROUP_NAME</th>\n      <th>LOT_V6_SPECIALIZED_OCCUPATION</th>\n      <th>LOT_V6_SPECIALIZED_OCCUPATION_NAME</th>\n      <th>LOT_V6_OCCUPATION</th>\n      <th>LOT_V6_OCCUPATION_NAME</th>\n      <th>LOT_V6_OCCUPATION_GROUP</th>\n      <th>LOT_V6_OCCUPATION_GROUP_NAME</th>\n      <th>LOT_V6_CAREER_AREA</th>\n      <th>LOT_V6_CAREER_AREA_NAME</th>\n      <th>SOC_2</th>\n      <th>SOC_2_NAME</th>\n      <th>SOC_3</th>\n      <th>SOC_3_NAME</th>\n      <th>SOC_4</th>\n      <th>SOC_4_NAME</th>\n      <th>SOC_5</th>\n      <th>SOC_5_NAME</th>\n      <th>LIGHTCAST_SECTORS</th>\n      <th>LIGHTCAST_SECTORS_NAME</th>\n      <th>NAICS_2022_2</th>\n      <th>NAICS_2022_2_NAME</th>\n      <th>NAICS_2022_3</th>\n      <th>NAICS_2022_3_NAME</th>\n      <th>NAICS_2022_4</th>\n      <th>NAICS_2022_4_NAME</th>\n      <th>NAICS_2022_5</th>\n      <th>NAICS_2022_5_NAME</th>\n      <th>NAICS_2022_6</th>\n      <th>NAICS_2022_6_NAME</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1f57d95acf4dc67ed2819eb12f049f6a5c11782c</td>\n      <td>9/6/2024</td>\n      <td>2024-09-06 20:32:57.352 Z</td>\n      <td>0.0</td>\n      <td>6/2/2024</td>\n      <td>6/8/2024</td>\n      <td>6.0</td>\n      <td>[\\n  \"Company\"\\n]</td>\n      <td>[\\n  \"brassring.com\"\\n]</td>\n      <td>[\\n  \"https://sjobs.brassring.com/TGnewUI/Sear...</td>\n      <td>[]</td>\n      <td>NaN</td>\n      <td>Enterprise Analyst (II-III)</td>\n      <td>31-May-2024\\n\\nEnterprise Analyst (II-III)\\n\\n...</td>\n      <td>6/8/2024</td>\n      <td>6.0</td>\n      <td>894731.0</td>\n      <td>Murphy USA</td>\n      <td>Murphy USA</td>\n      <td>False</td>\n      <td>[\\n  2\\n]</td>\n      <td>[\\n  \"Bachelor's degree\"\\n]</td>\n      <td>2.0</td>\n      <td>Bachelor's degree</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>Full-time (&gt; 32 hours)</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>[None]</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>{\\n  \"lat\": 33.20763,\\n  \"lon\": -92.6662674\\n}</td>\n      <td>RWwgRG9yYWRvLCBBUg==</td>\n      <td>El Dorado, AR</td>\n      <td>5139.0</td>\n      <td>Union, AR</td>\n      <td>20980.0</td>\n      <td>El Dorado, AR</td>\n      <td>5.0</td>\n      <td>Arkansas</td>\n      <td>5139.0</td>\n      <td>Union, AR</td>\n      <td>5139.0</td>\n      <td>Union, AR</td>\n      <td>20980.0</td>\n      <td>El Dorado, AR</td>\n      <td>20980.0</td>\n      <td>El Dorado, AR</td>\n      <td>44.0</td>\n      <td>Retail Trade</td>\n      <td>441.0</td>\n      <td>Motor Vehicle and Parts Dealers</td>\n      <td>4413.0</td>\n      <td>Automotive Parts, Accessories, and Tire Retailers</td>\n      <td>44133.0</td>\n      <td>Automotive Parts and Accessories Retailers</td>\n      <td>441330.0</td>\n      <td>Automotive Parts and Accessories Retailers</td>\n      <td>ET29C073C03D1F86B4</td>\n      <td>Enterprise Analysts</td>\n      <td>enterprise analyst ii iii</td>\n      <td>[\\n  \"KS126DB6T061MHD7RTGQ\",\\n  \"KS126706DPFD3...</td>\n      <td>[\\n  \"Merchandising\",\\n  \"Mathematics\",\\n  \"Pr...</td>\n      <td>[\\n  \"KS126DB6T061MHD7RTGQ\",\\n  \"KS128006L3V0H...</td>\n      <td>[\\n  \"Merchandising\",\\n  \"Predictive Modeling\"...</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[\\n  \"KS126706DPFD3354M7YK\",\\n  \"KS1280B68GD79...</td>\n      <td>[\\n  \"Mathematics\",\\n  \"Presentations\",\\n  \"Re...</td>\n      <td>[\\n  \"KS440W865GC4VRBW6LJP\",\\n  \"KS13USA80NE38...</td>\n      <td>[\\n  \"SQL (Programming Language)\",\\n  \"Power B...</td>\n      <td>15-2051.01</td>\n      <td>Business Intelligence Analysts</td>\n      <td>15-2051.01</td>\n      <td>Business Intelligence Analysts</td>\n      <td>[\\n  \"45.0601\",\\n  \"27.0101\"\\n]</td>\n      <td>[\\n  \"Economics, General\",\\n  \"Mathematics, Ge...</td>\n      <td>[\\n  \"45.06\",\\n  \"27.01\"\\n]</td>\n      <td>[\\n  \"Economics\",\\n  \"Mathematics\"\\n]</td>\n      <td>[\\n  \"45\",\\n  \"27\"\\n]</td>\n      <td>[\\n  \"Social Sciences\",\\n  \"Mathematics and St...</td>\n      <td>15-0000</td>\n      <td>Computer and Mathematical Occupations</td>\n      <td>15-2000</td>\n      <td>Mathematical Science Occupations</td>\n      <td>15-2050</td>\n      <td>Data Scientists</td>\n      <td>15-2051</td>\n      <td>Data Scientists</td>\n      <td>23.0</td>\n      <td>Information Technology and Computer Science</td>\n      <td>231010.0</td>\n      <td>Business Intelligence Analyst</td>\n      <td>23101011.0</td>\n      <td>General ERP Analyst / Consultant</td>\n      <td>2310.0</td>\n      <td>Business Intelligence</td>\n      <td>23101011.0</td>\n      <td>General ERP Analyst / Consultant</td>\n      <td>231010.0</td>\n      <td>Business Intelligence Analyst</td>\n      <td>2310.0</td>\n      <td>Business Intelligence</td>\n      <td>23.0</td>\n      <td>Information Technology and Computer Science</td>\n      <td>15-0000</td>\n      <td>Computer and Mathematical Occupations</td>\n      <td>15-2000</td>\n      <td>Mathematical Science Occupations</td>\n      <td>15-2050</td>\n      <td>Data Scientists</td>\n      <td>15-2051</td>\n      <td>Data Scientists</td>\n      <td>[\\n  7\\n]</td>\n      <td>[\\n  \"Artificial Intelligence\"\\n]</td>\n      <td>44.0</td>\n      <td>Retail Trade</td>\n      <td>441.0</td>\n      <td>Motor Vehicle and Parts Dealers</td>\n      <td>4413.0</td>\n      <td>Automotive Parts, Accessories, and Tire Retailers</td>\n      <td>44133.0</td>\n      <td>Automotive Parts and Accessories Retailers</td>\n      <td>441330.0</td>\n      <td>Automotive Parts and Accessories Retailers</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0cb072af26757b6c4ea9464472a50a443af681ac</td>\n      <td>8/2/2024</td>\n      <td>2024-08-02 17:08:58.838 Z</td>\n      <td>0.0</td>\n      <td>6/2/2024</td>\n      <td>8/1/2024</td>\n      <td>NaN</td>\n      <td>[\\n  \"Job Board\"\\n]</td>\n      <td>[\\n  \"maine.gov\"\\n]</td>\n      <td>[\\n  \"https://joblink.maine.gov/jobs/1085740\"\\n]</td>\n      <td>[]</td>\n      <td>NaN</td>\n      <td>Oracle Consultant - Reports (3592)</td>\n      <td>Oracle Consultant - Reports (3592)\\n\\nat SMX i...</td>\n      <td>8/1/2024</td>\n      <td>NaN</td>\n      <td>133098.0</td>\n      <td>Smx Corporation Limited</td>\n      <td>SMX</td>\n      <td>True</td>\n      <td>[\\n  99\\n]</td>\n      <td>[\\n  \"No Education Listed\"\\n]</td>\n      <td>99.0</td>\n      <td>No Education Listed</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>Full-time (&gt; 32 hours)</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>Remote</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>{\\n  \"lat\": 44.3106241,\\n  \"lon\": -69.7794897\\n}</td>\n      <td>QXVndXN0YSwgTUU=</td>\n      <td>Augusta, ME</td>\n      <td>23011.0</td>\n      <td>Kennebec, ME</td>\n      <td>12300.0</td>\n      <td>Augusta-Waterville, ME</td>\n      <td>23.0</td>\n      <td>Maine</td>\n      <td>23011.0</td>\n      <td>Kennebec, ME</td>\n      <td>23011.0</td>\n      <td>Kennebec, ME</td>\n      <td>12300.0</td>\n      <td>Augusta-Waterville, ME</td>\n      <td>12300.0</td>\n      <td>Augusta-Waterville, ME</td>\n      <td>56.0</td>\n      <td>Administrative and Support and Waste Managemen...</td>\n      <td>561.0</td>\n      <td>Administrative and Support Services</td>\n      <td>5613.0</td>\n      <td>Employment Services</td>\n      <td>56132.0</td>\n      <td>Temporary Help Services</td>\n      <td>561320.0</td>\n      <td>Temporary Help Services</td>\n      <td>ET21DDA63780A7DC09</td>\n      <td>Oracle Consultants</td>\n      <td>oracle consultant reports</td>\n      <td>[\\n  \"KS122626T550SLQ7QZ1C\",\\n  \"KS123YJ6KVWC9...</td>\n      <td>[\\n  \"Procurement\",\\n  \"Financial Statements\",...</td>\n      <td>[\\n  \"KS122626T550SLQ7QZ1C\",\\n  \"KS123YJ6KVWC9...</td>\n      <td>[\\n  \"Procurement\",\\n  \"Financial Statements\",...</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[\\n  \"BGSBF3F508F7F46312E3\",\\n  \"ESEA839CED378...</td>\n      <td>[\\n  \"Oracle Business Intelligence (BI) / OBIA...</td>\n      <td>15-2051.01</td>\n      <td>Business Intelligence Analysts</td>\n      <td>15-2051.01</td>\n      <td>Business Intelligence Analysts</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>15-0000</td>\n      <td>Computer and Mathematical Occupations</td>\n      <td>15-2000</td>\n      <td>Mathematical Science Occupations</td>\n      <td>15-2050</td>\n      <td>Data Scientists</td>\n      <td>15-2051</td>\n      <td>Data Scientists</td>\n      <td>23.0</td>\n      <td>Information Technology and Computer Science</td>\n      <td>231010.0</td>\n      <td>Business Intelligence Analyst</td>\n      <td>23101012.0</td>\n      <td>Oracle Consultant / Analyst</td>\n      <td>2310.0</td>\n      <td>Business Intelligence</td>\n      <td>23101012.0</td>\n      <td>Oracle Consultant / Analyst</td>\n      <td>231010.0</td>\n      <td>Business Intelligence Analyst</td>\n      <td>2310.0</td>\n      <td>Business Intelligence</td>\n      <td>23.0</td>\n      <td>Information Technology and Computer Science</td>\n      <td>15-0000</td>\n      <td>Computer and Mathematical Occupations</td>\n      <td>15-2000</td>\n      <td>Mathematical Science Occupations</td>\n      <td>15-2050</td>\n      <td>Data Scientists</td>\n      <td>15-2051</td>\n      <td>Data Scientists</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>56.0</td>\n      <td>Administrative and Support and Waste Managemen...</td>\n      <td>561.0</td>\n      <td>Administrative and Support Services</td>\n      <td>5613.0</td>\n      <td>Employment Services</td>\n      <td>56132.0</td>\n      <td>Temporary Help Services</td>\n      <td>561320.0</td>\n      <td>Temporary Help Services</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>85318b12b3331fa490d32ad014379df01855c557</td>\n      <td>9/6/2024</td>\n      <td>2024-09-06 20:32:57.352 Z</td>\n      <td>1.0</td>\n      <td>6/2/2024</td>\n      <td>7/7/2024</td>\n      <td>35.0</td>\n      <td>[\\n  \"Job Board\"\\n]</td>\n      <td>[\\n  \"dejobs.org\"\\n]</td>\n      <td>[\\n  \"https://dejobs.org/dallas-tx/data-analys...</td>\n      <td>[]</td>\n      <td>NaN</td>\n      <td>Data Analyst</td>\n      <td>Taking care of people is at the heart of every...</td>\n      <td>6/10/2024</td>\n      <td>8.0</td>\n      <td>39063746.0</td>\n      <td>Sedgwick</td>\n      <td>Sedgwick</td>\n      <td>False</td>\n      <td>[\\n  2\\n]</td>\n      <td>[\\n  \"Bachelor's degree\"\\n]</td>\n      <td>2.0</td>\n      <td>Bachelor's degree</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>Full-time (&gt; 32 hours)</td>\n      <td>5.0</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>[None]</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>{\\n  \"lat\": 32.7766642,\\n  \"lon\": -96.7969879\\n}</td>\n      <td>RGFsbGFzLCBUWA==</td>\n      <td>Dallas, TX</td>\n      <td>48113.0</td>\n      <td>Dallas, TX</td>\n      <td>19100.0</td>\n      <td>Dallas-Fort Worth-Arlington, TX</td>\n      <td>48.0</td>\n      <td>Texas</td>\n      <td>48113.0</td>\n      <td>Dallas, TX</td>\n      <td>48113.0</td>\n      <td>Dallas, TX</td>\n      <td>19100.0</td>\n      <td>Dallas-Fort Worth-Arlington, TX</td>\n      <td>19100.0</td>\n      <td>Dallas-Fort Worth-Arlington, TX</td>\n      <td>52.0</td>\n      <td>Finance and Insurance</td>\n      <td>524.0</td>\n      <td>Insurance Carriers and Related Activities</td>\n      <td>5242.0</td>\n      <td>Agencies, Brokerages, and Other Insurance Rela...</td>\n      <td>52429.0</td>\n      <td>Other Insurance Related Activities</td>\n      <td>524291.0</td>\n      <td>Claims Adjusting</td>\n      <td>ET3037E0C947A02404</td>\n      <td>Data Analysts</td>\n      <td>data analyst</td>\n      <td>[\\n  \"KS1218W78FGVPVP2KXPX\",\\n  \"ESF3939CE1F80...</td>\n      <td>[\\n  \"Management\",\\n  \"Exception Reporting\",\\n...</td>\n      <td>[\\n  \"ESF3939CE1F80C10C327\",\\n  \"KS120GV6C72JM...</td>\n      <td>[\\n  \"Exception Reporting\",\\n  \"Data Analysis\"...</td>\n      <td>[\\n  \"KS683TN76T77DQDVBZ1B\"\\n]</td>\n      <td>[\\n  \"Security Clearance\"\\n]</td>\n      <td>[\\n  \"KS1218W78FGVPVP2KXPX\",\\n  \"BGS1ADAA36DB6...</td>\n      <td>[\\n  \"Management\",\\n  \"Report Writing\",\\n  \"In...</td>\n      <td>[\\n  \"KS126HY6YLTB9R7XJC4Z\"\\n]</td>\n      <td>[\\n  \"Microsoft Office\"\\n]</td>\n      <td>15-2051.01</td>\n      <td>Business Intelligence Analysts</td>\n      <td>15-2051.01</td>\n      <td>Business Intelligence Analysts</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>15-0000</td>\n      <td>Computer and Mathematical Occupations</td>\n      <td>15-2000</td>\n      <td>Mathematical Science Occupations</td>\n      <td>15-2050</td>\n      <td>Data Scientists</td>\n      <td>15-2051</td>\n      <td>Data Scientists</td>\n      <td>23.0</td>\n      <td>Information Technology and Computer Science</td>\n      <td>231113.0</td>\n      <td>Data / Data Mining Analyst</td>\n      <td>23111310.0</td>\n      <td>Data Analyst</td>\n      <td>2311.0</td>\n      <td>Data Analysis and Mathematics</td>\n      <td>23111310.0</td>\n      <td>Data Analyst</td>\n      <td>231113.0</td>\n      <td>Data / Data Mining Analyst</td>\n      <td>2311.0</td>\n      <td>Data Analysis and Mathematics</td>\n      <td>23.0</td>\n      <td>Information Technology and Computer Science</td>\n      <td>15-0000</td>\n      <td>Computer and Mathematical Occupations</td>\n      <td>15-2000</td>\n      <td>Mathematical Science Occupations</td>\n      <td>15-2050</td>\n      <td>Data Scientists</td>\n      <td>15-2051</td>\n      <td>Data Scientists</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>52.0</td>\n      <td>Finance and Insurance</td>\n      <td>524.0</td>\n      <td>Insurance Carriers and Related Activities</td>\n      <td>5242.0</td>\n      <td>Agencies, Brokerages, and Other Insurance Rela...</td>\n      <td>52429.0</td>\n      <td>Other Insurance Related Activities</td>\n      <td>524291.0</td>\n      <td>Claims Adjusting</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1b5c3941e54a1889ef4f8ae55b401a550708a310</td>\n      <td>9/6/2024</td>\n      <td>2024-09-06 20:32:57.352 Z</td>\n      <td>1.0</td>\n      <td>6/2/2024</td>\n      <td>7/20/2024</td>\n      <td>48.0</td>\n      <td>[\\n  \"Job Board\"\\n]</td>\n      <td>[\\n  \"disabledperson.com\",\\n  \"dejobs.org\"\\n]</td>\n      <td>[\\n  \"https://www.disabledperson.com/jobs/5948...</td>\n      <td>[]</td>\n      <td>NaN</td>\n      <td>Sr. Lead Data Mgmt. Analyst - SAS Product Owner</td>\n      <td>About this role:\\n\\nWells Fargo is looking for...</td>\n      <td>6/12/2024</td>\n      <td>10.0</td>\n      <td>37615159.0</td>\n      <td>Wells Fargo</td>\n      <td>Wells Fargo</td>\n      <td>False</td>\n      <td>[\\n  99\\n]</td>\n      <td>[\\n  \"No Education Listed\"\\n]</td>\n      <td>99.0</td>\n      <td>No Education Listed</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>Full-time (&gt; 32 hours)</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>[None]</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>{\\n  \"lat\": 33.4483771,\\n  \"lon\": -112.0740373\\n}</td>\n      <td>UGhvZW5peCwgQVo=</td>\n      <td>Phoenix, AZ</td>\n      <td>4013.0</td>\n      <td>Maricopa, AZ</td>\n      <td>38060.0</td>\n      <td>Phoenix-Mesa-Chandler, AZ</td>\n      <td>4.0</td>\n      <td>Arizona</td>\n      <td>4013.0</td>\n      <td>Maricopa, AZ</td>\n      <td>4013.0</td>\n      <td>Maricopa, AZ</td>\n      <td>38060.0</td>\n      <td>Phoenix-Mesa-Chandler, AZ</td>\n      <td>38060.0</td>\n      <td>Phoenix-Mesa-Chandler, AZ</td>\n      <td>52.0</td>\n      <td>Finance and Insurance</td>\n      <td>522.0</td>\n      <td>Credit Intermediation and Related Activities</td>\n      <td>5221.0</td>\n      <td>Depository Credit Intermediation</td>\n      <td>52211.0</td>\n      <td>Commercial Banking</td>\n      <td>522110.0</td>\n      <td>Commercial Banking</td>\n      <td>ET2114E0404BA30075</td>\n      <td>Management Analysts</td>\n      <td>sr lead data mgmt analyst sas product owner</td>\n      <td>[\\n  \"KS123QX62QYTC4JF38H8\",\\n  \"KS7G6NP6R6L1H...</td>\n      <td>[\\n  \"Exit Strategies\",\\n  \"Reliability\",\\n  \"...</td>\n      <td>[\\n  \"KS123QX62QYTC4JF38H8\",\\n  \"KS441PQ64HT13...</td>\n      <td>[\\n  \"Exit Strategies\",\\n  \"User Story\",\\n  \"H...</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[\\n  \"KS7G6NP6R6L1H1SKFTSY\",\\n  \"KS1218W78FGVP...</td>\n      <td>[\\n  \"Reliability\",\\n  \"Management\",\\n  \"Strat...</td>\n      <td>[\\n  \"KS4409D76NW1S5LNCL18\",\\n  \"ESC7869CF7378...</td>\n      <td>[\\n  \"SAS (Software)\",\\n  \"Google Cloud Platfo...</td>\n      <td>15-2051.01</td>\n      <td>Business Intelligence Analysts</td>\n      <td>15-2051.01</td>\n      <td>Business Intelligence Analysts</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>15-0000</td>\n      <td>Computer and Mathematical Occupations</td>\n      <td>15-2000</td>\n      <td>Mathematical Science Occupations</td>\n      <td>15-2050</td>\n      <td>Data Scientists</td>\n      <td>15-2051</td>\n      <td>Data Scientists</td>\n      <td>23.0</td>\n      <td>Information Technology and Computer Science</td>\n      <td>231113.0</td>\n      <td>Data / Data Mining Analyst</td>\n      <td>23111310.0</td>\n      <td>Data Analyst</td>\n      <td>2311.0</td>\n      <td>Data Analysis and Mathematics</td>\n      <td>23111310.0</td>\n      <td>Data Analyst</td>\n      <td>231113.0</td>\n      <td>Data / Data Mining Analyst</td>\n      <td>2311.0</td>\n      <td>Data Analysis and Mathematics</td>\n      <td>23.0</td>\n      <td>Information Technology and Computer Science</td>\n      <td>15-0000</td>\n      <td>Computer and Mathematical Occupations</td>\n      <td>15-2000</td>\n      <td>Mathematical Science Occupations</td>\n      <td>15-2050</td>\n      <td>Data Scientists</td>\n      <td>15-2051</td>\n      <td>Data Scientists</td>\n      <td>[\\n  6\\n]</td>\n      <td>[\\n  \"Data Privacy/Protection\"\\n]</td>\n      <td>52.0</td>\n      <td>Finance and Insurance</td>\n      <td>522.0</td>\n      <td>Credit Intermediation and Related Activities</td>\n      <td>5221.0</td>\n      <td>Depository Credit Intermediation</td>\n      <td>52211.0</td>\n      <td>Commercial Banking</td>\n      <td>522110.0</td>\n      <td>Commercial Banking</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>cb5ca25f02bdf25c13edfede7931508bfd9e858f</td>\n      <td>6/19/2024</td>\n      <td>2024-06-19 07:00:00.000 Z</td>\n      <td>0.0</td>\n      <td>6/2/2024</td>\n      <td>6/17/2024</td>\n      <td>15.0</td>\n      <td>[\\n  \"FreeJobBoard\"\\n]</td>\n      <td>[\\n  \"craigslist.org\"\\n]</td>\n      <td>[\\n  \"https://modesto.craigslist.org/sls/77475...</td>\n      <td>[]</td>\n      <td>NaN</td>\n      <td>Comisiones de $1000 - $3000 por semana... Comi...</td>\n      <td>Comisiones de $1000 - $3000 por semana... Comi...</td>\n      <td>6/17/2024</td>\n      <td>15.0</td>\n      <td>0.0</td>\n      <td>Unclassified</td>\n      <td>LH/GM</td>\n      <td>False</td>\n      <td>[\\n  99\\n]</td>\n      <td>[\\n  \"No Education Listed\"\\n]</td>\n      <td>99.0</td>\n      <td>No Education Listed</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3.0</td>\n      <td>Part-time / full-time</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>92500.0</td>\n      <td>0.0</td>\n      <td>[None]</td>\n      <td>year</td>\n      <td>150000.0</td>\n      <td>35000.0</td>\n      <td>{\\n  \"lat\": 37.6392595,\\n  \"lon\": -120.9970014\\n}</td>\n      <td>TW9kZXN0bywgQ0E=</td>\n      <td>Modesto, CA</td>\n      <td>6099.0</td>\n      <td>Stanislaus, CA</td>\n      <td>33700.0</td>\n      <td>Modesto, CA</td>\n      <td>6.0</td>\n      <td>California</td>\n      <td>6099.0</td>\n      <td>Stanislaus, CA</td>\n      <td>6099.0</td>\n      <td>Stanislaus, CA</td>\n      <td>33700.0</td>\n      <td>Modesto, CA</td>\n      <td>33700.0</td>\n      <td>Modesto, CA</td>\n      <td>99.0</td>\n      <td>Unclassified Industry</td>\n      <td>999.0</td>\n      <td>Unclassified Industry</td>\n      <td>9999.0</td>\n      <td>Unclassified Industry</td>\n      <td>99999.0</td>\n      <td>Unclassified Industry</td>\n      <td>999999.0</td>\n      <td>Unclassified Industry</td>\n      <td>ET0000000000000000</td>\n      <td>Unclassified</td>\n      <td>comisiones de por semana comiensa rapido</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>15-2051.01</td>\n      <td>Business Intelligence Analysts</td>\n      <td>15-2051.01</td>\n      <td>Business Intelligence Analysts</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>15-0000</td>\n      <td>Computer and Mathematical Occupations</td>\n      <td>15-2000</td>\n      <td>Mathematical Science Occupations</td>\n      <td>15-2050</td>\n      <td>Data Scientists</td>\n      <td>15-2051</td>\n      <td>Data Scientists</td>\n      <td>23.0</td>\n      <td>Information Technology and Computer Science</td>\n      <td>231010.0</td>\n      <td>Business Intelligence Analyst</td>\n      <td>23101012.0</td>\n      <td>Oracle Consultant / Analyst</td>\n      <td>2310.0</td>\n      <td>Business Intelligence</td>\n      <td>23101012.0</td>\n      <td>Oracle Consultant / Analyst</td>\n      <td>231010.0</td>\n      <td>Business Intelligence Analyst</td>\n      <td>2310.0</td>\n      <td>Business Intelligence</td>\n      <td>23.0</td>\n      <td>Information Technology and Computer Science</td>\n      <td>15-0000</td>\n      <td>Computer and Mathematical Occupations</td>\n      <td>15-2000</td>\n      <td>Mathematical Science Occupations</td>\n      <td>15-2050</td>\n      <td>Data Scientists</td>\n      <td>15-2051</td>\n      <td>Data Scientists</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>99.0</td>\n      <td>Unclassified Industry</td>\n      <td>999.0</td>\n      <td>Unclassified Industry</td>\n      <td>9999.0</td>\n      <td>Unclassified Industry</td>\n      <td>99999.0</td>\n      <td>Unclassified Industry</td>\n      <td>999999.0</td>\n      <td>Unclassified Industry</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n# Handling Missing Data\n\n::: {.cell execution_count=25}\n``` {.python .cell-code}\ndf.isnull().mean().sort_values(ascending=False).head(10)\n```\n\n::: {.cell-output .cell-output-display execution_count=25}\n```\nACTIVE_SOURCES_INFO       0.892163\nMAX_YEARS_EXPERIENCE      0.883721\nMAX_EDULEVELS_NAME        0.774959\nMAX_EDULEVELS             0.774959\nLIGHTCAST_SECTORS         0.754655\nLIGHTCAST_SECTORS_NAME    0.754655\nSALARY                    0.575050\nSALARY_FROM               0.553119\nSALARY_TO                 0.553119\nORIGINAL_PAY_PERIOD       0.553119\ndtype: float64\n```\n:::\n:::\n\n\n# Salary Distribution\n\n::: {.cell execution_count=26}\n``` {.python .cell-code}\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndf['SALARY'] = pd.to_numeric(df['SALARY'], errors='coerce')\nplt.figure(figsize=(10,6))\nsns.histplot(df['SALARY'], bins=50, kde=True)\nplt.title(\"Salary Distribution\")\nplt.xlabel(\"Salary ($)\")\nplt.ylabel(\"Frequency\")\nplt.xlim(0, 300000)\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](final_report_files/figure-docx/cell-27-output-1.png){}\n:::\n:::\n\n\n# Top 10 Job Titles\n\n::: {.cell execution_count=27}\n``` {.python .cell-code}\ndf['TITLE_NAME'].value_counts().head(10)\n```\n\n::: {.cell-output .cell-output-display execution_count=27}\n```\nTITLE_NAME\nData Analysts                     8591\nUnclassified                      3149\nBusiness Intelligence Analysts    2072\nEnterprise Architects             1999\nOracle Cloud HCM Consultants      1042\nData Modelers                      668\nData Governance Analysts           628\nData Analytics Engineers           537\nERP Business Analysts              488\nData Quality Analysts              467\nName: count, dtype: int64\n```\n:::\n:::\n\n\n# Top 10 Industries\n\n::: {.cell execution_count=28}\n``` {.python .cell-code}\ndf['NAICS_2022_2_NAME'].value_counts().head(10)\n```\n\n::: {.cell-output .cell-output-display execution_count=28}\n```\nNAICS_2022_2_NAME\nProfessional, Scientific, and Technical Services                            23315\nUnclassified Industry                                                        9488\nAdministrative and Support and Waste Management and Remediation Services     8628\nFinance and Insurance                                                        7342\nManufacturing                                                                4827\nInformation                                                                  3967\nHealth Care and Social Assistance                                            2877\nWholesale Trade                                                              2141\nEducational Services                                                         2004\nRetail Trade                                                                 1953\nName: count, dtype: int64\n```\n:::\n:::\n\n\n# Job Postings by State\n\n::: {.cell execution_count=29}\n``` {.python .cell-code}\nstate_counts = df['STATE_NAME'].value_counts().head(15)\nstate_counts.plot(kind='barh', figsize=(10,6), color='steelblue')\nplt.title(\"Top 15 States by Job Postings\")\nplt.xlabel(\"Number of Postings\")\nplt.gca().invert_yaxis()\nplt.grid(True, linestyle='--', alpha=0.5)\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](final_report_files/figure-docx/cell-30-output-1.png){}\n:::\n:::\n\n\n# Posting Trends Over Time\n\n::: {.cell execution_count=30}\n``` {.python .cell-code}\ndf['POSTED'] = pd.to_datetime(df['POSTED'], errors='coerce')\ndf['POSTED'].dt.to_period('M').value_counts().sort_index().plot(kind='line', figsize=(12,6))\nplt.title(\"Job Postings Over Time\")\nplt.ylabel(\"Number of Postings\")\nplt.xlabel(\"Month\")\nplt.grid(True, alpha=0.5)\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](final_report_files/figure-docx/cell-31-output-1.png){}\n:::\n:::\n\n\n::: {.cell execution_count=31}\n``` {.python .cell-code}\nprint(df.columns.tolist())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n['ID', 'LAST_UPDATED_DATE', 'LAST_UPDATED_TIMESTAMP', 'DUPLICATES', 'POSTED', 'EXPIRED', 'DURATION', 'SOURCE_TYPES', 'SOURCES', 'URL', 'ACTIVE_URLS', 'ACTIVE_SOURCES_INFO', 'TITLE_RAW', 'BODY', 'MODELED_EXPIRED', 'MODELED_DURATION', 'COMPANY', 'COMPANY_NAME', 'COMPANY_RAW', 'COMPANY_IS_STAFFING', 'EDUCATION_LEVELS', 'EDUCATION_LEVELS_NAME', 'MIN_EDULEVELS', 'MIN_EDULEVELS_NAME', 'MAX_EDULEVELS', 'MAX_EDULEVELS_NAME', 'EMPLOYMENT_TYPE', 'EMPLOYMENT_TYPE_NAME', 'MIN_YEARS_EXPERIENCE', 'MAX_YEARS_EXPERIENCE', 'IS_INTERNSHIP', 'SALARY', 'REMOTE_TYPE', 'REMOTE_TYPE_NAME', 'ORIGINAL_PAY_PERIOD', 'SALARY_TO', 'SALARY_FROM', 'LOCATION', 'CITY', 'CITY_NAME', 'COUNTY', 'COUNTY_NAME', 'MSA', 'MSA_NAME', 'STATE', 'STATE_NAME', 'COUNTY_OUTGOING', 'COUNTY_NAME_OUTGOING', 'COUNTY_INCOMING', 'COUNTY_NAME_INCOMING', 'MSA_OUTGOING', 'MSA_NAME_OUTGOING', 'MSA_INCOMING', 'MSA_NAME_INCOMING', 'NAICS2', 'NAICS2_NAME', 'NAICS3', 'NAICS3_NAME', 'NAICS4', 'NAICS4_NAME', 'NAICS5', 'NAICS5_NAME', 'NAICS6', 'NAICS6_NAME', 'TITLE', 'TITLE_NAME', 'TITLE_CLEAN', 'SKILLS', 'SKILLS_NAME', 'SPECIALIZED_SKILLS', 'SPECIALIZED_SKILLS_NAME', 'CERTIFICATIONS', 'CERTIFICATIONS_NAME', 'COMMON_SKILLS', 'COMMON_SKILLS_NAME', 'SOFTWARE_SKILLS', 'SOFTWARE_SKILLS_NAME', 'ONET', 'ONET_NAME', 'ONET_2019', 'ONET_2019_NAME', 'CIP6', 'CIP6_NAME', 'CIP4', 'CIP4_NAME', 'CIP2', 'CIP2_NAME', 'SOC_2021_2', 'SOC_2021_2_NAME', 'SOC_2021_3', 'SOC_2021_3_NAME', 'SOC_2021_4', 'SOC_2021_4_NAME', 'SOC_2021_5', 'SOC_2021_5_NAME', 'LOT_CAREER_AREA', 'LOT_CAREER_AREA_NAME', 'LOT_OCCUPATION', 'LOT_OCCUPATION_NAME', 'LOT_SPECIALIZED_OCCUPATION', 'LOT_SPECIALIZED_OCCUPATION_NAME', 'LOT_OCCUPATION_GROUP', 'LOT_OCCUPATION_GROUP_NAME', 'LOT_V6_SPECIALIZED_OCCUPATION', 'LOT_V6_SPECIALIZED_OCCUPATION_NAME', 'LOT_V6_OCCUPATION', 'LOT_V6_OCCUPATION_NAME', 'LOT_V6_OCCUPATION_GROUP', 'LOT_V6_OCCUPATION_GROUP_NAME', 'LOT_V6_CAREER_AREA', 'LOT_V6_CAREER_AREA_NAME', 'SOC_2', 'SOC_2_NAME', 'SOC_3', 'SOC_3_NAME', 'SOC_4', 'SOC_4_NAME', 'SOC_5', 'SOC_5_NAME', 'LIGHTCAST_SECTORS', 'LIGHTCAST_SECTORS_NAME', 'NAICS_2022_2', 'NAICS_2022_2_NAME', 'NAICS_2022_3', 'NAICS_2022_3_NAME', 'NAICS_2022_4', 'NAICS_2022_4_NAME', 'NAICS_2022_5', 'NAICS_2022_5_NAME', 'NAICS_2022_6', 'NAICS_2022_6_NAME']\n```\n:::\n:::\n\n\n---\n\ntitle: \"Skill Gap Analysis\"\nsubtitle: \"Comprehensive Data Cleaning & Exploratory Analysis of Job Market Trends\"\nauthor:\n  - name: \"Ritusri Mohan\"\n    affiliations:\n      - id: bu\n        name: Boston University\n        city: Boston\n        state: MA\nformat: \n  html:\n    toc: true\n    number-sections: true\n    df-print: paged\n---\n\n# Skill Gap Analysis\n\n\n\nIn this analysis, we evaluate the current skill levels of our team and compare them with industry requirements based on job postings data. This will help identify skill gaps and propose improvement strategies.\n\n\n\n## Team Skill Level Data\n\n::: {#clean-data .cell message='false' execution_count=32}\n``` {.python .cell-code}\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\n\n# Load dataset\ncsv_path = 'region_analysis/lightcast_job_postings.csv'\ndf = pd.read_csv(csv_path)\n\n# Drop unnecessary columns\ncolumns_to_drop = [\n    \"ID\", \"URL\", \"ACTIVE_URLS\", \"DUPLICATES\", \"LAST_UPDATED_TIMESTAMP\",\n    \"NAICS2\", \"NAICS3\", \"NAICS4\", \"NAICS5\", \"NAICS6\",\n    \"SOC_2\", \"SOC_3\", \"SOC_5\"\n]\ndf.drop(columns=columns_to_drop, inplace=True)\n\n# Drop columns with >50% missing\ndf.dropna(thresh=len(df) * 0.5, axis=1, inplace=True)\n\n# Fill missing values\nfor col in df.select_dtypes(include=[np.number]):\n    df[col].fillna(df[col].median(), inplace=True)\n\nfor col in df.select_dtypes(include=['object']):\n    df[col].fillna(\"Unknown\", inplace=True)\n\n# Drop duplicates\ndf.drop_duplicates(subset=[\"TITLE\", \"COMPANY\", \"LOCATION\", \"POSTED\"], keep=\"first\", inplace=True)\n```\n:::\n\n\n## Top 5 and Top 8 Software Skills from Job Postings\n\n::: {#top-software-skills .cell execution_count=33}\n``` {.python .cell-code}\n# Get top software skills from job postings\nsoftware_skills = (\n    df['SOFTWARE_SKILLS_NAME']\n    .dropna()\n    .str.replace(r'[\\[\\]\\n]', '', regex=True)  # Remove brackets and newlines\n    .str.split(',')\n    .explode()\n    .str.strip()\n)\n\n# Filter out empty strings\nsoftware_skills = software_skills[software_skills != '']\n\n# Get top 5 most frequent software skills\ntop_5_software_skills = software_skills.value_counts().head(5)\n\n# Extract skill names\ntop_5_skills = top_5_software_skills.index.tolist()\n\nprint(\"Top 5 software skills from job postings:\")\nprint(top_5_software_skills)\n\n# Get top 8 most frequent software skills\ntop_8_software_skills = software_skills.value_counts().head(8)\n\n# Extract skill names\ntop_8_skills = top_8_software_skills.index.tolist()\n\nprint(\"Top 8 software skills from job postings:\")\nprint(top_8_software_skills)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTop 5 software skills from job postings:\nSOFTWARE_SKILLS_NAME\n\"SQL (Programming Language)\"       20744\n\"Microsoft Excel\"                  12262\n\"Python (Programming Language)\"    11626\n\"SAP Applications\"                 11554\n\"Dashboard\"                        11373\nName: count, dtype: int64\nTop 8 software skills from job postings:\nSOFTWARE_SKILLS_NAME\n\"SQL (Programming Language)\"                  20744\n\"Microsoft Excel\"                             12262\n\"Python (Programming Language)\"               11626\n\"SAP Applications\"                            11554\n\"Dashboard\"                                   11373\n\"Tableau (Business Intelligence Software)\"    11220\n\"Power BI\"                                    10369\n\"Microsoft Office\"                             7238\nName: count, dtype: int64\n```\n:::\n:::\n\n\n::: {.cell execution_count=34}\n``` {.python .cell-code}\nimport pandas as pd\n\n# Define team skill levels (Proficiency scale: 1=Beginner, 5=Expert)\nskills_data = {\n    \"Name\": [\"Shreya\", \"An Ly\", \"Advait\", \"Ritusri\"],\n    \"SQL (Programming Language)\": [3, 2, 2, 3],\n    \"Microsoft Excel\": [4, 3, 3, 4],\n    \"Python (Programming Language)\": [3, 3, 3, 3],\n    \"SAP Applications\": [2, 1, 3, 2],\n    \"Dashboard\": [2, 2, 3, 4]\n}\n\ndf_skills = pd.DataFrame(skills_data)\ndf_skills.set_index(\"Name\", inplace=True)\ndf_skills\n\n```\n\n::: {#team-skills-5 .cell-output .cell-output-display execution_count=34}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SQL (Programming Language)</th>\n      <th>Microsoft Excel</th>\n      <th>Python (Programming Language)</th>\n      <th>SAP Applications</th>\n      <th>Dashboard</th>\n    </tr>\n    <tr>\n      <th>Name</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Shreya</th>\n      <td>3</td>\n      <td>4</td>\n      <td>3</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>An Ly</th>\n      <td>2</td>\n      <td>3</td>\n      <td>3</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>Advait</th>\n      <td>2</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>Ritusri</th>\n      <td>3</td>\n      <td>4</td>\n      <td>3</td>\n      <td>2</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {.cell execution_count=35}\n``` {.python .cell-code}\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Team skills for top 5\nskills_data_top5 = {\n    \"Name\": [\"Shreya\", \"An Ly\", \"Advait\", \"Ritusri\"],\n    \"SQL (Programming Language)\": [3, 2, 2, 3],\n    \"Microsoft Excel\": [4, 3, 3, 4],\n    \"Python (Programming Language)\": [3, 3, 3, 3],\n    \"SAP Applications\": [2, 1, 3, 2],\n    \"Dashboard\": [2, 2, 3, 4]\n}\n\ndf_skills_top5 = pd.DataFrame(skills_data_top5).set_index(\"Name\")\n\n# Plot Heatmap 1\nplt.figure(figsize=(10, 5))\nsns.heatmap(df_skills_top5, annot=True, cmap=\"YlOrBr\", linewidths=0.5)\nplt.title(\"Team Skill Levels – Top 5 Software Skills\")\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](final_report_files/figure-docx/heatmap-top5-output-1.png){#heatmap-top5}\n:::\n:::\n\n\n::: {.cell execution_count=36}\n``` {.python .cell-code}\nimport pandas as pd\n\n# Define team skill levels (Proficiency scale: 1=Beginner, 5=Expert)\nskills_data1 = {\n    \"Name\": [\"Shreya\", \"An Ly\", \"Advait\", \"Ritusri\"],\n    \"SQL (Programming Language)\": [3, 2, 2, 3],\n    \"Microsoft Excel\": [4, 3, 3, 4],\n    \"Python (Programming Language)\": [3, 3, 3, 3],\n    \"SAP Applications\": [2, 1, 3, 2],\n    \"Dashboard\": [2, 2, 3, 4],\n    \"Tableau (Business Intelligence Software)\":[0, 0, 0, 0],\n    \"Power BI\":[0, 0, 0, 0],\n    \"Microsoft Office\":[0, 0, 0, 0],\n    \n}\n\ndf_skills1 = pd.DataFrame(skills_data1)\ndf_skills1.set_index(\"Name\", inplace=True)\ndf_skills1\n```\n\n::: {#team-skills-8 .cell-output .cell-output-display execution_count=36}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SQL (Programming Language)</th>\n      <th>Microsoft Excel</th>\n      <th>Python (Programming Language)</th>\n      <th>SAP Applications</th>\n      <th>Dashboard</th>\n      <th>Tableau (Business Intelligence Software)</th>\n      <th>Power BI</th>\n      <th>Microsoft Office</th>\n    </tr>\n    <tr>\n      <th>Name</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Shreya</th>\n      <td>3</td>\n      <td>4</td>\n      <td>3</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>An Ly</th>\n      <td>2</td>\n      <td>3</td>\n      <td>3</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Advait</th>\n      <td>2</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Ritusri</th>\n      <td>3</td>\n      <td>4</td>\n      <td>3</td>\n      <td>2</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {.cell execution_count=37}\n``` {.python .cell-code}\nimport pandas as pd\n\n# Define team skill levels (Proficiency scale: 1=Beginner, 5=Expert)\nskills_data1 = {\n    \"Name\": [\"Shreya\", \"An Ly\", \"Advait\", \"Ritusri\"],\n    \"SQL (Programming Language)\": [3, 2, 2, 3],\n    \"Microsoft Excel\": [4, 3, 3, 4],\n    \"Python (Programming Language)\": [3, 3, 3, 3],\n    \"SAP Applications\": [2, 1, 3, 2],\n    \"Dashboard\": [2, 2, 3, 4],\n    \"Tableau (Business Intelligence Software)\":[0, 0, 0, 0],\n    \"Power BI\":[0, 0, 0, 0],\n    \"Microsoft Office\":[0, 0, 0, 0],\n    \n}\ndf_skills_top8 = pd.DataFrame(skills_data1).set_index(\"Name\")\n\n# Plot Heatmap 2\nplt.figure(figsize=(10, 5))\nsns.heatmap(df_skills_top8, annot=True, cmap=\"YlOrBr\", linewidths=0.5)\nplt.title(\"Team Skill Levels – Top 8 Software Skills\")\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](final_report_files/figure-docx/heatmap-top8-output-1.png){#heatmap-top8}\n:::\n:::\n\n\n### Improvement Plan\nThe heatmap analysis indicates that while the team has solid grounding in fundamental IT tools, there are significant gaps in certain enterprise and visualization technologies that are highly demanded in job postings. Addressing these gaps will elevate the team’s capabilities and make them more market-ready.\n\nSQL (Programming Language)\nAlthough the team has intermediate proficiency in SQL, moving towards expert-level understanding is essential. SQL remains one of the most requested skills across IT and data-centric roles. Advanced topics like complex joins, window functions, performance tuning, and writing optimized queries should be covered. Recommended resources include Coursera's SQL for Data Science and DataCamp SQL Career Track.\n\nPython (Programming Language)\nPython is the cornerstone of automation, analytics, and machine learning. The team should focus on advancing their skills beyond basic scripting. This includes learning about data manipulation (Pandas), building small projects, and exploring libraries used in data science or automation. Free resources like the Google Python Crash Course and the IBM Python for Data Science (Coursera) can be leveraged.\n\nSAP Applications\nSAP is currently one of the weakest areas within the team. Enterprise software skills like SAP are critical in corporate environments. Team members should target introductory SAP courses to gain a basic understanding of navigation, reporting, and common SAP modules. Free options like OpenSAP are recommended to start with.\n\nDashboarding Tools (Power BI / Tableau)\nVisual storytelling and data presentation are crucial skills in modern IT roles. As seen in the analysis, there is little to no current exposure to Power BI and Tableau. Training should start with beginner-friendly courses that teach how to create interactive dashboards and perform basic data analysis. Tableau Public and Microsoft Learn for Power BI offer excellent free resources.\n\nMicrosoft Excel\nWhile the team is relatively advanced in Excel, moving towards expert proficiency will unlock greater efficiencies. Topics like VBA macros, Power Query, pivot tables, and advanced formulas should be prioritized. Recommended platforms include LinkedIn Learning and Excel Skills for Business (Coursera).\n\nTableau, Power BI, and Microsoft Office (Missing Skills)\nThe missing ratings for Tableau, Power BI, and Microsoft Office indicate complete lack of knowledge. These tools are essential for reporting, business communication, and project collaboration in IT environments. Each team member should aim to reach at least intermediate level proficiency through self-paced courses and hands-on practice.\n\n#### Suggested Team Learning Plan\nTo close these gaps systematically:\n\nWeekly Learning Sessions: Rotate weekly responsibilities where each member shares what they learned about a specific skill.\n\nPair Learning: Pair up team members with stronger skills (e.g., SQL, Python) to support others.\n\nMicro-Certifications: Encourage completion of short certifications within 4–6 weeks (e.g., Tableau Desktop Specialist, Power BI Fundamentals).\n\nPractical Projects: Apply new skills through internal mock projects like building dashboards or writing Python scripts.\n\nTracking Progress: Regularly assess skill levels every month and update the heatmap to measure progress.\n\n### Conclusion\nThe skill gap analysis clearly highlights the team’s current strengths and opportunities for improvement. While foundational skills like SQL, Python, and Excel are relatively well developed, enterprise tools like SAP, Tableau, and Power BI remain significant blind spots.\n\nBy following the improvement plan and encouraging structured learning, the team will not only close existing gaps but also align with modern IT and data industry expectations. This proactive approach will make the team more versatile, industry-relevant, and ready for advanced career opportunities.\n\n---\n\n---\ntitle: \"ML Methods\"\nsubtitle: \"Predicting Job Posting Duration Using Random Forest Regressor\"\nauthor:\n  - name: \"Shreya Mani\"\n    affiliations:\n          - id: bu\n            name: Boston University\n            city: Boston\n            state: MA\nformat: \n  html:\n        toc: true\n        number-sections: true\n        df-print: paged\n---\n\n# Introduction\n\nIn this machine learning project, I aimed to predict how long job postings remain active (i.e., their DURATION) using a Random Forest Regressor. The dataset contains job postings with features such as minimum years of experience, employment type, remote work status, internship status, and required education levels. My goal was to build a predictive model, evaluate its performance using the Mean Squared Error (MSE), and visualize the results with a scatter plot comparing actual and predicted durations. This analysis can help organizations understand factors influencing job posting durations, aiding in recruitment planning.\n\n# Data Preprocessing\n\nI started by loading the dataset and selecting a subset of features relevant to predicting DURATION. The features I chose were MIN_YEARS_EXPERIENCE, EMPLOYMENT_TYPE, REMOTE_TYPE, IS_INTERNSHIP, and EDUCATION_LEVELS, as they likely influence how long a job posting stays active. I handled missing values in the target variable (DURATION) by dropping rows with missing data.\n\nA challenge arose with the EDUCATION_LEVELS column, which contained string representations of lists (e.g., '[\\n 2\\n]'). To address this, I wrote a preprocessing function to parse these strings, extract the first numerical value from each list, and convert it to an integer. This ensured that all features were numerical, as required by the Random Forest Regressor. The dataset was then split into training (80%) and testing (20%) sets to evaluate the model's performance on unseen data.\n\nHere’s the Python code I used for data preprocessing:\n\n::: {.cell message='false' execution_count=38}\n``` {.python .cell-code}\n# Import necessary libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport ast\n\n# Set display options\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', 100)\n\n# Auto-download CSV if missing\ncsv_path = 'region_analysis/lightcast_job_postings.csv'\nif not os.path.exists(csv_path):\n    print(f\"{csv_path} not found! Attempting to download...\")\n\n    os.makedirs('region_analysis', exist_ok=True)\n\n    try:\n        import gdown\n    except ImportError:\n        !pip install gdown\n        import gdown\n\n    file_id = '1V2GCHGt2dkFGqVBeoUFckU4IhUgk4ocQ'  # <--- your actual file ID\n    url = f'https://drive.google.com/uc?id={file_id}'\n    gdown.download(url, csv_path, quiet=False)\n    print(\"Download complete!\")\nelse:\n    print(f\"{csv_path} found. Proceeding...\")\n\n# Load the dataset\ndf = pd.read_csv('region_analysis/lightcast_job_postings.csv')\ndf.head()\ndf.tail()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nregion_analysis/lightcast_job_postings.csv found. Proceeding...\n```\n:::\n\n::: {#ml-data-cleaning .cell-output .cell-output-display execution_count=38}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>LAST_UPDATED_DATE</th>\n      <th>LAST_UPDATED_TIMESTAMP</th>\n      <th>DUPLICATES</th>\n      <th>POSTED</th>\n      <th>EXPIRED</th>\n      <th>DURATION</th>\n      <th>SOURCE_TYPES</th>\n      <th>SOURCES</th>\n      <th>URL</th>\n      <th>ACTIVE_URLS</th>\n      <th>ACTIVE_SOURCES_INFO</th>\n      <th>TITLE_RAW</th>\n      <th>BODY</th>\n      <th>MODELED_EXPIRED</th>\n      <th>MODELED_DURATION</th>\n      <th>COMPANY</th>\n      <th>COMPANY_NAME</th>\n      <th>COMPANY_RAW</th>\n      <th>COMPANY_IS_STAFFING</th>\n      <th>EDUCATION_LEVELS</th>\n      <th>EDUCATION_LEVELS_NAME</th>\n      <th>MIN_EDULEVELS</th>\n      <th>MIN_EDULEVELS_NAME</th>\n      <th>MAX_EDULEVELS</th>\n      <th>MAX_EDULEVELS_NAME</th>\n      <th>EMPLOYMENT_TYPE</th>\n      <th>EMPLOYMENT_TYPE_NAME</th>\n      <th>MIN_YEARS_EXPERIENCE</th>\n      <th>MAX_YEARS_EXPERIENCE</th>\n      <th>IS_INTERNSHIP</th>\n      <th>SALARY</th>\n      <th>REMOTE_TYPE</th>\n      <th>REMOTE_TYPE_NAME</th>\n      <th>ORIGINAL_PAY_PERIOD</th>\n      <th>SALARY_TO</th>\n      <th>SALARY_FROM</th>\n      <th>LOCATION</th>\n      <th>CITY</th>\n      <th>CITY_NAME</th>\n      <th>COUNTY</th>\n      <th>COUNTY_NAME</th>\n      <th>MSA</th>\n      <th>MSA_NAME</th>\n      <th>STATE</th>\n      <th>STATE_NAME</th>\n      <th>COUNTY_OUTGOING</th>\n      <th>COUNTY_NAME_OUTGOING</th>\n      <th>COUNTY_INCOMING</th>\n      <th>COUNTY_NAME_INCOMING</th>\n      <th>MSA_OUTGOING</th>\n      <th>MSA_NAME_OUTGOING</th>\n      <th>MSA_INCOMING</th>\n      <th>MSA_NAME_INCOMING</th>\n      <th>NAICS2</th>\n      <th>NAICS2_NAME</th>\n      <th>NAICS3</th>\n      <th>NAICS3_NAME</th>\n      <th>NAICS4</th>\n      <th>NAICS4_NAME</th>\n      <th>NAICS5</th>\n      <th>NAICS5_NAME</th>\n      <th>NAICS6</th>\n      <th>NAICS6_NAME</th>\n      <th>TITLE</th>\n      <th>TITLE_NAME</th>\n      <th>TITLE_CLEAN</th>\n      <th>SKILLS</th>\n      <th>SKILLS_NAME</th>\n      <th>SPECIALIZED_SKILLS</th>\n      <th>SPECIALIZED_SKILLS_NAME</th>\n      <th>CERTIFICATIONS</th>\n      <th>CERTIFICATIONS_NAME</th>\n      <th>COMMON_SKILLS</th>\n      <th>COMMON_SKILLS_NAME</th>\n      <th>SOFTWARE_SKILLS</th>\n      <th>SOFTWARE_SKILLS_NAME</th>\n      <th>ONET</th>\n      <th>ONET_NAME</th>\n      <th>ONET_2019</th>\n      <th>ONET_2019_NAME</th>\n      <th>CIP6</th>\n      <th>CIP6_NAME</th>\n      <th>CIP4</th>\n      <th>CIP4_NAME</th>\n      <th>CIP2</th>\n      <th>CIP2_NAME</th>\n      <th>SOC_2021_2</th>\n      <th>SOC_2021_2_NAME</th>\n      <th>SOC_2021_3</th>\n      <th>SOC_2021_3_NAME</th>\n      <th>SOC_2021_4</th>\n      <th>SOC_2021_4_NAME</th>\n      <th>SOC_2021_5</th>\n      <th>SOC_2021_5_NAME</th>\n      <th>LOT_CAREER_AREA</th>\n      <th>LOT_CAREER_AREA_NAME</th>\n      <th>LOT_OCCUPATION</th>\n      <th>LOT_OCCUPATION_NAME</th>\n      <th>LOT_SPECIALIZED_OCCUPATION</th>\n      <th>LOT_SPECIALIZED_OCCUPATION_NAME</th>\n      <th>LOT_OCCUPATION_GROUP</th>\n      <th>LOT_OCCUPATION_GROUP_NAME</th>\n      <th>LOT_V6_SPECIALIZED_OCCUPATION</th>\n      <th>LOT_V6_SPECIALIZED_OCCUPATION_NAME</th>\n      <th>LOT_V6_OCCUPATION</th>\n      <th>LOT_V6_OCCUPATION_NAME</th>\n      <th>LOT_V6_OCCUPATION_GROUP</th>\n      <th>LOT_V6_OCCUPATION_GROUP_NAME</th>\n      <th>LOT_V6_CAREER_AREA</th>\n      <th>LOT_V6_CAREER_AREA_NAME</th>\n      <th>SOC_2</th>\n      <th>SOC_2_NAME</th>\n      <th>SOC_3</th>\n      <th>SOC_3_NAME</th>\n      <th>SOC_4</th>\n      <th>SOC_4_NAME</th>\n      <th>SOC_5</th>\n      <th>SOC_5_NAME</th>\n      <th>LIGHTCAST_SECTORS</th>\n      <th>LIGHTCAST_SECTORS_NAME</th>\n      <th>NAICS_2022_2</th>\n      <th>NAICS_2022_2_NAME</th>\n      <th>NAICS_2022_3</th>\n      <th>NAICS_2022_3_NAME</th>\n      <th>NAICS_2022_4</th>\n      <th>NAICS_2022_4_NAME</th>\n      <th>NAICS_2022_5</th>\n      <th>NAICS_2022_5_NAME</th>\n      <th>NAICS_2022_6</th>\n      <th>NAICS_2022_6_NAME</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>72493</th>\n      <td>4c25b449c876d8e22d3e356f368cde5ab525cd03</td>\n      <td>9/6/2024</td>\n      <td>2024-09-06 20:32:57.352 Z</td>\n      <td>0.0</td>\n      <td>8/16/2024</td>\n      <td>8/31/2024</td>\n      <td>15.0</td>\n      <td>[\\n  \"Job Board\"\\n]</td>\n      <td>[\\n  \"dejobs.org\"\\n]</td>\n      <td>[\\n  \"https://dejobs.org/richmond-va/data-anal...</td>\n      <td>[]</td>\n      <td>NaN</td>\n      <td>Data Analyst</td>\n      <td>TEKsystems\\n\\n \\n \\n \\n\\n \\n\\n \\nData Analyst\\...</td>\n      <td>8/31/2024</td>\n      <td>15.0</td>\n      <td>37110815.0</td>\n      <td>TEKsystems</td>\n      <td>TEKsystems</td>\n      <td>False</td>\n      <td>[\\n  99\\n]</td>\n      <td>[\\n  \"No Education Listed\"\\n]</td>\n      <td>99.0</td>\n      <td>No Education Listed</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>Full-time (&gt; 32 hours)</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>[None]</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>{\\n  \"lat\": 37.5407246,\\n  \"lon\": -77.4360481\\n}</td>\n      <td>UmljaG1vbmQsIFZB</td>\n      <td>Richmond, VA</td>\n      <td>51041.0</td>\n      <td>Chesterfield, VA</td>\n      <td>40060.0</td>\n      <td>Richmond, VA</td>\n      <td>51.0</td>\n      <td>Virginia</td>\n      <td>51041.0</td>\n      <td>Chesterfield, VA</td>\n      <td>51760.0</td>\n      <td>Richmond City, VA</td>\n      <td>40060.0</td>\n      <td>Richmond, VA</td>\n      <td>40060.0</td>\n      <td>Richmond, VA</td>\n      <td>54.0</td>\n      <td>Professional, Scientific, and Technical Services</td>\n      <td>541.0</td>\n      <td>Professional, Scientific, and Technical Services</td>\n      <td>5415.0</td>\n      <td>Computer Systems Design and Related Services</td>\n      <td>54151.0</td>\n      <td>Computer Systems Design and Related Services</td>\n      <td>541511.0</td>\n      <td>Custom Computer Programming Services</td>\n      <td>ET3037E0C947A02404</td>\n      <td>Data Analysts</td>\n      <td>data analyst</td>\n      <td>[\\n  \"KS1282N6NQMZ95M1HJ7L\",\\n  \"KS13USA80NE38...</td>\n      <td>[\\n  \"Scrum (Software Development)\",\\n  \"Power...</td>\n      <td>[\\n  \"KS1282N6NQMZ95M1HJ7L\",\\n  \"KS13USA80NE38...</td>\n      <td>[\\n  \"Scrum (Software Development)\",\\n  \"Power...</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[\\n  \"KS1259D6L30YYG3XR3VL\",\\n  \"KS122556LMQ82...</td>\n      <td>[\\n  \"Interpersonal Communications\",\\n  \"Commu...</td>\n      <td>[\\n  \"KS13USA80NE38XJHA2TL\",\\n  \"KS125LS6N7WP4...</td>\n      <td>[\\n  \"Power BI\",\\n  \"Python (Programming Langu...</td>\n      <td>15-2051.01</td>\n      <td>Business Intelligence Analysts</td>\n      <td>15-2051.01</td>\n      <td>Business Intelligence Analysts</td>\n      <td>[\\n  \"52.0101\"\\n]</td>\n      <td>[\\n  \"Business/Commerce, General\"\\n]</td>\n      <td>[\\n  \"52.01\"\\n]</td>\n      <td>[\\n  \"Business/Commerce, General\"\\n]</td>\n      <td>[\\n  \"52\"\\n]</td>\n      <td>[\\n  \"Business, Management, Marketing, and Rel...</td>\n      <td>15-0000</td>\n      <td>Computer and Mathematical Occupations</td>\n      <td>15-2000</td>\n      <td>Mathematical Science Occupations</td>\n      <td>15-2050</td>\n      <td>Data Scientists</td>\n      <td>15-2051</td>\n      <td>Data Scientists</td>\n      <td>23.0</td>\n      <td>Information Technology and Computer Science</td>\n      <td>231113.0</td>\n      <td>Data / Data Mining Analyst</td>\n      <td>23111310.0</td>\n      <td>Data Analyst</td>\n      <td>2311.0</td>\n      <td>Data Analysis and Mathematics</td>\n      <td>23111310.0</td>\n      <td>Data Analyst</td>\n      <td>231113.0</td>\n      <td>Data / Data Mining Analyst</td>\n      <td>2311.0</td>\n      <td>Data Analysis and Mathematics</td>\n      <td>23.0</td>\n      <td>Information Technology and Computer Science</td>\n      <td>15-0000</td>\n      <td>Computer and Mathematical Occupations</td>\n      <td>15-2000</td>\n      <td>Mathematical Science Occupations</td>\n      <td>15-2050</td>\n      <td>Data Scientists</td>\n      <td>15-2051</td>\n      <td>Data Scientists</td>\n      <td>[\\n  7\\n]</td>\n      <td>[\\n  \"Artificial Intelligence\"\\n]</td>\n      <td>54.0</td>\n      <td>Professional, Scientific, and Technical Services</td>\n      <td>541.0</td>\n      <td>Professional, Scientific, and Technical Services</td>\n      <td>5415.0</td>\n      <td>Computer Systems Design and Related Services</td>\n      <td>54151.0</td>\n      <td>Computer Systems Design and Related Services</td>\n      <td>541511.0</td>\n      <td>Custom Computer Programming Services</td>\n    </tr>\n    <tr>\n      <th>72494</th>\n      <td>241d30b5478c0b1715618e0cfac65d40f781c0d8</td>\n      <td>10/21/2024</td>\n      <td>2024-10-21 13:59:53.998 Z</td>\n      <td>6.0</td>\n      <td>8/16/2024</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>[\\n  \"Company\",\\n  \"Job Board\"\\n]</td>\n      <td>[\\n  \"myworkdayjobs.com\",\\n  \"mass-veterans.jo...</td>\n      <td>[\\n  \"https://wk.wd3.myworkdayjobs.com/en-us/e...</td>\n      <td>[\\n  \"https://wk.wd3.myworkdayjobs.com/en-US/E...</td>\n      <td>[\\n  {\\n    \"source\": \"jobserve.com\",\\n    \"ty...</td>\n      <td>Lead Enterprise Architect - SalesForce</td>\n      <td>Lead Enterprise Architect - SalesForce \\nLead ...</td>\n      <td>9/13/2024</td>\n      <td>28.0</td>\n      <td>59335641.0</td>\n      <td>Wolters Kluwer</td>\n      <td>Wolters Kluwer N.V.</td>\n      <td>False</td>\n      <td>[\\n  2\\n]</td>\n      <td>[\\n  \"Bachelor's degree\"\\n]</td>\n      <td>2.0</td>\n      <td>Bachelor's degree</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>Full-time (&gt; 32 hours)</td>\n      <td>10.0</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>169275.0</td>\n      <td>0.0</td>\n      <td>[None]</td>\n      <td>year</td>\n      <td>197550.0</td>\n      <td>141000.0</td>\n      <td>{\\n  \"lat\": 42.3764852,\\n  \"lon\": -71.2356113\\n}</td>\n      <td>V2FsdGhhbSwgTUE=</td>\n      <td>Waltham, MA</td>\n      <td>25017.0</td>\n      <td>Middlesex, MA</td>\n      <td>14460.0</td>\n      <td>Boston-Cambridge-Newton, MA-NH</td>\n      <td>25.0</td>\n      <td>Massachusetts</td>\n      <td>25017.0</td>\n      <td>Middlesex, MA</td>\n      <td>25017.0</td>\n      <td>Middlesex, MA</td>\n      <td>14460.0</td>\n      <td>Boston-Cambridge-Newton, MA-NH</td>\n      <td>14460.0</td>\n      <td>Boston-Cambridge-Newton, MA-NH</td>\n      <td>51.0</td>\n      <td>Information</td>\n      <td>513.0</td>\n      <td>Publishing Industries</td>\n      <td>5131.0</td>\n      <td>Newspaper, Periodical, Book, and Directory Pub...</td>\n      <td>51313.0</td>\n      <td>Book Publishers</td>\n      <td>513130.0</td>\n      <td>Book Publishers</td>\n      <td>ETA6C910340E81639B</td>\n      <td>Lead Enterprise Architects</td>\n      <td>lead enterprise architect salesforce</td>\n      <td>[\\n  \"KS4407N6CMTCYT0NYSVM\",\\n  \"ESF6784E14B18...</td>\n      <td>[\\n  \"Salesforce\",\\n  \"Programming Languages\",...</td>\n      <td>[\\n  \"KS4407N6CMTCYT0NYSVM\",\\n  \"ESF6784E14B18...</td>\n      <td>[\\n  \"Salesforce\",\\n  \"Programming Languages\",...</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[\\n  \"KS441VC75P5WHX8QL5SN\",\\n  \"ES20CECA4FF83...</td>\n      <td>[\\n  \"Visionary\",\\n  \"Influencing Skills\",\\n  ...</td>\n      <td>[\\n  \"KS4407N6CMTCYT0NYSVM\",\\n  \"ESE9117F9A17C...</td>\n      <td>[\\n  \"Salesforce\",\\n  \"Salesforce Object Searc...</td>\n      <td>15-2051.01</td>\n      <td>Business Intelligence Analysts</td>\n      <td>15-2051.01</td>\n      <td>Business Intelligence Analysts</td>\n      <td>[\\n  \"52.0201\",\\n  \"11.0701\"\\n]</td>\n      <td>[\\n  \"Business Administration and Management, ...</td>\n      <td>[\\n  \"52.02\",\\n  \"11.07\"\\n]</td>\n      <td>[\\n  \"Business Administration, Management and ...</td>\n      <td>[\\n  \"52\",\\n  \"11\"\\n]</td>\n      <td>[\\n  \"Business, Management, Marketing, and Rel...</td>\n      <td>15-0000</td>\n      <td>Computer and Mathematical Occupations</td>\n      <td>15-2000</td>\n      <td>Mathematical Science Occupations</td>\n      <td>15-2050</td>\n      <td>Data Scientists</td>\n      <td>15-2051</td>\n      <td>Data Scientists</td>\n      <td>23.0</td>\n      <td>Information Technology and Computer Science</td>\n      <td>231510.0</td>\n      <td>Computer Systems Engineer / Architect</td>\n      <td>23151012.0</td>\n      <td>Enterprise Architect</td>\n      <td>2315.0</td>\n      <td>Network and Systems Engineering</td>\n      <td>23151012.0</td>\n      <td>Enterprise Architect</td>\n      <td>231510.0</td>\n      <td>Computer Systems Engineer / Architect</td>\n      <td>2315.0</td>\n      <td>Network and Systems Engineering</td>\n      <td>23.0</td>\n      <td>Information Technology and Computer Science</td>\n      <td>15-0000</td>\n      <td>Computer and Mathematical Occupations</td>\n      <td>15-2000</td>\n      <td>Mathematical Science Occupations</td>\n      <td>15-2050</td>\n      <td>Data Scientists</td>\n      <td>15-2051</td>\n      <td>Data Scientists</td>\n      <td>[\\n  5\\n]</td>\n      <td>[\\n  \"Cybersecurity\"\\n]</td>\n      <td>51.0</td>\n      <td>Information</td>\n      <td>513.0</td>\n      <td>Publishing Industries</td>\n      <td>5131.0</td>\n      <td>Newspaper, Periodical, Book, and Directory Pub...</td>\n      <td>51313.0</td>\n      <td>Book Publishers</td>\n      <td>513130.0</td>\n      <td>Book Publishers</td>\n    </tr>\n    <tr>\n      <th>72495</th>\n      <td>3a0bc8e830dfb4ea44f721fb3139f41f398bb66d</td>\n      <td>10/16/2024</td>\n      <td>2024-10-16 13:45:59.907 Z</td>\n      <td>4.0</td>\n      <td>8/16/2024</td>\n      <td>9/22/2024</td>\n      <td>37.0</td>\n      <td>[\\n  \"Job Board\",\\n  \"Company\"\\n]</td>\n      <td>[\\n  \"disabledperson.com\",\\n  \"dejobs.org\"\\n]</td>\n      <td>[\\n  \"https://disabilities.dejobs.org/lansing-...</td>\n      <td>[]</td>\n      <td>NaN</td>\n      <td>Data Analyst</td>\n      <td>Volt\\n\\n \\n \\n \\n\\n \\n\\n \\nData Analyst\\n in\\n...</td>\n      <td>8/31/2024</td>\n      <td>15.0</td>\n      <td>36997534.0</td>\n      <td>Volt</td>\n      <td>Volt</td>\n      <td>True</td>\n      <td>[\\n  2\\n]</td>\n      <td>[\\n  \"Bachelor's degree\"\\n]</td>\n      <td>2.0</td>\n      <td>Bachelor's degree</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>Full-time (&gt; 32 hours)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>72800.0</td>\n      <td>3.0</td>\n      <td>Hybrid Remote</td>\n      <td>hour</td>\n      <td>83200.0</td>\n      <td>62400.0</td>\n      <td>{\\n  \"lat\": 42.732535,\\n  \"lon\": -84.5555347\\n}</td>\n      <td>TGFuc2luZywgTUk=</td>\n      <td>Lansing, MI</td>\n      <td>26065.0</td>\n      <td>Ingham, MI</td>\n      <td>29620.0</td>\n      <td>Lansing-East Lansing, MI</td>\n      <td>26.0</td>\n      <td>Michigan</td>\n      <td>26065.0</td>\n      <td>Ingham, MI</td>\n      <td>26065.0</td>\n      <td>Ingham, MI</td>\n      <td>29620.0</td>\n      <td>Lansing-East Lansing, MI</td>\n      <td>29620.0</td>\n      <td>Lansing-East Lansing, MI</td>\n      <td>56.0</td>\n      <td>Administrative and Support and Waste Managemen...</td>\n      <td>561.0</td>\n      <td>Administrative and Support Services</td>\n      <td>5613.0</td>\n      <td>Employment Services</td>\n      <td>56131.0</td>\n      <td>Employment Placement Agencies and Executive Se...</td>\n      <td>561311.0</td>\n      <td>Employment Placement Agencies</td>\n      <td>ET3037E0C947A02404</td>\n      <td>Data Analysts</td>\n      <td>data analyst</td>\n      <td>[\\n  \"KSQPGV2XZO8UMNCC49LK\",\\n  \"ES899BA440FA3...</td>\n      <td>[\\n  \"Detail Oriented\",\\n  \"Workflow Managemen...</td>\n      <td>[\\n  \"ES899BA440FA3441F22A\",\\n  \"KS1203K6FQ749...</td>\n      <td>[\\n  \"Workflow Management\",\\n  \"Acceptance Tes...</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[\\n  \"KSQPGV2XZO8UMNCC49LK\",\\n  \"KS1200H6XYN1C...</td>\n      <td>[\\n  \"Detail Oriented\",\\n  \"Microsoft Excel\",\\...</td>\n      <td>[\\n  \"KS1200H6XYN1CR0G5NZ0\",\\n  \"KS1218L60PDVZ...</td>\n      <td>[\\n  \"Microsoft Excel\",\\n  \"Dashboard\",\\n  \"Ta...</td>\n      <td>15-2051.01</td>\n      <td>Business Intelligence Analysts</td>\n      <td>15-2051.01</td>\n      <td>Business Intelligence Analysts</td>\n      <td>[\\n  \"30.7101\",\\n  \"27.0501\",\\n  \"11.0701\"\\n]</td>\n      <td>[\\n  \"Data Analytics, General\",\\n  \"Statistics...</td>\n      <td>[\\n  \"30.71\",\\n  \"27.05\",\\n  \"11.07\"\\n]</td>\n      <td>[\\n  \"Data Analytics\",\\n  \"Statistics\",\\n  \"Co...</td>\n      <td>[\\n  \"30\",\\n  \"27\",\\n  \"11\"\\n]</td>\n      <td>[\\n  \"Multi/Interdisciplinary Studies\",\\n  \"Ma...</td>\n      <td>15-0000</td>\n      <td>Computer and Mathematical Occupations</td>\n      <td>15-2000</td>\n      <td>Mathematical Science Occupations</td>\n      <td>15-2050</td>\n      <td>Data Scientists</td>\n      <td>15-2051</td>\n      <td>Data Scientists</td>\n      <td>23.0</td>\n      <td>Information Technology and Computer Science</td>\n      <td>231113.0</td>\n      <td>Data / Data Mining Analyst</td>\n      <td>23111310.0</td>\n      <td>Data Analyst</td>\n      <td>2311.0</td>\n      <td>Data Analysis and Mathematics</td>\n      <td>23111310.0</td>\n      <td>Data Analyst</td>\n      <td>231113.0</td>\n      <td>Data / Data Mining Analyst</td>\n      <td>2311.0</td>\n      <td>Data Analysis and Mathematics</td>\n      <td>23.0</td>\n      <td>Information Technology and Computer Science</td>\n      <td>15-0000</td>\n      <td>Computer and Mathematical Occupations</td>\n      <td>15-2000</td>\n      <td>Mathematical Science Occupations</td>\n      <td>15-2050</td>\n      <td>Data Scientists</td>\n      <td>15-2051</td>\n      <td>Data Scientists</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>56.0</td>\n      <td>Administrative and Support and Waste Managemen...</td>\n      <td>561.0</td>\n      <td>Administrative and Support Services</td>\n      <td>5613.0</td>\n      <td>Employment Services</td>\n      <td>56131.0</td>\n      <td>Employment Placement Agencies and Executive Se...</td>\n      <td>561311.0</td>\n      <td>Employment Placement Agencies</td>\n    </tr>\n    <tr>\n      <th>72496</th>\n      <td>2e842ecdc031bdb4b8f8c2f724b5c51cdc7814eb</td>\n      <td>10/16/2024</td>\n      <td>2024-10-16 13:45:59.907 Z</td>\n      <td>0.0</td>\n      <td>8/16/2024</td>\n      <td>10/15/2024</td>\n      <td>NaN</td>\n      <td>[\\n  \"Job Board\"\\n]</td>\n      <td>[\\n  \"maine.gov\"\\n]</td>\n      <td>[\\n  \"https://joblink.maine.gov/jobs/1114773\"\\n]</td>\n      <td>[]</td>\n      <td>NaN</td>\n      <td>Data Analyst</td>\n      <td>Data Analyst\\n\\nat Consolidated Communications...</td>\n      <td>9/8/2024</td>\n      <td>23.0</td>\n      <td>98412363.0</td>\n      <td>Consolidated Communications Enterprise Service...</td>\n      <td>Consolidated Communications Enterprise Service...</td>\n      <td>False</td>\n      <td>[\\n  2\\n]</td>\n      <td>[\\n  \"Bachelor's degree\"\\n]</td>\n      <td>2.0</td>\n      <td>Bachelor's degree</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>Full-time (&gt; 32 hours)</td>\n      <td>7.0</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>[None]</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>{\\n  \"lat\": 44.8016128,\\n  \"lon\": -68.7712257\\n}</td>\n      <td>QmFuZ29yLCBNRQ==</td>\n      <td>Bangor, ME</td>\n      <td>23019.0</td>\n      <td>Penobscot, ME</td>\n      <td>12620.0</td>\n      <td>Bangor, ME</td>\n      <td>23.0</td>\n      <td>Maine</td>\n      <td>23019.0</td>\n      <td>Penobscot, ME</td>\n      <td>23019.0</td>\n      <td>Penobscot, ME</td>\n      <td>12620.0</td>\n      <td>Bangor, ME</td>\n      <td>12620.0</td>\n      <td>Bangor, ME</td>\n      <td>51.0</td>\n      <td>Information</td>\n      <td>517.0</td>\n      <td>Telecommunications</td>\n      <td>5178.0</td>\n      <td>All Other Telecommunications</td>\n      <td>51781.0</td>\n      <td>All Other Telecommunications</td>\n      <td>517810.0</td>\n      <td>All Other Telecommunications</td>\n      <td>ET3037E0C947A02404</td>\n      <td>Data Analysts</td>\n      <td>data analyst</td>\n      <td>[\\n  \"KS13USA80NE38XJHA2TL\",\\n  \"KS1219774ZFQ6...</td>\n      <td>[\\n  \"Power BI\",\\n  \"Business Reporting\",\\n  \"...</td>\n      <td>[\\n  \"KS13USA80NE38XJHA2TL\",\\n  \"KS1219774ZFQ6...</td>\n      <td>[\\n  \"Power BI\",\\n  \"Business Reporting\",\\n  \"...</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[\\n  \"KS1203C6N9B52QGB4H67\",\\n  \"KS7G747655VG2...</td>\n      <td>[\\n  \"Research\",\\n  \"Prioritization\",\\n  \"Writ...</td>\n      <td>[\\n  \"KS13USA80NE38XJHA2TL\",\\n  \"KS125LS6N7WP4...</td>\n      <td>[\\n  \"Power BI\",\\n  \"Python (Programming Langu...</td>\n      <td>15-2051.01</td>\n      <td>Business Intelligence Analysts</td>\n      <td>15-2051.01</td>\n      <td>Business Intelligence Analysts</td>\n      <td>[\\n  \"52.0101\",\\n  \"52.0201\",\\n  \"11.0103\",\\n ...</td>\n      <td>[\\n  \"Business/Commerce, General\",\\n  \"Busines...</td>\n      <td>[\\n  \"52.01\",\\n  \"52.02\",\\n  \"11.01\",\\n  \"11.0...</td>\n      <td>[\\n  \"Business/Commerce, General\",\\n  \"Busines...</td>\n      <td>[\\n  \"52\",\\n  \"52\",\\n  \"11\",\\n  \"11\"\\n]</td>\n      <td>[\\n  \"Business, Management, Marketing, and Rel...</td>\n      <td>15-0000</td>\n      <td>Computer and Mathematical Occupations</td>\n      <td>15-2000</td>\n      <td>Mathematical Science Occupations</td>\n      <td>15-2050</td>\n      <td>Data Scientists</td>\n      <td>15-2051</td>\n      <td>Data Scientists</td>\n      <td>23.0</td>\n      <td>Information Technology and Computer Science</td>\n      <td>231113.0</td>\n      <td>Data / Data Mining Analyst</td>\n      <td>23111310.0</td>\n      <td>Data Analyst</td>\n      <td>2311.0</td>\n      <td>Data Analysis and Mathematics</td>\n      <td>23111310.0</td>\n      <td>Data Analyst</td>\n      <td>231113.0</td>\n      <td>Data / Data Mining Analyst</td>\n      <td>2311.0</td>\n      <td>Data Analysis and Mathematics</td>\n      <td>23.0</td>\n      <td>Information Technology and Computer Science</td>\n      <td>15-0000</td>\n      <td>Computer and Mathematical Occupations</td>\n      <td>15-2000</td>\n      <td>Mathematical Science Occupations</td>\n      <td>15-2050</td>\n      <td>Data Scientists</td>\n      <td>15-2051</td>\n      <td>Data Scientists</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>51.0</td>\n      <td>Information</td>\n      <td>517.0</td>\n      <td>Telecommunications</td>\n      <td>5178.0</td>\n      <td>All Other Telecommunications</td>\n      <td>51781.0</td>\n      <td>All Other Telecommunications</td>\n      <td>517810.0</td>\n      <td>All Other Telecommunications</td>\n    </tr>\n    <tr>\n      <th>72497</th>\n      <td>733c12969489de888093ef22d09204dc0945148a</td>\n      <td>10/9/2024</td>\n      <td>2024-10-09 18:07:44.758 Z</td>\n      <td>0.0</td>\n      <td>8/16/2024</td>\n      <td>8/22/2024</td>\n      <td>6.0</td>\n      <td>[\\n  \"Job Board\"\\n]</td>\n      <td>[\\n  \"dice.com\"\\n]</td>\n      <td>[\\n  \"https://www.dice.com/job-detail/8f1208f4...</td>\n      <td>[]</td>\n      <td>NaN</td>\n      <td>Oracle Fusion Analytics Warehouse (FAW) HCM Lead</td>\n      <td>Oracle Fusion Analytics Warehouse (FAW) HCM Le...</td>\n      <td>8/22/2024</td>\n      <td>6.0</td>\n      <td>39411763.0</td>\n      <td>Lorven Technologies</td>\n      <td>Lorven Technologies, Inc.</td>\n      <td>True</td>\n      <td>[\\n  2\\n]</td>\n      <td>[\\n  \"Bachelor's degree\"\\n]</td>\n      <td>2.0</td>\n      <td>Bachelor's degree</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>Full-time (&gt; 32 hours)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>Remote</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>{\\n  \"lat\": 32.7766642,\\n  \"lon\": -96.7969879\\n}</td>\n      <td>RGFsbGFzLCBUWA==</td>\n      <td>Dallas, TX</td>\n      <td>48113.0</td>\n      <td>Dallas, TX</td>\n      <td>19100.0</td>\n      <td>Dallas-Fort Worth-Arlington, TX</td>\n      <td>48.0</td>\n      <td>Texas</td>\n      <td>48113.0</td>\n      <td>Dallas, TX</td>\n      <td>48113.0</td>\n      <td>Dallas, TX</td>\n      <td>19100.0</td>\n      <td>Dallas-Fort Worth-Arlington, TX</td>\n      <td>19100.0</td>\n      <td>Dallas-Fort Worth-Arlington, TX</td>\n      <td>54.0</td>\n      <td>Professional, Scientific, and Technical Services</td>\n      <td>541.0</td>\n      <td>Professional, Scientific, and Technical Services</td>\n      <td>5415.0</td>\n      <td>Computer Systems Design and Related Services</td>\n      <td>54151.0</td>\n      <td>Computer Systems Design and Related Services</td>\n      <td>541512.0</td>\n      <td>Computer Systems Design Services</td>\n      <td>ET36323C71A36AB5BD</td>\n      <td>Oracle HCM Consultants</td>\n      <td>oracle fusion analytics warehouse faw hcm lead</td>\n      <td>[\\n  \"KS122PM76DCYL9WC89Y7\",\\n  \"KS124DX6G31F5...</td>\n      <td>[\\n  \"Data Modeling\",\\n  \"Warehousing\",\\n  \"Co...</td>\n      <td>[\\n  \"KS122PM76DCYL9WC89Y7\",\\n  \"KS124DX6G31F5...</td>\n      <td>[\\n  \"Data Modeling\",\\n  \"Warehousing\",\\n  \"Da...</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[\\n  \"KS122556LMQ829GZCCRV\",\\n  \"KS1259D6L30YY...</td>\n      <td>[\\n  \"Communication\",\\n  \"Interpersonal Commun...</td>\n      <td>[\\n  \"KS1218L60PDVZX16NZT1\",\\n  \"ES4A15D4D2BD2...</td>\n      <td>[\\n  \"Dashboard\",\\n  \"Oracle Human Capital Man...</td>\n      <td>15-2051.01</td>\n      <td>Business Intelligence Analysts</td>\n      <td>15-2051.01</td>\n      <td>Business Intelligence Analysts</td>\n      <td>[\\n  \"11.0701\"\\n]</td>\n      <td>[\\n  \"Computer Science\"\\n]</td>\n      <td>[\\n  \"11.07\"\\n]</td>\n      <td>[\\n  \"Computer Science\"\\n]</td>\n      <td>[\\n  \"11\"\\n]</td>\n      <td>[\\n  \"Computer and Information Sciences and Su...</td>\n      <td>15-0000</td>\n      <td>Computer and Mathematical Occupations</td>\n      <td>15-2000</td>\n      <td>Mathematical Science Occupations</td>\n      <td>15-2050</td>\n      <td>Data Scientists</td>\n      <td>15-2051</td>\n      <td>Data Scientists</td>\n      <td>23.0</td>\n      <td>Information Technology and Computer Science</td>\n      <td>231010.0</td>\n      <td>Business Intelligence Analyst</td>\n      <td>23101012.0</td>\n      <td>Oracle Consultant / Analyst</td>\n      <td>2310.0</td>\n      <td>Business Intelligence</td>\n      <td>23101012.0</td>\n      <td>Oracle Consultant / Analyst</td>\n      <td>231010.0</td>\n      <td>Business Intelligence Analyst</td>\n      <td>2310.0</td>\n      <td>Business Intelligence</td>\n      <td>23.0</td>\n      <td>Information Technology and Computer Science</td>\n      <td>15-0000</td>\n      <td>Computer and Mathematical Occupations</td>\n      <td>15-2000</td>\n      <td>Mathematical Science Occupations</td>\n      <td>15-2050</td>\n      <td>Data Scientists</td>\n      <td>15-2051</td>\n      <td>Data Scientists</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>54.0</td>\n      <td>Professional, Scientific, and Technical Services</td>\n      <td>541.0</td>\n      <td>Professional, Scientific, and Technical Services</td>\n      <td>5415.0</td>\n      <td>Computer Systems Design and Related Services</td>\n      <td>54151.0</td>\n      <td>Computer Systems Design and Related Services</td>\n      <td>541512.0</td>\n      <td>Computer Systems Design Services</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n## Sample of preprocessed EDUCATION_LEVELS\n\n::: {.cell execution_count=39}\n``` {.python .cell-code}\nimport pandas as pd\nimport numpy as np\nimport ast\nfrom sklearn.model_selection import train_test_split\n\n# Load the dataset (using the provided sample data)\ndata = {\n    'DURATION': [6.0, np.nan, 35.0, 48.0],\n    'MIN_YEARS_EXPERIENCE': [2.0, 3.0, 5.0, 3.0],\n    'EMPLOYMENT_TYPE': [1.0, 1.0, 1.0, 1.0],\n    'REMOTE_TYPE': [0.0, 1.0, 0.0, 0.0],\n    'IS_INTERNSHIP': [False, False, False, False],\n    'EDUCATION_LEVELS': ['[\\n 2\\n]', '[\\n 99\\n]', '[\\n 2\\n]', '[\\n 99\\n]']\n}\ndf = pd.DataFrame(data)\n\n# Function to parse EDUCATION_LEVELS strings and handle different types\ndef parse_education_levels(edu):\n    # If the value is already a float, use it directly (or convert to nan if invalid)\n    if isinstance(edu, float):\n        return edu if not np.isnan(edu) else np.nan\n    # If the value is a string, parse it\n    if isinstance(edu, str):\n        try:\n            # Parse the string into a list using ast.literal_eval\n            edu_list = ast.literal_eval(edu.replace('\\n', ''))\n            # Return the first numerical value (as an integer)\n            return int(edu_list[0])\n        except (ValueError, SyntaxError, IndexError):\n            return np.nan  # Return NaN if parsing fails\n    # If the value is neither a string nor a float, return NaN\n    return np.nan\n\n# Apply the parsing function to EDUCATION_LEVELS\ndf['EDUCATION_LEVELS'] = df['EDUCATION_LEVELS'].apply(parse_education_levels)\n\n# Drop rows with missing values in DURATION or EDUCATION_LEVELS\ndf = df.dropna(subset=['DURATION', 'EDUCATION_LEVELS'])\n\n# Features and target\nX = df[['MIN_YEARS_EXPERIENCE', 'EMPLOYMENT_TYPE', 'REMOTE_TYPE', 'IS_INTERNSHIP', 'EDUCATION_LEVELS']]\ny = df['DURATION']\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nprint(\"Training set size:\", X_train.shape)\nprint(\"Testing set size:\", X_test.shape)\nprint(\"Sample of preprocessed EDUCATION_LEVELS:\", df['EDUCATION_LEVELS'].head().tolist())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTraining set size: (2, 5)\nTesting set size: (1, 5)\nSample of preprocessed EDUCATION_LEVELS: [2, 2, 99]\n```\n:::\n:::\n\n\n# Model Training\n\nWith the data preprocessed, I trained a Random Forest Regressor, a robust model that handles numerical features well and is less prone to overfitting. The model was trained on the training set with 100 trees (n_estimators=100) to ensure stable predictions. Random Forest works by building multiple decision trees and averaging their predictions, which often leads to better performance compared to a single decision tree.\n\nHere’s the code for training the Random Forest Regressor:\n\n::: {.cell execution_count=40}\n``` {.python .cell-code}\nfrom sklearn.ensemble import RandomForestRegressor\n\n# Initialize and train the Random Forest Regressor\nrf = RandomForestRegressor(n_estimators=100, random_state=42)\nrf.fit(X_train, y_train)\n\nprint(\"Model training completed.\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nModel training completed.\n```\n:::\n:::\n\n\n# Model Evaluation and Visualization\nAfter training the model, I used it to predict the DURATION for the test set. To evaluate the model's performance, I calculated the Mean Squared Error (MSE), which measures the average squared difference between actual and predicted values. A lower MSE indicates better predictive accuracy.\n\nI also created a scatter plot to visualize the model's performance, comparing the actual DURATION values to the predicted ones. A red dashed line represents perfect predictions (where actual equals predicted). Points closer to this line indicate better predictions.\n\nHere’s the code for evaluation and visualization:\n\n::: {.cell execution_count=41}\n``` {.python .cell-code}\nfrom sklearn.metrics import mean_squared_error\nimport matplotlib.pyplot as plt\n\n# Make predictions on the test set\ny_pred = rf.predict(X_test)\n\n# Calculate Mean Squared Error\nmse = mean_squared_error(y_test, y_pred)\nprint(f\"Mean Squared Error: {mse:.2f}\")\n\n# Plot actual vs predicted values\nplt.figure(figsize=(8, 6))\nplt.scatter(y_test, y_pred, color='blue', label='Predicted vs Actual')\nplt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', label='Perfect Prediction')\nplt.xlabel('Actual Duration (Days)')\nplt.ylabel('Predicted Duration (Days)')\nplt.title('Random Forest Regressor: Actual vs Predicted Job Posting Duration')\nplt.legend()\nplt.grid(True)\nplt.savefig('actual_vs_predicted_duration.png')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nMean Squared Error: 1297.44\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](final_report_files/figure-docx/cell-42-output-2.png){}\n:::\n:::\n\n\n# Results\n\nThe Mean Squared Error (MSE) provides a quantitative measure of the model's performance. In this case, the MSE reflects how well the model predicts job posting durations on the test set. The scatter plot (actual_vs_predicted_duration.png) visually demonstrates the model's accuracy. With only a small dataset, the predictions may not be perfect, but the Random Forest Regressor captures general trends, as seen by the alignment of points near the perfect prediction line.\n\n# Conclusion\n\nUsing a Random Forest Regressor, I built a model to predict the duration of job postings based on features like experience, employment type, and education level. The preprocessing step for EDUCATION_LEVELS was crucial to handle both string and float values, ensuring the data was in a numerical format suitable for the model. However, the model's performance was poor, with an MSE of 1296.00 and a significant overprediction (42.0 days predicted vs. 6.0 days actual), as shown in the scatter plot. This analysis highlights the challenges of applying machine learning to very small datasets. Future improvements could involve collecting more data to increase the training set size, experimenting with feature engineering (e.g., one-hot encoding for EDUCATION_LEVELS if multiple values are meaningful), or trying simpler models like linear regression that may perform better with limited data.\n\n\n---\n\ntitle: \"NLP Methods\"\nsubtitle: \"NLP Analysis: Extracting Required Skills from Job Postings\"\nauthor:\n  - name: Shreya Mani\n    affiliations:\n      - id: bu\n        name: Boston University\n        city: Boston\n        state: MA\nformat: \n  html:\n        toc: true\n        number-sections: true\n        df-print: paged\n---\n\n# Introduction\nIn this project, we used Natural Language Processing (NLP) to extract required skills from job postings based on their description text in the BODY column. The dataset contains job postings with unstructured text descriptions, which often mention skills needed for the role (e.g., \"analyze data\" or \"develop software\"). Our goal was to identify and analyze the most common skills mentioned in these postings, providing insights into the skills most in demand. This analysis can help job seekers understand the key skills to develop and assist employers in identifying trends in skill requirements.\n\n# Data Preprocessing\nWe started by loading the dataset and focusing on the BODY column, which contains the job description text. The BODY text is unstructured and requires preprocessing for NLP analysis. We performed the following steps:\n\nTokenization and Cleaning: Converted the text to lowercase, removed punctuation, and tokenized the text into words.\n\n\nStop Word Removal: Removed common stop words (e.g., \"the\", \"is\") that don’t add meaningful information. We used a predefined list of common stop words to avoid external dependencies.\n\n\nSkill Extraction: Defined a list of common skills relevant to job postings (e.g., \"data analysis,\" \"software development\") and searched for these skills in the cleaned text. For simplicity, we used keyword matching to identify skills, but this could be extended with more advanced NLP techniques like named entity recognition (NER) or pre-trained models.\n\nSince this task is exploratory and doesn’t require a target variable, we didn’t split the data into training and testing sets. Instead, we processed all available job descriptions to extract and analyze skills.\n\nHere’s the Python code we used for data preprocessing and skill extraction:\n\n::: {.cell message='false' execution_count=42}\n``` {.python .cell-code}\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport re\nfrom collections import Counter\n\n# Load dataset\ncsv_path = 'region_analysis/lightcast_job_postings.csv'\ndf = pd.read_csv(csv_path)\n\n# Drop rows with missing job descriptions\ndf = df.dropna(subset=['BODY'])\n\n# Define stop words\nstop_words = {\n    'a', 'an', 'and', 'are', 'as', 'at', 'be', 'by', 'for', 'from', 'has', 'he',\n    'in', 'is', 'it', 'its', 'of', 'on', 'that', 'the', 'to', 'was', 'were', 'will',\n    'with', 'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your',\n    'yours', 'yourself', 'yourselves', 'him', 'his', 'her', 'hers', 'herself', 'it',\n    'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which',\n    'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were',\n    'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing',\n    'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of',\n    'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during',\n    'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on',\n    'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when',\n    'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other',\n    'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very',\n    's', 't', 'can', 'will', 'just', 'don', 'should', 'now'\n}\n\n# Clean text\ndef clean_text(text):\n    text = text.lower()\n    text = re.sub(r'[^a-z\\s]', '', text)\n    tokens = text.split()\n    return ' '.join([word for word in tokens if word not in stop_words])\n\ndf['BODY_CLEANED'] = df['BODY'].apply(clean_text)\n\n# Define common skills\nskills_list = [\n    \"data analysis\", \"software development\", \"machine learning\",\n    \"project management\", \"communication\", \"teamwork\",\n    \"sql\", \"python\", \"modeling\", \"analytics\"\n]\n\n# Extract skills\ndef extract_skills(text):\n    found_skills = []\n    for skill in skills_list:\n        if skill in text:\n            found_skills.append(skill)\n    return found_skills\n\ndf['SKILLS'] = df['BODY_CLEANED'].apply(extract_skills)\n\n# Flatten skill list and count\nall_skills = [skill for sublist in df['SKILLS'] for skill in sublist]\nskill_counts = Counter(all_skills)\n\n\n\n# Visualize top skills\nplt.figure(figsize=(10, 6))\nif skill_counts:\n    skills, counts = zip(*sorted(skill_counts.items(), key=lambda x: x[1], reverse=True))\n    plt.bar(skills, counts, color='skyblue')\n    plt.xlabel('Skills')\n    plt.ylabel('Frequency')\n    plt.title('Most Common Skills in Job Postings')\n    plt.xticks(rotation=45, ha='right')\n    plt.tight_layout()\n    plt.savefig('skills_frequency.png')\n    plt.show()\nelse:\n    print(\"No skills were found in the job descriptions.\")\n```\n\n::: {.cell-output .cell-output-display}\n![](final_report_files/figure-docx/skill-extraction-output-1.png){#skill-extraction}\n:::\n:::\n\n\n# Skill Analysis and Visualization\n\nAfter extracting skills from the job descriptions, we analyzed their frequency to identify the most common skills mentioned. We visualized the results using a bar plot, showing the count of each skill across all job postings. This helps highlight the skills that are most in demand based on the dataset.\n\nHere’s the code we used for analyzing and visualizing the skills:\n\n---\ntitle: \"Career Strategy\"\nsubtitle: \"Personal Career Roadmap Based on 2024 Job Market Trends\"\nauthor:\n  - name: \"An Ly, Advait Pillai, Ritusri Mohan, Shreya Mani \"\n    affiliations:\n      - id: bu\n        name: Boston University\n        city: Boston\n        state: MA\nformat: \n  html:\n    toc: true\n    number-sections: true\n    df-print: paged\nbibliography: references.bib\ncsl: csl/econometrica.csl\n---\n\n# 1. An Ly – Business Analyst in Finance or Tech\n\n## Career Goal\n\nMy goal is to secure a Business Analyst role in either the financial services or technology industry. I'm particularly interested in companies that use analytics to drive strategic decision-making, especially in hybrid or remote-friendly environments.\n\n## Key Trends Supporting My Career Plan\n\nOur EDA revealed that roles in professional, scientific, and technical services dominate job postings in 2024. Remote roles are especially prevalent in tech, aligning well with my flexibility needs and skills in Python, Tableau, and SQL.\n\n## Action Plan\n\n1. Strengthen Python and Power BI visualization skills.\n2. Network with Boston alumni working in fintech.\n3. Apply to hybrid analyst roles in NY, MA, and CA.\n\n---\n\n# 2. Advait Pillai – Data Engineer in Cloud & Big Data\n\n## Career Goal\n\nI aim to become a data engineer focused on big data pipelines and cloud infrastructure, particularly with AWS and Spark.\n\n## Key Trends Supporting My Career Plan\n\nThe job title analysis showed strong demand for technical roles like Data Engineer, especially in major tech hubs like California and Texas. Our project also highlighted the increasing importance of cloud-based roles with remote options.\n\n## Action Plan\n\n1. Earn AWS Cloud Practitioner and Spark certifications.\n2. Complete hands-on projects in ETL and data pipeline development.\n3. Target roles at cloud-first companies like Snowflake, Amazon, and startups.\n\n---\n\n# 3. Ritusri Mohan – Business Intelligence Analyst in Healthcare\n\n## Career Goal\n\nI want to pursue a career as a Business Intelligence Analyst within the healthcare industry. I’m passionate about combining analytics and patient-centric systems to improve operations.\n\n## Key Trends Supporting My Career Plan\n\nHealthcare & Social Assistance was the second-largest industry by job postings in our dataset. However, most roles remain on-site, which aligns with my comfort level working in physical healthcare environments.\n\n## Action Plan\n\n1. Complete Tableau + SQL + Healthcare Analytics specialization on Coursera.\n2. Attend HIMSS career webinars and healthcare data meetups.\n3. Apply for entry-level BI roles in hospitals or health tech firms.\n\n---\n\n# 4. Shreya Mani – Data Scientist in Retail or Consulting\n\n## Career Goal\n\nMy goal is to become a Data Scientist specializing in customer behavior, forecasting, or supply chain analytics in the retail or consulting sectors.\n\n## Key Trends Supporting My Career Plan\n\nOur analysis of job titles and word clouds indicated demand for data and consulting roles. While retail showed fewer postings, consulting and analytics-driven firms remain strong in hiring for hybrid data roles.\n\n## Action Plan\n\n1. Build end-to-end forecasting models using time-series libraries.\n2. Apply to rotational data science programs at firms like Deloitte and Target.\n3. Practice Kaggle competitions and publish findings to GitHub/LinkedIn.\n\n---\n\n## Conclusion\n\nEach of us is aligning our personal goals with the trends we uncovered through our analysis of 2024 job market data. Whether targeting technical infrastructure, healthcare analytics, or strategic consulting, we aim to use our data-driven insights to inform smart, personalized job search strategies.\n\n\n---\n\ntitle: \"References\"\n---\n\n## Predictive Salary Modelling: Leveraging Data Science Skills and Machine Learning for Accurate Forecasting\nHaseeb, M. A., Viswanathan, R., Iyer, K., Hota, A. R., & Prathaban, B. P. (2024). Predictive salary modelling: Leveraging data science skills and machine learning for accurate forecasting. 2024 9th International Conference on Communication and Electronics Systems (ICCES), 1011–1019. https://ieeexplore.ieee.org/document/10859447\n\n## Tackling Economic Inequalities Through Business Analytics: A Literature Review\nAdaga, E. M., Egieya, Z. E., Ewuga, S. K., Abdul, A. A., & Abrahams, O. (2024). Tackling economic inequalities through business analytics: A literature review. Computer Science & IT Research Journal, 5(1), 60–80. https://doi.org/10.51594/csitjr.v5i1.702\n\n## Antecedent Configurations Toward Supply Chain Resilience: The Joint Impact of Supply Chain Integration and Big Data Analytics Capability\nJiang, Y., Feng, T., & Huang, Y. (2024). Antecedent configurations toward supply chain resilience: The joint impact of supply chain integration and big data analytics capability. Journal of Operations Management, 70(2), 257–284. https://doi.org/10.1002/joom.1282\n\n## Leveraging AI and Data Analytics for Enhancing Financial Inclusion in Developing Economies\nAdeoye, O. B., Addy, W. A., Ajayi-Nifise, A. O., Odeyemi, O., Okoye, C. C., & Ofodile, O. C. (n.d.). Leveraging AI and data analytics for enhancing financial inclusion in developing economies. Finance & Accounting Research Journal. https://fepbl.com/index.php/farj/article/view/856\n\n## Employee Career Decision Making: The Influence of Salary and Benefits, Work Environment and Job Security\nAchim, N., Badrolhisam, N. I., & Zulkipli, N. (2019). Employee career decision making: The influence of salary and benefits, work environment and job security. Journal of Academia, 7(Special Issue 1), 41–50.\n\n## The Influence of Salaries and “Opportunity Costs” on Teachers’ Career Choices\nMurnane, R. J., Singer, J. D., & Willett, J. B. (1989). The influences of salaries and “opportunity costs” on teachers' career choices: Evidence from North Carolina. Harvard Educational Review, 59(3), 325–349.\n\n## The Future of Work: Impacts of AI on Employment and Job Market Dynamics\nTomar, A., Sharma, S., Arti, & Suman, S. (2024). The future of work: Impacts of AI on employment and job market dynamics. 2024 International Conference on Progressive Innovations in Intelligent Systems and Data Science (ICPIDS).\n\n## AI and Job Market: Analysing the Potential Impact of AI on Employment, Skills, and Job Displacement\nFaluyi, S. E. (2025). AI and job market: Analysing the potential impact of AI on employment, skills, and job displacement. African Journal of Marketing Management, 17(1), 1–8.\n\n",
    "supporting": [
      "final_report_files"
    ],
    "filters": []
  }
}